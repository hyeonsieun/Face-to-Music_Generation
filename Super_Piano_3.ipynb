{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9opKSK2RSDRg"
      },
      "source": [
        "# Super Piano 3: Google Music Transformer\n",
        "## Generating Music with Long-Term structure\n",
        "### Based on 2019 ICLR paper by Cheng-Zhi Anna Huang, Google Brain and Damon Gwinn's code/repo https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "Huge thanks go out to the following people who contributed the code/repos used in this colab. Additional contributors are listed in the code as well.\n",
        "\n",
        "1) Kevin-Yang https://github.com/jason9693/midi-neural-processor\n",
        "\n",
        "2) gudgud96 for fixing Kevin's MIDI Encoder properly https://github.com/gudgud96\n",
        "\n",
        "2) jinyi12, Zac Koh, Akamight, Zhang https://github.com/COMP6248-Reproducability-Challenge/music-transformer-comp6248\n",
        "\n",
        "Thank you so much for your hard work and for sharing it with the world :)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "05hD19W0hSCP"
      },
      "source": [
        "###Setup Environment and Dependencies. Check GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "Ror_UJUp7wlO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Mon_May__3_19:15:13_PDT_2021\n",
            "Cuda compilation tools, release 11.3, V11.3.109\n",
            "Build cuda_11.3.r11.3/compiler.29920130_0\n",
            "Mon Jun  5 08:19:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
            "| 22%   47C    P8    19W / 250W |      2MiB / 12212MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
            "| 17%   34C    P8     6W / 215W |     20MiB /  7981MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   2  NVIDIA TITAN X ...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
            "| 26%   46C    P8    11W / 250W |      2MiB / 12196MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   3  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
            "| 25%   56C    P8    18W / 250W |      2MiB / 12212MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title Check if GPU (driver) is avaiiable (you do not want to run this on CPU, trust me)\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "paYvoZHihtux"
      },
      "outputs": [],
      "source": [
        "#@title Clone/Install all dependencies\n",
        "!git clone https://github.com/asigalov61/midi-neural-processor\n",
        "#!git clone https://github.com/asigalov61/MusicTransformer-Pytorch\n",
        "!pip install tqdm\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install librosa\n",
        "!pip install scipy\n",
        "!pip install pillow\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install mir_eval\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "VM71tUPVfffi"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "# For plotting\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "#%matplotlib inline\n",
        "#matplotlib.get_backend()\n",
        "import mir_eval.display\n",
        "import librosa\n",
        "import librosa.display\n",
        "# For rendering output audio\n",
        "import pretty_midi\n",
        "from midi2audio import FluidSynth\n",
        "#from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JwCQIziNwHxe"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hwisXl2Iy_Xf"
      },
      "outputs": [],
      "source": [
        "#@title Activate Tensorboard Graphs/Stats to monitor/evaluate model perfomance during and after training runs\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/MusicTransformer-Pytorch/rpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Sbv_sJyLq5om"
      },
      "outputs": [],
      "source": [
        "#@title Start to Train the Model\n",
        "batch_size = 4 #@param {type:\"slider\", min:0, max:8, step:1}\n",
        "number_of_training_epochs = 500 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "maximum_output_MIDI_sequence = 2048 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "!python3 train.py -output_dir ./output -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence  #-n_layers -num_heads -d_model -dim_feedforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "9VLdhokSGUAu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================\n",
            "input_dir: ./dataset\n",
            "output_dir: ./output\n",
            "weight_modulus: 1\n",
            "print_modulus: 1\n",
            "\n",
            "n_workers: 1\n",
            "force_cpu: False\n",
            "tensorboard: True\n",
            "\n",
            "continue_weights: ./output/weights/epoch_0493.pickle\n",
            "continue_epoch: 493\n",
            "\n",
            "lr: None\n",
            "ce_smoothing: None\n",
            "batch_size: 4\n",
            "epochs: 500\n",
            "\n",
            "rpr: False\n",
            "max_sequence: 2048\n",
            "n_layers: 6\n",
            "num_heads: 8\n",
            "d_model: 512\n",
            "\n",
            "dim_feedforward: 1024\n",
            "dropout: 0.1\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 1 / 499\n",
            "LR: 8.910260564395426e-05\n",
            "Train loss: 0.8978692889213562\n",
            "\n",
            "Time (s): 1.0134024620056152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 2 / 499\n",
            "LR: 8.910242454753869e-05\n",
            "Train loss: 0.6205321550369263\n",
            "\n",
            "Time (s): 0.5629901885986328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 3 / 499\n",
            "LR: 8.910224345222733e-05\n",
            "Train loss: 0.7072031497955322\n",
            "\n",
            "Time (s): 0.5632383823394775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 4 / 499\n",
            "LR: 8.910206235802017e-05\n",
            "Train loss: 0.5450633764266968\n",
            "\n",
            "Time (s): 0.5661189556121826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 5 / 499\n",
            "LR: 8.910188126491717e-05\n",
            "Train loss: 0.7497311234474182\n",
            "\n",
            "Time (s): 0.5639288425445557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 6 / 499\n",
            "LR: 8.910170017291837e-05\n",
            "Train loss: 0.9462281465530396\n",
            "\n",
            "Time (s): 0.5681195259094238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 7 / 499\n",
            "LR: 8.910151908202369e-05\n",
            "Train loss: 0.4319309592247009\n",
            "\n",
            "Time (s): 0.564476490020752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 8 / 499\n",
            "LR: 8.91013379922332e-05\n",
            "Train loss: 0.5167514681816101\n",
            "\n",
            "Time (s): 0.5697612762451172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 9 / 499\n",
            "LR: 8.910115690354681e-05\n",
            "Train loss: 0.785947322845459\n",
            "\n",
            "Time (s): 0.5689833164215088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 10 / 499\n",
            "LR: 8.910097581596456e-05\n",
            "Train loss: 0.48834657669067383\n",
            "\n",
            "Time (s): 0.5724015235900879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 11 / 499\n",
            "LR: 8.910079472948641e-05\n",
            "Train loss: 0.7001001834869385\n",
            "\n",
            "Time (s): 0.5652120113372803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 12 / 499\n",
            "LR: 8.910061364411237e-05\n",
            "Train loss: 0.3430576026439667\n",
            "\n",
            "Time (s): 0.5687079429626465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 13 / 499\n",
            "LR: 8.910043255984241e-05\n",
            "Train loss: 0.7344292998313904\n",
            "\n",
            "Time (s): 0.571220874786377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 14 / 499\n",
            "LR: 8.910025147667656e-05\n",
            "Train loss: 1.0873584747314453\n",
            "\n",
            "Time (s): 0.567457914352417\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 15 / 499\n",
            "LR: 8.910007039461475e-05\n",
            "Train loss: 0.6422503590583801\n",
            "\n",
            "Time (s): 0.5725152492523193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 16 / 499\n",
            "LR: 8.909988931365701e-05\n",
            "Train loss: 1.3052712678909302\n",
            "\n",
            "Time (s): 0.568077802658081\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 17 / 499\n",
            "LR: 8.90997082338033e-05\n",
            "Train loss: 0.9455503821372986\n",
            "\n",
            "Time (s): 0.5738928318023682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 18 / 499\n",
            "LR: 8.909952715505364e-05\n",
            "Train loss: 1.0074093341827393\n",
            "\n",
            "Time (s): 0.5731790065765381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 19 / 499\n",
            "LR: 8.909934607740799e-05\n",
            "Train loss: 0.755398690700531\n",
            "\n",
            "Time (s): 0.5752487182617188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 20 / 499\n",
            "LR: 8.909916500086636e-05\n",
            "Train loss: 0.650434672832489\n",
            "\n",
            "Time (s): 0.569779634475708\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 21 / 499\n",
            "LR: 8.909898392542874e-05\n",
            "Train loss: 0.700566828250885\n",
            "\n",
            "Time (s): 0.5704185962677002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 22 / 499\n",
            "LR: 8.909880285109509e-05\n",
            "Train loss: 1.1800634860992432\n",
            "\n",
            "Time (s): 0.5740401744842529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 23 / 499\n",
            "LR: 8.909862177786542e-05\n",
            "Train loss: 0.36866986751556396\n",
            "\n",
            "Time (s): 0.57377028465271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 24 / 499\n",
            "LR: 8.909844070573973e-05\n",
            "Train loss: 1.1222959756851196\n",
            "\n",
            "Time (s): 0.568835973739624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 25 / 499\n",
            "LR: 8.909825963471797e-05\n",
            "Train loss: 0.994295060634613\n",
            "\n",
            "Time (s): 0.5776379108428955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 26 / 499\n",
            "LR: 8.90980785648002e-05\n",
            "Train loss: 0.652837872505188\n",
            "\n",
            "Time (s): 0.5751030445098877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 27 / 499\n",
            "LR: 8.909789749598633e-05\n",
            "Train loss: 0.9593526124954224\n",
            "\n",
            "Time (s): 0.5738847255706787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 28 / 499\n",
            "LR: 8.909771642827638e-05\n",
            "Train loss: 0.8128834366798401\n",
            "\n",
            "Time (s): 0.5756330490112305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 29 / 499\n",
            "LR: 8.909753536167038e-05\n",
            "Train loss: 1.1124110221862793\n",
            "\n",
            "Time (s): 0.571251630783081\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 30 / 499\n",
            "LR: 8.909735429616824e-05\n",
            "Train loss: 0.5281789302825928\n",
            "\n",
            "Time (s): 0.5756397247314453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 31 / 499\n",
            "LR: 8.909717323176998e-05\n",
            "Train loss: 0.5086319446563721\n",
            "\n",
            "Time (s): 0.5773451328277588\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 32 / 499\n",
            "LR: 8.909699216847562e-05\n",
            "Train loss: 1.8252636194229126\n",
            "\n",
            "Time (s): 0.580233097076416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 33 / 499\n",
            "LR: 8.909681110628513e-05\n",
            "Train loss: 0.6941159963607788\n",
            "\n",
            "Time (s): 0.5726587772369385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 34 / 499\n",
            "LR: 8.90966300451985e-05\n",
            "Train loss: 1.1782944202423096\n",
            "\n",
            "Time (s): 0.5752995014190674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 35 / 499\n",
            "LR: 8.90964489852157e-05\n",
            "Train loss: 0.7957447171211243\n",
            "\n",
            "Time (s): 0.5740132331848145\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 36 / 499\n",
            "LR: 8.909626792633672e-05\n",
            "Train loss: 0.922570526599884\n",
            "\n",
            "Time (s): 0.5773622989654541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 37 / 499\n",
            "LR: 8.909608686856158e-05\n",
            "Train loss: 0.7624176740646362\n",
            "\n",
            "Time (s): 0.579444169998169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 38 / 499\n",
            "LR: 8.909590581189024e-05\n",
            "Train loss: 1.275741696357727\n",
            "\n",
            "Time (s): 0.5786075592041016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 39 / 499\n",
            "LR: 8.90957247563227e-05\n",
            "Train loss: 0.7730952501296997\n",
            "\n",
            "Time (s): 0.580157995223999\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 40 / 499\n",
            "LR: 8.909554370185897e-05\n",
            "Train loss: 1.1860216856002808\n",
            "\n",
            "Time (s): 0.5737242698669434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 41 / 499\n",
            "LR: 8.909536264849899e-05\n",
            "Train loss: 0.8644882440567017\n",
            "\n",
            "Time (s): 0.5810110569000244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 42 / 499\n",
            "LR: 8.909518159624279e-05\n",
            "Train loss: 1.150719165802002\n",
            "\n",
            "Time (s): 0.5816237926483154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 43 / 499\n",
            "LR: 8.909500054509033e-05\n",
            "Train loss: 0.5461337566375732\n",
            "\n",
            "Time (s): 0.5787804126739502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 44 / 499\n",
            "LR: 8.909481949504162e-05\n",
            "Train loss: 0.6707189679145813\n",
            "\n",
            "Time (s): 0.5817415714263916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 45 / 499\n",
            "LR: 8.909463844609665e-05\n",
            "Train loss: 1.4365758895874023\n",
            "\n",
            "Time (s): 0.5753247737884521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 46 / 499\n",
            "LR: 8.909445739825538e-05\n",
            "Train loss: 0.5936581492424011\n",
            "\n",
            "Time (s): 0.5813026428222656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 47 / 499\n",
            "LR: 8.909427635151784e-05\n",
            "Train loss: 1.088971495628357\n",
            "\n",
            "Time (s): 0.5790717601776123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 48 / 499\n",
            "LR: 8.909409530588399e-05\n",
            "Train loss: 0.5662952065467834\n",
            "\n",
            "Time (s): 0.5745067596435547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 49 / 499\n",
            "LR: 8.909391426135383e-05\n",
            "Train loss: 0.8297398090362549\n",
            "\n",
            "Time (s): 0.5808823108673096\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 50 / 499\n",
            "LR: 8.909373321792734e-05\n",
            "Train loss: 0.9030212759971619\n",
            "\n",
            "Time (s): 0.5771539211273193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 51 / 499\n",
            "LR: 8.909355217560451e-05\n",
            "Train loss: 1.0050855875015259\n",
            "\n",
            "Time (s): 0.5824856758117676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 52 / 499\n",
            "LR: 8.909337113438535e-05\n",
            "Train loss: 0.7750892639160156\n",
            "\n",
            "Time (s): 0.5840473175048828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 53 / 499\n",
            "LR: 8.909319009426982e-05\n",
            "Train loss: 0.5722768306732178\n",
            "\n",
            "Time (s): 0.5853455066680908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 54 / 499\n",
            "LR: 8.909300905525791e-05\n",
            "Train loss: 0.8545594215393066\n",
            "\n",
            "Time (s): 0.5801317691802979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 55 / 499\n",
            "LR: 8.909282801734963e-05\n",
            "Train loss: 0.9332651495933533\n",
            "\n",
            "Time (s): 0.5850653648376465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 56 / 499\n",
            "LR: 8.909264698054495e-05\n",
            "Train loss: 1.1910496950149536\n",
            "\n",
            "Time (s): 0.585212230682373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 57 / 499\n",
            "LR: 8.90924659448439e-05\n",
            "Train loss: 0.891646683216095\n",
            "\n",
            "Time (s): 0.5812621116638184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 58 / 499\n",
            "LR: 8.90922849102464e-05\n",
            "Train loss: 0.6910864114761353\n",
            "\n",
            "Time (s): 0.5811715126037598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 59 / 499\n",
            "LR: 8.909210387675248e-05\n",
            "Train loss: 0.5647796988487244\n",
            "\n",
            "Time (s): 0.5838301181793213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 60 / 499\n",
            "LR: 8.909192284436213e-05\n",
            "Train loss: 0.7120703458786011\n",
            "\n",
            "Time (s): 0.5837740898132324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 61 / 499\n",
            "LR: 8.909174181307533e-05\n",
            "Train loss: 0.21538348495960236\n",
            "\n",
            "Time (s): 0.5870912075042725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 62 / 499\n",
            "LR: 8.909156078289206e-05\n",
            "Train loss: 0.8395458459854126\n",
            "\n",
            "Time (s): 0.5876874923706055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 63 / 499\n",
            "LR: 8.909137975381234e-05\n",
            "Train loss: 1.2079800367355347\n",
            "\n",
            "Time (s): 0.5880982875823975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 64 / 499\n",
            "LR: 8.909119872583614e-05\n",
            "Train loss: 1.0724310874938965\n",
            "\n",
            "Time (s): 0.586658239364624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 65 / 499\n",
            "LR: 8.909101769896343e-05\n",
            "Train loss: 1.1744619607925415\n",
            "\n",
            "Time (s): 0.5854501724243164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 66 / 499\n",
            "LR: 8.909083667319423e-05\n",
            "Train loss: 0.6997274160385132\n",
            "\n",
            "Time (s): 0.5837488174438477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 67 / 499\n",
            "LR: 8.909065564852849e-05\n",
            "Train loss: 0.72752845287323\n",
            "\n",
            "Time (s): 0.5887932777404785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 68 / 499\n",
            "LR: 8.909047462496627e-05\n",
            "Train loss: 0.4779447317123413\n",
            "\n",
            "Time (s): 0.5888547897338867\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 69 / 499\n",
            "LR: 8.909029360250748e-05\n",
            "Train loss: 0.8455252051353455\n",
            "\n",
            "Time (s): 0.5850813388824463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 70 / 499\n",
            "LR: 8.909011258115214e-05\n",
            "Train loss: 0.6927734017372131\n",
            "\n",
            "Time (s): 0.5890073776245117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 71 / 499\n",
            "LR: 8.908993156090024e-05\n",
            "Train loss: 1.0987333059310913\n",
            "\n",
            "Time (s): 0.5889265537261963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 72 / 499\n",
            "LR: 8.908975054175177e-05\n",
            "Train loss: 0.8968879580497742\n",
            "\n",
            "Time (s): 0.5873687267303467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 73 / 499\n",
            "LR: 8.908956952370672e-05\n",
            "Train loss: 0.9365512132644653\n",
            "\n",
            "Time (s): 0.5885529518127441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 74 / 499\n",
            "LR: 8.908938850676509e-05\n",
            "Train loss: 0.212106391787529\n",
            "\n",
            "Time (s): 0.5880475044250488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 75 / 499\n",
            "LR: 8.908920749092684e-05\n",
            "Train loss: 0.6507980227470398\n",
            "\n",
            "Time (s): 0.5925517082214355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 76 / 499\n",
            "LR: 8.908902647619198e-05\n",
            "Train loss: 0.8030245304107666\n",
            "\n",
            "Time (s): 0.5938720703125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 77 / 499\n",
            "LR: 8.90888454625605e-05\n",
            "Train loss: 0.9453567266464233\n",
            "\n",
            "Time (s): 0.5899498462677002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 78 / 499\n",
            "LR: 8.908866445003235e-05\n",
            "Train loss: 0.954567551612854\n",
            "\n",
            "Time (s): 0.5876858234405518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 79 / 499\n",
            "LR: 8.908848343860758e-05\n",
            "Train loss: 1.361976981163025\n",
            "\n",
            "Time (s): 0.5901923179626465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 80 / 499\n",
            "LR: 8.908830242828613e-05\n",
            "Train loss: 0.9334840178489685\n",
            "\n",
            "Time (s): 0.5922436714172363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 81 / 499\n",
            "LR: 8.908812141906804e-05\n",
            "Train loss: 1.7080527544021606\n",
            "\n",
            "Time (s): 0.5885376930236816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 82 / 499\n",
            "LR: 8.908794041095325e-05\n",
            "Train loss: 0.92760169506073\n",
            "\n",
            "Time (s): 0.5873572826385498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 83 / 499\n",
            "LR: 8.908775940394176e-05\n",
            "Train loss: 0.8884549140930176\n",
            "\n",
            "Time (s): 0.5921962261199951\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 84 / 499\n",
            "LR: 8.908757839803354e-05\n",
            "Train loss: 0.4214724898338318\n",
            "\n",
            "Time (s): 0.5997018814086914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 85 / 499\n",
            "LR: 8.908739739322863e-05\n",
            "Train loss: 0.791032075881958\n",
            "\n",
            "Time (s): 0.617835521697998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 86 / 499\n",
            "LR: 8.908721638952701e-05\n",
            "Train loss: 0.5975145697593689\n",
            "\n",
            "Time (s): 0.6278238296508789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 87 / 499\n",
            "LR: 8.908703538692863e-05\n",
            "Train loss: 0.9212709069252014\n",
            "\n",
            "Time (s): 0.6292271614074707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 88 / 499\n",
            "LR: 8.90868543854335e-05\n",
            "Train loss: 1.055479884147644\n",
            "\n",
            "Time (s): 0.6279418468475342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 89 / 499\n",
            "LR: 8.90866733850416e-05\n",
            "Train loss: 0.8103950023651123\n",
            "\n",
            "Time (s): 0.627784252166748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 90 / 499\n",
            "LR: 8.908649238575295e-05\n",
            "Train loss: 0.9999725818634033\n",
            "\n",
            "Time (s): 0.6284518241882324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 91 / 499\n",
            "LR: 8.908631138756749e-05\n",
            "Train loss: 0.6087452173233032\n",
            "\n",
            "Time (s): 0.6282286643981934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 92 / 499\n",
            "LR: 8.908613039048524e-05\n",
            "Train loss: 0.8794509768486023\n",
            "\n",
            "Time (s): 0.6288061141967773\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 93 / 499\n",
            "LR: 8.90859493945062e-05\n",
            "Train loss: 1.0490939617156982\n",
            "\n",
            "Time (s): 0.6280457973480225\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 94 / 499\n",
            "LR: 8.908576839963032e-05\n",
            "Train loss: 1.16020929813385\n",
            "\n",
            "Time (s): 0.627873420715332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 95 / 499\n",
            "LR: 8.908558740585763e-05\n",
            "Train loss: 1.1093014478683472\n",
            "\n",
            "Time (s): 0.628732442855835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 96 / 499\n",
            "LR: 8.908540641318809e-05\n",
            "Train loss: 0.7802303433418274\n",
            "\n",
            "Time (s): 0.6279442310333252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 97 / 499\n",
            "LR: 8.90852254216217e-05\n",
            "Train loss: 0.682485818862915\n",
            "\n",
            "Time (s): 0.6279630661010742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 98 / 499\n",
            "LR: 8.908504443115846e-05\n",
            "Train loss: 1.4947303533554077\n",
            "\n",
            "Time (s): 0.6237218379974365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 99 / 499\n",
            "LR: 8.908486344179831e-05\n",
            "Train loss: 1.0513997077941895\n",
            "\n",
            "Time (s): 0.6284763813018799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 100 / 499\n",
            "LR: 8.908468245354131e-05\n",
            "Train loss: 1.4309008121490479\n",
            "\n",
            "Time (s): 0.6240990161895752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 101 / 499\n",
            "LR: 8.90845014663874e-05\n",
            "Train loss: 1.4958961009979248\n",
            "\n",
            "Time (s): 0.6235723495483398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 102 / 499\n",
            "LR: 8.90843204803366e-05\n",
            "Train loss: 1.213354229927063\n",
            "\n",
            "Time (s): 0.6270632743835449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 103 / 499\n",
            "LR: 8.908413949538886e-05\n",
            "Train loss: 0.4643400311470032\n",
            "\n",
            "Time (s): 0.628709077835083\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 104 / 499\n",
            "LR: 8.908395851154421e-05\n",
            "Train loss: 0.8618800640106201\n",
            "\n",
            "Time (s): 0.6270201206207275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 105 / 499\n",
            "LR: 8.908377752880259e-05\n",
            "Train loss: 2.070533275604248\n",
            "\n",
            "Time (s): 0.6280431747436523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 106 / 499\n",
            "LR: 8.908359654716403e-05\n",
            "Train loss: 0.7680562734603882\n",
            "\n",
            "Time (s): 0.6287217140197754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 107 / 499\n",
            "LR: 8.908341556662851e-05\n",
            "Train loss: 0.5160035490989685\n",
            "\n",
            "Time (s): 0.6234467029571533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 108 / 499\n",
            "LR: 8.908323458719602e-05\n",
            "Train loss: 0.4035683274269104\n",
            "\n",
            "Time (s): 0.6236064434051514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 109 / 499\n",
            "LR: 8.908305360886656e-05\n",
            "Train loss: 0.22647663950920105\n",
            "\n",
            "Time (s): 0.6236176490783691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 110 / 499\n",
            "LR: 8.908287263164007e-05\n",
            "Train loss: 1.475695252418518\n",
            "\n",
            "Time (s): 0.6242215633392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 111 / 499\n",
            "LR: 8.908269165551659e-05\n",
            "Train loss: 1.3369396924972534\n",
            "\n",
            "Time (s): 0.6287908554077148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 112 / 499\n",
            "LR: 8.90825106804961e-05\n",
            "Train loss: 0.6370440721511841\n",
            "\n",
            "Time (s): 0.6289656162261963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 113 / 499\n",
            "LR: 8.908232970657854e-05\n",
            "Train loss: 0.32267487049102783\n",
            "\n",
            "Time (s): 0.6272616386413574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 114 / 499\n",
            "LR: 8.908214873376398e-05\n",
            "Train loss: 0.6946136355400085\n",
            "\n",
            "Time (s): 0.6237437725067139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 115 / 499\n",
            "LR: 8.908196776205235e-05\n",
            "Train loss: 0.7242463231086731\n",
            "\n",
            "Time (s): 0.6278927326202393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 116 / 499\n",
            "LR: 8.908178679144364e-05\n",
            "Train loss: 1.19688081741333\n",
            "\n",
            "Time (s): 0.6277322769165039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 117 / 499\n",
            "LR: 8.908160582193789e-05\n",
            "Train loss: 0.38761866092681885\n",
            "\n",
            "Time (s): 0.6244552135467529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 118 / 499\n",
            "LR: 8.908142485353503e-05\n",
            "Train loss: 0.7785457372665405\n",
            "\n",
            "Time (s): 0.629070520401001\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 119 / 499\n",
            "LR: 8.908124388623507e-05\n",
            "Train loss: 0.4910385310649872\n",
            "\n",
            "Time (s): 0.6275429725646973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 120 / 499\n",
            "LR: 8.9081062920038e-05\n",
            "Train loss: 1.3755664825439453\n",
            "\n",
            "Time (s): 0.6292214393615723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 121 / 499\n",
            "LR: 8.908088195494383e-05\n",
            "Train loss: 0.9453667402267456\n",
            "\n",
            "Time (s): 0.6243226528167725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 122 / 499\n",
            "LR: 8.908070099095251e-05\n",
            "Train loss: 0.6234074831008911\n",
            "\n",
            "Time (s): 0.6282405853271484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 123 / 499\n",
            "LR: 8.908052002806403e-05\n",
            "Train loss: 1.0573418140411377\n",
            "\n",
            "Time (s): 0.6281118392944336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 124 / 499\n",
            "LR: 8.908033906627844e-05\n",
            "Train loss: 0.6096149682998657\n",
            "\n",
            "Time (s): 0.6265823841094971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 125 / 499\n",
            "LR: 8.908015810559565e-05\n",
            "Train loss: 1.0111300945281982\n",
            "\n",
            "Time (s): 0.6287124156951904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 126 / 499\n",
            "LR: 8.907997714601569e-05\n",
            "Train loss: 0.34533408284187317\n",
            "\n",
            "Time (s): 0.6286280155181885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 127 / 499\n",
            "LR: 8.907979618753855e-05\n",
            "Train loss: 0.825965166091919\n",
            "\n",
            "Time (s): 0.6285080909729004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 128 / 499\n",
            "LR: 8.907961523016422e-05\n",
            "Train loss: 0.39697909355163574\n",
            "\n",
            "Time (s): 0.6238582134246826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 129 / 499\n",
            "LR: 8.907943427389266e-05\n",
            "Train loss: 1.1969228982925415\n",
            "\n",
            "Time (s): 0.6290304660797119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 130 / 499\n",
            "LR: 8.90792533187239e-05\n",
            "Train loss: 1.3259849548339844\n",
            "\n",
            "Time (s): 0.6288676261901855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 131 / 499\n",
            "LR: 8.907907236465789e-05\n",
            "Train loss: 0.35388994216918945\n",
            "\n",
            "Time (s): 0.6283080577850342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 132 / 499\n",
            "LR: 8.907889141169464e-05\n",
            "Train loss: 0.7651459574699402\n",
            "\n",
            "Time (s): 0.6262497901916504\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 133 / 499\n",
            "LR: 8.907871045983414e-05\n",
            "Train loss: 1.3329358100891113\n",
            "\n",
            "Time (s): 0.6241011619567871\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 134 / 499\n",
            "LR: 8.907852950907637e-05\n",
            "Train loss: 0.7943441271781921\n",
            "\n",
            "Time (s): 0.6290297508239746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 135 / 499\n",
            "LR: 8.907834855942132e-05\n",
            "Train loss: 1.078469157218933\n",
            "\n",
            "Time (s): 0.6286964416503906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 136 / 499\n",
            "LR: 8.907816761086901e-05\n",
            "Train loss: 1.7609422206878662\n",
            "\n",
            "Time (s): 0.6293766498565674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 137 / 499\n",
            "LR: 8.907798666341937e-05\n",
            "Train loss: 0.716452956199646\n",
            "\n",
            "Time (s): 0.6298229694366455\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 138 / 499\n",
            "LR: 8.907780571707242e-05\n",
            "Train loss: 1.369431972503662\n",
            "\n",
            "Time (s): 0.6256623268127441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 139 / 499\n",
            "LR: 8.907762477182816e-05\n",
            "Train loss: 0.32071834802627563\n",
            "\n",
            "Time (s): 0.6241426467895508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 140 / 499\n",
            "LR: 8.907744382768657e-05\n",
            "Train loss: 1.1092255115509033\n",
            "\n",
            "Time (s): 0.6238865852355957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 141 / 499\n",
            "LR: 8.907726288464762e-05\n",
            "Train loss: 0.9846037030220032\n",
            "\n",
            "Time (s): 0.6242680549621582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 142 / 499\n",
            "LR: 8.907708194271133e-05\n",
            "Train loss: 0.9200797080993652\n",
            "\n",
            "Time (s): 0.628241777420044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 143 / 499\n",
            "LR: 8.907690100187767e-05\n",
            "Train loss: 0.23835152387619019\n",
            "\n",
            "Time (s): 0.6288557052612305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 144 / 499\n",
            "LR: 8.907672006214663e-05\n",
            "Train loss: 0.5236414074897766\n",
            "\n",
            "Time (s): 0.628896951675415\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 145 / 499\n",
            "LR: 8.907653912351818e-05\n",
            "Train loss: 0.8625271916389465\n",
            "\n",
            "Time (s): 0.6281173229217529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 146 / 499\n",
            "LR: 8.907635818599234e-05\n",
            "Train loss: 1.163865566253662\n",
            "\n",
            "Time (s): 0.6279213428497314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 147 / 499\n",
            "LR: 8.90761772495691e-05\n",
            "Train loss: 0.7968485951423645\n",
            "\n",
            "Time (s): 0.629075288772583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 148 / 499\n",
            "LR: 8.907599631424843e-05\n",
            "Train loss: 0.5926863551139832\n",
            "\n",
            "Time (s): 0.6278254985809326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 149 / 499\n",
            "LR: 8.907581538003034e-05\n",
            "Train loss: 0.5500630736351013\n",
            "\n",
            "Time (s): 0.6232404708862305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 150 / 499\n",
            "LR: 8.907563444691479e-05\n",
            "Train loss: 0.37744662165641785\n",
            "\n",
            "Time (s): 0.628556489944458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 151 / 499\n",
            "LR: 8.907545351490179e-05\n",
            "Train loss: 1.2636903524398804\n",
            "\n",
            "Time (s): 0.6283893585205078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 152 / 499\n",
            "LR: 8.907527258399132e-05\n",
            "Train loss: 0.5985069274902344\n",
            "\n",
            "Time (s): 0.6241598129272461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 153 / 499\n",
            "LR: 8.907509165418337e-05\n",
            "Train loss: 0.6346392035484314\n",
            "\n",
            "Time (s): 0.6289558410644531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 154 / 499\n",
            "LR: 8.907491072547794e-05\n",
            "Train loss: 0.5168216824531555\n",
            "\n",
            "Time (s): 0.6294569969177246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 155 / 499\n",
            "LR: 8.907472979787499e-05\n",
            "Train loss: 0.5886311531066895\n",
            "\n",
            "Time (s): 0.6235766410827637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 156 / 499\n",
            "LR: 8.907454887137455e-05\n",
            "Train loss: 0.6524234414100647\n",
            "\n",
            "Time (s): 0.627960205078125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 157 / 499\n",
            "LR: 8.907436794597657e-05\n",
            "Train loss: 0.9977643489837646\n",
            "\n",
            "Time (s): 0.6236979961395264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 158 / 499\n",
            "LR: 8.907418702168107e-05\n",
            "Train loss: 0.9667314887046814\n",
            "\n",
            "Time (s): 0.62532639503479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 159 / 499\n",
            "LR: 8.907400609848802e-05\n",
            "Train loss: 0.6221426129341125\n",
            "\n",
            "Time (s): 0.6272878646850586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 160 / 499\n",
            "LR: 8.907382517639738e-05\n",
            "Train loss: 0.8662667870521545\n",
            "\n",
            "Time (s): 0.6244473457336426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 161 / 499\n",
            "LR: 8.907364425540921e-05\n",
            "Train loss: 0.7557374238967896\n",
            "\n",
            "Time (s): 0.6285061836242676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 162 / 499\n",
            "LR: 8.907346333552345e-05\n",
            "Train loss: 1.1502923965454102\n",
            "\n",
            "Time (s): 0.6286132335662842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 163 / 499\n",
            "LR: 8.90732824167401e-05\n",
            "Train loss: 1.2080039978027344\n",
            "\n",
            "Time (s): 0.6277611255645752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 164 / 499\n",
            "LR: 8.907310149905915e-05\n",
            "Train loss: 0.853648841381073\n",
            "\n",
            "Time (s): 0.6278691291809082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 165 / 499\n",
            "LR: 8.90729205824806e-05\n",
            "Train loss: 1.3756556510925293\n",
            "\n",
            "Time (s): 0.6277143955230713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 166 / 499\n",
            "LR: 8.907273966700441e-05\n",
            "Train loss: 1.0521950721740723\n",
            "\n",
            "Time (s): 0.6235857009887695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 167 / 499\n",
            "LR: 8.907255875263057e-05\n",
            "Train loss: 0.46663397550582886\n",
            "\n",
            "Time (s): 0.6282868385314941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 168 / 499\n",
            "LR: 8.90723778393591e-05\n",
            "Train loss: 1.1091383695602417\n",
            "\n",
            "Time (s): 0.6235201358795166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 169 / 499\n",
            "LR: 8.907219692718994e-05\n",
            "Train loss: 0.7167282104492188\n",
            "\n",
            "Time (s): 0.6276586055755615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 170 / 499\n",
            "LR: 8.907201601612316e-05\n",
            "Train loss: 1.005531907081604\n",
            "\n",
            "Time (s): 0.6275172233581543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 171 / 499\n",
            "LR: 8.907183510615868e-05\n",
            "Train loss: 0.6844967007637024\n",
            "\n",
            "Time (s): 0.6252670288085938\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 172 / 499\n",
            "LR: 8.907165419729652e-05\n",
            "Train loss: 1.0011094808578491\n",
            "\n",
            "Time (s): 0.6289181709289551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 173 / 499\n",
            "LR: 8.907147328953665e-05\n",
            "Train loss: 0.7639954090118408\n",
            "\n",
            "Time (s): 0.629199743270874\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 174 / 499\n",
            "LR: 8.907129238287906e-05\n",
            "Train loss: 1.1885173320770264\n",
            "\n",
            "Time (s): 0.6239721775054932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 175 / 499\n",
            "LR: 8.907111147732373e-05\n",
            "Train loss: 1.1657551527023315\n",
            "\n",
            "Time (s): 0.6287879943847656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 176 / 499\n",
            "LR: 8.907093057287069e-05\n",
            "Train loss: 0.7004058957099915\n",
            "\n",
            "Time (s): 0.6282598972320557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 177 / 499\n",
            "LR: 8.90707496695199e-05\n",
            "Train loss: 0.8308181762695312\n",
            "\n",
            "Time (s): 0.6291985511779785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 178 / 499\n",
            "LR: 8.907056876727134e-05\n",
            "Train loss: 1.1230041980743408\n",
            "\n",
            "Time (s): 0.6269960403442383\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 179 / 499\n",
            "LR: 8.907038786612501e-05\n",
            "Train loss: 0.9852287769317627\n",
            "\n",
            "Time (s): 0.623058557510376\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 180 / 499\n",
            "LR: 8.907020696608091e-05\n",
            "Train loss: 0.6595637798309326\n",
            "\n",
            "Time (s): 0.6232149600982666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 181 / 499\n",
            "LR: 8.907002606713903e-05\n",
            "Train loss: 0.9838986992835999\n",
            "\n",
            "Time (s): 0.6233584880828857\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 182 / 499\n",
            "LR: 8.906984516929932e-05\n",
            "Train loss: 1.4745475053787231\n",
            "\n",
            "Time (s): 0.6277081966400146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 183 / 499\n",
            "LR: 8.906966427256181e-05\n",
            "Train loss: 1.07072114944458\n",
            "\n",
            "Time (s): 0.6274101734161377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 184 / 499\n",
            "LR: 8.906948337692647e-05\n",
            "Train loss: 0.9525414109230042\n",
            "\n",
            "Time (s): 0.6281383037567139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 185 / 499\n",
            "LR: 8.906930248239328e-05\n",
            "Train loss: 0.34925979375839233\n",
            "\n",
            "Time (s): 0.6267790794372559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 186 / 499\n",
            "LR: 8.906912158896226e-05\n",
            "Train loss: 0.9010713696479797\n",
            "\n",
            "Time (s): 0.6279892921447754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 187 / 499\n",
            "LR: 8.906894069663338e-05\n",
            "Train loss: 0.6511232256889343\n",
            "\n",
            "Time (s): 0.6230711936950684\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 188 / 499\n",
            "LR: 8.906875980540662e-05\n",
            "Train loss: 0.7615405917167664\n",
            "\n",
            "Time (s): 0.6281249523162842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 189 / 499\n",
            "LR: 8.906857891528197e-05\n",
            "Train loss: 0.3940628468990326\n",
            "\n",
            "Time (s): 0.6275308132171631\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 190 / 499\n",
            "LR: 8.906839802625945e-05\n",
            "Train loss: 0.6468929052352905\n",
            "\n",
            "Time (s): 0.6268706321716309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 191 / 499\n",
            "LR: 8.9068217138339e-05\n",
            "Train loss: 0.7274780869483948\n",
            "\n",
            "Time (s): 0.6261272430419922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 192 / 499\n",
            "LR: 8.906803625152066e-05\n",
            "Train loss: 0.776595413684845\n",
            "\n",
            "Time (s): 0.626168966293335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 193 / 499\n",
            "LR: 8.906785536580438e-05\n",
            "Train loss: 0.8578200340270996\n",
            "\n",
            "Time (s): 0.6255612373352051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 194 / 499\n",
            "LR: 8.906767448119017e-05\n",
            "Train loss: 0.7447173595428467\n",
            "\n",
            "Time (s): 0.6283886432647705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 195 / 499\n",
            "LR: 8.906749359767801e-05\n",
            "Train loss: 0.768422544002533\n",
            "\n",
            "Time (s): 0.6281304359436035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 196 / 499\n",
            "LR: 8.906731271526789e-05\n",
            "Train loss: 0.4427100419998169\n",
            "\n",
            "Time (s): 0.6248388290405273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 197 / 499\n",
            "LR: 8.90671318339598e-05\n",
            "Train loss: 0.8926254510879517\n",
            "\n",
            "Time (s): 0.6234374046325684\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 198 / 499\n",
            "LR: 8.906695095375372e-05\n",
            "Train loss: 0.6216614842414856\n",
            "\n",
            "Time (s): 0.6284229755401611\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 199 / 499\n",
            "LR: 8.906677007464964e-05\n",
            "Train loss: 0.5972226858139038\n",
            "\n",
            "Time (s): 0.6277616024017334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 200 / 499\n",
            "LR: 8.906658919664756e-05\n",
            "Train loss: 1.2274609804153442\n",
            "\n",
            "Time (s): 0.6234982013702393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 201 / 499\n",
            "LR: 8.906640831974747e-05\n",
            "Train loss: 0.7712215781211853\n",
            "\n",
            "Time (s): 0.6277816295623779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 202 / 499\n",
            "LR: 8.906622744394937e-05\n",
            "Train loss: 0.598151683807373\n",
            "\n",
            "Time (s): 0.6285510063171387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 203 / 499\n",
            "LR: 8.90660465692532e-05\n",
            "Train loss: 0.6726318001747131\n",
            "\n",
            "Time (s): 0.6252110004425049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 204 / 499\n",
            "LR: 8.9065865695659e-05\n",
            "Train loss: 0.6173893809318542\n",
            "\n",
            "Time (s): 0.627629280090332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 205 / 499\n",
            "LR: 8.906568482316674e-05\n",
            "Train loss: 0.5755834579467773\n",
            "\n",
            "Time (s): 0.6236908435821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 206 / 499\n",
            "LR: 8.90655039517764e-05\n",
            "Train loss: 0.464227557182312\n",
            "\n",
            "Time (s): 0.6235842704772949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 207 / 499\n",
            "LR: 8.906532308148797e-05\n",
            "Train loss: 0.8089265823364258\n",
            "\n",
            "Time (s): 0.6282634735107422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 208 / 499\n",
            "LR: 8.906514221230145e-05\n",
            "Train loss: 0.4244893193244934\n",
            "\n",
            "Time (s): 0.6263794898986816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 209 / 499\n",
            "LR: 8.906496134421682e-05\n",
            "Train loss: 0.948677122592926\n",
            "\n",
            "Time (s): 0.6273350715637207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 210 / 499\n",
            "LR: 8.906478047723411e-05\n",
            "Train loss: 0.7112756371498108\n",
            "\n",
            "Time (s): 0.6281986236572266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 211 / 499\n",
            "LR: 8.906459961135323e-05\n",
            "Train loss: 0.9381198883056641\n",
            "\n",
            "Time (s): 0.6281383037567139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 212 / 499\n",
            "LR: 8.906441874657423e-05\n",
            "Train loss: 1.1632733345031738\n",
            "\n",
            "Time (s): 0.6281626224517822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 213 / 499\n",
            "LR: 8.906423788289708e-05\n",
            "Train loss: 0.16076666116714478\n",
            "\n",
            "Time (s): 0.6284809112548828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 214 / 499\n",
            "LR: 8.906405702032175e-05\n",
            "Train loss: 0.61121666431427\n",
            "\n",
            "Time (s): 0.6278009414672852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 215 / 499\n",
            "LR: 8.906387615884827e-05\n",
            "Train loss: 0.3186134696006775\n",
            "\n",
            "Time (s): 0.6275625228881836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 216 / 499\n",
            "LR: 8.906369529847659e-05\n",
            "Train loss: 1.4185431003570557\n",
            "\n",
            "Time (s): 0.6237266063690186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 217 / 499\n",
            "LR: 8.906351443920671e-05\n",
            "Train loss: 0.48127761483192444\n",
            "\n",
            "Time (s): 0.6236920356750488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 218 / 499\n",
            "LR: 8.906333358103864e-05\n",
            "Train loss: 0.7952408790588379\n",
            "\n",
            "Time (s): 0.6283605098724365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 219 / 499\n",
            "LR: 8.906315272397234e-05\n",
            "Train loss: 0.980619490146637\n",
            "\n",
            "Time (s): 0.6235806941986084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 220 / 499\n",
            "LR: 8.906297186800783e-05\n",
            "Train loss: 0.8300003409385681\n",
            "\n",
            "Time (s): 0.6276285648345947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 221 / 499\n",
            "LR: 8.906279101314506e-05\n",
            "Train loss: 0.3218567669391632\n",
            "\n",
            "Time (s): 0.6250979900360107\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 222 / 499\n",
            "LR: 8.906261015938406e-05\n",
            "Train loss: 1.1603249311447144\n",
            "\n",
            "Time (s): 0.6239187717437744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 223 / 499\n",
            "LR: 8.90624293067248e-05\n",
            "Train loss: 0.9023188948631287\n",
            "\n",
            "Time (s): 0.6270477771759033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 224 / 499\n",
            "LR: 8.906224845516723e-05\n",
            "Train loss: 0.8233468532562256\n",
            "\n",
            "Time (s): 0.6276636123657227\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 225 / 499\n",
            "LR: 8.906206760471142e-05\n",
            "Train loss: 0.910963773727417\n",
            "\n",
            "Time (s): 0.6271591186523438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 226 / 499\n",
            "LR: 8.906188675535727e-05\n",
            "Train loss: 0.9678573608398438\n",
            "\n",
            "Time (s): 0.6278810501098633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 227 / 499\n",
            "LR: 8.906170590710484e-05\n",
            "Train loss: 1.463867425918579\n",
            "\n",
            "Time (s): 0.6289045810699463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 228 / 499\n",
            "LR: 8.906152505995409e-05\n",
            "Train loss: 1.0451605319976807\n",
            "\n",
            "Time (s): 0.6241607666015625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 229 / 499\n",
            "LR: 8.906134421390501e-05\n",
            "Train loss: 0.5451260805130005\n",
            "\n",
            "Time (s): 0.6234879493713379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 230 / 499\n",
            "LR: 8.90611633689576e-05\n",
            "Train loss: 0.6505212187767029\n",
            "\n",
            "Time (s): 0.6276602745056152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 231 / 499\n",
            "LR: 8.906098252511181e-05\n",
            "Train loss: 0.6264536380767822\n",
            "\n",
            "Time (s): 0.6286067962646484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 232 / 499\n",
            "LR: 8.906080168236768e-05\n",
            "Train loss: 0.7811983227729797\n",
            "\n",
            "Time (s): 0.6284101009368896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 233 / 499\n",
            "LR: 8.906062084072516e-05\n",
            "Train loss: 0.8621413111686707\n",
            "\n",
            "Time (s): 0.6276633739471436\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 234 / 499\n",
            "LR: 8.906044000018428e-05\n",
            "Train loss: 0.7532795667648315\n",
            "\n",
            "Time (s): 0.6235888004302979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 235 / 499\n",
            "LR: 8.906025916074498e-05\n",
            "Train loss: 0.8339264392852783\n",
            "\n",
            "Time (s): 0.6278231143951416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 236 / 499\n",
            "LR: 8.90600783224073e-05\n",
            "Train loss: 1.2454465627670288\n",
            "\n",
            "Time (s): 0.6269781589508057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 237 / 499\n",
            "LR: 8.905989748517117e-05\n",
            "Train loss: 0.8220189809799194\n",
            "\n",
            "Time (s): 0.6280667781829834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 238 / 499\n",
            "LR: 8.905971664903663e-05\n",
            "Train loss: 0.8143837451934814\n",
            "\n",
            "Time (s): 0.6277415752410889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 239 / 499\n",
            "LR: 8.905953581400363e-05\n",
            "Train loss: 0.8758341670036316\n",
            "\n",
            "Time (s): 0.6281712055206299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 240 / 499\n",
            "LR: 8.90593549800722e-05\n",
            "Train loss: 0.9788126349449158\n",
            "\n",
            "Time (s): 0.6275885105133057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 241 / 499\n",
            "LR: 8.905917414724228e-05\n",
            "Train loss: 0.21602407097816467\n",
            "\n",
            "Time (s): 0.6293473243713379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 242 / 499\n",
            "LR: 8.905899331551391e-05\n",
            "Train loss: 0.9258410930633545\n",
            "\n",
            "Time (s): 0.6294395923614502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 243 / 499\n",
            "LR: 8.905881248488704e-05\n",
            "Train loss: 0.657691478729248\n",
            "\n",
            "Time (s): 0.6288785934448242\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 244 / 499\n",
            "LR: 8.905863165536168e-05\n",
            "Train loss: 1.377813696861267\n",
            "\n",
            "Time (s): 0.6289312839508057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 245 / 499\n",
            "LR: 8.905845082693782e-05\n",
            "Train loss: 1.0835025310516357\n",
            "\n",
            "Time (s): 0.627758264541626\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 246 / 499\n",
            "LR: 8.905826999961543e-05\n",
            "Train loss: 1.0395290851593018\n",
            "\n",
            "Time (s): 0.6287500858306885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 247 / 499\n",
            "LR: 8.90580891733945e-05\n",
            "Train loss: 1.871758222579956\n",
            "\n",
            "Time (s): 0.6298649311065674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 248 / 499\n",
            "LR: 8.905790834827504e-05\n",
            "Train loss: 0.8513162732124329\n",
            "\n",
            "Time (s): 0.628955602645874\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 249 / 499\n",
            "LR: 8.905772752425704e-05\n",
            "Train loss: 0.37512078881263733\n",
            "\n",
            "Time (s): 0.6273581981658936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 250 / 499\n",
            "LR: 8.905754670134046e-05\n",
            "Train loss: 0.7983614802360535\n",
            "\n",
            "Time (s): 0.6293151378631592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 251 / 499\n",
            "LR: 8.90573658795253e-05\n",
            "Train loss: 0.4853924810886383\n",
            "\n",
            "Time (s): 0.6292023658752441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 252 / 499\n",
            "LR: 8.905718505881156e-05\n",
            "Train loss: 1.1298614740371704\n",
            "\n",
            "Time (s): 0.6277916431427002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 253 / 499\n",
            "LR: 8.905700423919921e-05\n",
            "Train loss: 0.4683634638786316\n",
            "\n",
            "Time (s): 0.6287736892700195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 254 / 499\n",
            "LR: 8.905682342068826e-05\n",
            "Train loss: 0.9609163403511047\n",
            "\n",
            "Time (s): 0.628807783126831\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 255 / 499\n",
            "LR: 8.90566426032787e-05\n",
            "Train loss: 1.1540493965148926\n",
            "\n",
            "Time (s): 0.6276504993438721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 256 / 499\n",
            "LR: 8.90564617869705e-05\n",
            "Train loss: 1.3738008737564087\n",
            "\n",
            "Time (s): 0.6279208660125732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 257 / 499\n",
            "LR: 8.905628097176367e-05\n",
            "Train loss: 0.6124038696289062\n",
            "\n",
            "Time (s): 0.6276388168334961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 258 / 499\n",
            "LR: 8.905610015765816e-05\n",
            "Train loss: 0.6696428060531616\n",
            "\n",
            "Time (s): 0.6283066272735596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 259 / 499\n",
            "LR: 8.9055919344654e-05\n",
            "Train loss: 1.0566930770874023\n",
            "\n",
            "Time (s): 0.6292910575866699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 260 / 499\n",
            "LR: 8.905573853275118e-05\n",
            "Train loss: 0.47083351016044617\n",
            "\n",
            "Time (s): 0.6294906139373779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 261 / 499\n",
            "LR: 8.905555772194966e-05\n",
            "Train loss: 1.450972318649292\n",
            "\n",
            "Time (s): 0.6282401084899902\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 262 / 499\n",
            "LR: 8.905537691224944e-05\n",
            "Train loss: 0.6013926863670349\n",
            "\n",
            "Time (s): 0.6269383430480957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 263 / 499\n",
            "LR: 8.905519610365052e-05\n",
            "Train loss: 1.153002142906189\n",
            "\n",
            "Time (s): 0.6282389163970947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 264 / 499\n",
            "LR: 8.905501529615285e-05\n",
            "Train loss: 1.1900415420532227\n",
            "\n",
            "Time (s): 0.6278340816497803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 265 / 499\n",
            "LR: 8.905483448975648e-05\n",
            "Train loss: 0.6827404499053955\n",
            "\n",
            "Time (s): 0.628868579864502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 266 / 499\n",
            "LR: 8.905465368446134e-05\n",
            "Train loss: 0.7663077712059021\n",
            "\n",
            "Time (s): 0.6276438236236572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 267 / 499\n",
            "LR: 8.905447288026747e-05\n",
            "Train loss: 0.6561782956123352\n",
            "\n",
            "Time (s): 0.628819465637207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 268 / 499\n",
            "LR: 8.905429207717482e-05\n",
            "Train loss: 1.0570834875106812\n",
            "\n",
            "Time (s): 0.6274824142456055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 269 / 499\n",
            "LR: 8.905411127518341e-05\n",
            "Train loss: 0.7842168807983398\n",
            "\n",
            "Time (s): 0.6240549087524414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 270 / 499\n",
            "LR: 8.90539304742932e-05\n",
            "Train loss: 0.5515384078025818\n",
            "\n",
            "Time (s): 0.6274063587188721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 271 / 499\n",
            "LR: 8.905374967450419e-05\n",
            "Train loss: 0.6732982397079468\n",
            "\n",
            "Time (s): 0.6242430210113525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 272 / 499\n",
            "LR: 8.905356887581638e-05\n",
            "Train loss: 0.5807119011878967\n",
            "\n",
            "Time (s): 0.6233501434326172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 273 / 499\n",
            "LR: 8.905338807822974e-05\n",
            "Train loss: 0.6375564932823181\n",
            "\n",
            "Time (s): 0.627753734588623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 274 / 499\n",
            "LR: 8.905320728174426e-05\n",
            "Train loss: 0.6235983967781067\n",
            "\n",
            "Time (s): 0.6304419040679932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 275 / 499\n",
            "LR: 8.905302648635996e-05\n",
            "Train loss: 1.3276265859603882\n",
            "\n",
            "Time (s): 0.6277515888214111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 276 / 499\n",
            "LR: 8.905284569207677e-05\n",
            "Train loss: 0.43771007657051086\n",
            "\n",
            "Time (s): 0.6290757656097412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 277 / 499\n",
            "LR: 8.905266489889476e-05\n",
            "Train loss: 1.2651662826538086\n",
            "\n",
            "Time (s): 0.6325421333312988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 278 / 499\n",
            "LR: 8.905248410681384e-05\n",
            "Train loss: 0.47562992572784424\n",
            "\n",
            "Time (s): 0.6296875476837158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 279 / 499\n",
            "LR: 8.905230331583404e-05\n",
            "Train loss: 0.8685252666473389\n",
            "\n",
            "Time (s): 0.6284499168395996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 280 / 499\n",
            "LR: 8.905212252595534e-05\n",
            "Train loss: 0.7348243594169617\n",
            "\n",
            "Time (s): 0.6281757354736328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 281 / 499\n",
            "LR: 8.905194173717773e-05\n",
            "Train loss: 0.5064079761505127\n",
            "\n",
            "Time (s): 0.6283309459686279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 282 / 499\n",
            "LR: 8.905176094950119e-05\n",
            "Train loss: 0.6885498762130737\n",
            "\n",
            "Time (s): 0.6297354698181152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 283 / 499\n",
            "LR: 8.905158016292571e-05\n",
            "Train loss: 0.5570067763328552\n",
            "\n",
            "Time (s): 0.6276950836181641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 284 / 499\n",
            "LR: 8.905139937745132e-05\n",
            "Train loss: 1.1756869554519653\n",
            "\n",
            "Time (s): 0.6291544437408447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 285 / 499\n",
            "LR: 8.905121859307794e-05\n",
            "Train loss: 0.888762354850769\n",
            "\n",
            "Time (s): 0.6272411346435547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 286 / 499\n",
            "LR: 8.905103780980562e-05\n",
            "Train loss: 0.6284279823303223\n",
            "\n",
            "Time (s): 0.6322810649871826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 287 / 499\n",
            "LR: 8.905085702763431e-05\n",
            "Train loss: 0.4138016104698181\n",
            "\n",
            "Time (s): 0.6296663284301758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 288 / 499\n",
            "LR: 8.9050676246564e-05\n",
            "Train loss: 1.1046091318130493\n",
            "\n",
            "Time (s): 0.6285009384155273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 289 / 499\n",
            "LR: 8.905049546659471e-05\n",
            "Train loss: 0.930254340171814\n",
            "\n",
            "Time (s): 0.6296348571777344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 290 / 499\n",
            "LR: 8.905031468772641e-05\n",
            "Train loss: 0.4696405231952667\n",
            "\n",
            "Time (s): 0.6281540393829346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 291 / 499\n",
            "LR: 8.905013390995907e-05\n",
            "Train loss: 0.6732503175735474\n",
            "\n",
            "Time (s): 0.6277971267700195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 292 / 499\n",
            "LR: 8.90499531332927e-05\n",
            "Train loss: 0.6674447655677795\n",
            "\n",
            "Time (s): 0.6287922859191895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 293 / 499\n",
            "LR: 8.904977235772729e-05\n",
            "Train loss: 0.5140386819839478\n",
            "\n",
            "Time (s): 0.6280922889709473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 294 / 499\n",
            "LR: 8.904959158326284e-05\n",
            "Train loss: 0.8211967349052429\n",
            "\n",
            "Time (s): 0.6295003890991211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 295 / 499\n",
            "LR: 8.904941080989929e-05\n",
            "Train loss: 1.1764787435531616\n",
            "\n",
            "Time (s): 0.6294617652893066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 296 / 499\n",
            "LR: 8.904923003763668e-05\n",
            "Train loss: 1.1727933883666992\n",
            "\n",
            "Time (s): 0.6272497177124023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 297 / 499\n",
            "LR: 8.904904926647498e-05\n",
            "Train loss: 0.9370815753936768\n",
            "\n",
            "Time (s): 0.6291236877441406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 298 / 499\n",
            "LR: 8.904886849641418e-05\n",
            "Train loss: 0.8450131416320801\n",
            "\n",
            "Time (s): 0.6290624141693115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 299 / 499\n",
            "LR: 8.904868772745425e-05\n",
            "Train loss: 1.2060941457748413\n",
            "\n",
            "Time (s): 0.6293103694915771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 300 / 499\n",
            "LR: 8.904850695959521e-05\n",
            "Train loss: 1.5673010349273682\n",
            "\n",
            "Time (s): 0.6298866271972656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 301 / 499\n",
            "LR: 8.904832619283706e-05\n",
            "Train loss: 0.369113564491272\n",
            "\n",
            "Time (s): 0.6306807994842529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 302 / 499\n",
            "LR: 8.904814542717973e-05\n",
            "Train loss: 0.8111468553543091\n",
            "\n",
            "Time (s): 0.6274588108062744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 303 / 499\n",
            "LR: 8.904796466262328e-05\n",
            "Train loss: 0.5481858253479004\n",
            "\n",
            "Time (s): 0.6285266876220703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 304 / 499\n",
            "LR: 8.904778389916763e-05\n",
            "Train loss: 0.5706896185874939\n",
            "\n",
            "Time (s): 0.6284739971160889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 305 / 499\n",
            "LR: 8.904760313681282e-05\n",
            "Train loss: 0.8305942416191101\n",
            "\n",
            "Time (s): 0.6236593723297119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 306 / 499\n",
            "LR: 8.904742237555881e-05\n",
            "Train loss: 0.7464367747306824\n",
            "\n",
            "Time (s): 0.6290760040283203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 307 / 499\n",
            "LR: 8.90472416154056e-05\n",
            "Train loss: 0.7560164332389832\n",
            "\n",
            "Time (s): 0.6279406547546387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 308 / 499\n",
            "LR: 8.904706085635316e-05\n",
            "Train loss: 1.021801233291626\n",
            "\n",
            "Time (s): 0.6283142566680908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 309 / 499\n",
            "LR: 8.904688009840152e-05\n",
            "Train loss: 0.7419836521148682\n",
            "\n",
            "Time (s): 0.6289117336273193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 310 / 499\n",
            "LR: 8.904669934155064e-05\n",
            "Train loss: 0.5529224276542664\n",
            "\n",
            "Time (s): 0.6291306018829346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 311 / 499\n",
            "LR: 8.904651858580051e-05\n",
            "Train loss: 0.5373914837837219\n",
            "\n",
            "Time (s): 0.6297943592071533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 312 / 499\n",
            "LR: 8.904633783115113e-05\n",
            "Train loss: 0.7151247262954712\n",
            "\n",
            "Time (s): 0.6261122226715088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 313 / 499\n",
            "LR: 8.904615707760246e-05\n",
            "Train loss: 0.6789839267730713\n",
            "\n",
            "Time (s): 0.6298971176147461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 314 / 499\n",
            "LR: 8.904597632515455e-05\n",
            "Train loss: 1.008305549621582\n",
            "\n",
            "Time (s): 0.6239466667175293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 315 / 499\n",
            "LR: 8.904579557380733e-05\n",
            "Train loss: 0.4460740387439728\n",
            "\n",
            "Time (s): 0.6275386810302734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 316 / 499\n",
            "LR: 8.90456148235608e-05\n",
            "Train loss: 0.5904909372329712\n",
            "\n",
            "Time (s): 0.6296157836914062\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 317 / 499\n",
            "LR: 8.904543407441496e-05\n",
            "Train loss: 0.5930106043815613\n",
            "\n",
            "Time (s): 0.6240248680114746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 318 / 499\n",
            "LR: 8.904525332636981e-05\n",
            "Train loss: 0.47476285696029663\n",
            "\n",
            "Time (s): 0.6281964778900146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 319 / 499\n",
            "LR: 8.904507257942531e-05\n",
            "Train loss: 1.0275541543960571\n",
            "\n",
            "Time (s): 0.6272900104522705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 320 / 499\n",
            "LR: 8.904489183358147e-05\n",
            "Train loss: 0.5694647431373596\n",
            "\n",
            "Time (s): 0.6287472248077393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 321 / 499\n",
            "LR: 8.904471108883825e-05\n",
            "Train loss: 0.5273457169532776\n",
            "\n",
            "Time (s): 0.6301934719085693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 322 / 499\n",
            "LR: 8.90445303451957e-05\n",
            "Train loss: 0.8022932410240173\n",
            "\n",
            "Time (s): 0.6296091079711914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 323 / 499\n",
            "LR: 8.904434960265373e-05\n",
            "Train loss: 0.6834129095077515\n",
            "\n",
            "Time (s): 0.6289992332458496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 324 / 499\n",
            "LR: 8.90441688612124e-05\n",
            "Train loss: 0.5209961533546448\n",
            "\n",
            "Time (s): 0.6275594234466553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 325 / 499\n",
            "LR: 8.904398812087167e-05\n",
            "Train loss: 0.9194020628929138\n",
            "\n",
            "Time (s): 0.6283431053161621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 326 / 499\n",
            "LR: 8.904380738163149e-05\n",
            "Train loss: 0.5044039487838745\n",
            "\n",
            "Time (s): 0.629124641418457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 327 / 499\n",
            "LR: 8.904362664349193e-05\n",
            "Train loss: 0.6417028307914734\n",
            "\n",
            "Time (s): 0.6280186176300049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 328 / 499\n",
            "LR: 8.90434459064529e-05\n",
            "Train loss: 0.697700560092926\n",
            "\n",
            "Time (s): 0.629176139831543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 329 / 499\n",
            "LR: 8.904326517051443e-05\n",
            "Train loss: 0.9658387303352356\n",
            "\n",
            "Time (s): 0.6287667751312256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 330 / 499\n",
            "LR: 8.904308443567652e-05\n",
            "Train loss: 0.6070526242256165\n",
            "\n",
            "Time (s): 0.6268434524536133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 331 / 499\n",
            "LR: 8.904290370193915e-05\n",
            "Train loss: 0.6478859782218933\n",
            "\n",
            "Time (s): 0.6283044815063477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 332 / 499\n",
            "LR: 8.904272296930227e-05\n",
            "Train loss: 1.4029425382614136\n",
            "\n",
            "Time (s): 0.6280789375305176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 333 / 499\n",
            "LR: 8.904254223776591e-05\n",
            "Train loss: 1.538069248199463\n",
            "\n",
            "Time (s): 0.6283774375915527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 334 / 499\n",
            "LR: 8.904236150733004e-05\n",
            "Train loss: 0.5075790882110596\n",
            "\n",
            "Time (s): 0.6301274299621582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 335 / 499\n",
            "LR: 8.904218077799466e-05\n",
            "Train loss: 1.1878681182861328\n",
            "\n",
            "Time (s): 0.6279854774475098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 336 / 499\n",
            "LR: 8.904200004975975e-05\n",
            "Train loss: 0.5133681297302246\n",
            "\n",
            "Time (s): 0.628347635269165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 337 / 499\n",
            "LR: 8.90418193226253e-05\n",
            "Train loss: 1.2277443408966064\n",
            "\n",
            "Time (s): 0.6280133724212646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 338 / 499\n",
            "LR: 8.90416385965913e-05\n",
            "Train loss: 0.5772051215171814\n",
            "\n",
            "Time (s): 0.6280877590179443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 339 / 499\n",
            "LR: 8.904145787165777e-05\n",
            "Train loss: 0.695858359336853\n",
            "\n",
            "Time (s): 0.6261439323425293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 340 / 499\n",
            "LR: 8.904127714782467e-05\n",
            "Train loss: 0.909736156463623\n",
            "\n",
            "Time (s): 0.6258640289306641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 341 / 499\n",
            "LR: 8.904109642509197e-05\n",
            "Train loss: 0.8732675909996033\n",
            "\n",
            "Time (s): 0.6285398006439209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 342 / 499\n",
            "LR: 8.904091570345967e-05\n",
            "Train loss: 0.7271654605865479\n",
            "\n",
            "Time (s): 0.6286237239837646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 343 / 499\n",
            "LR: 8.904073498292778e-05\n",
            "Train loss: 0.414442777633667\n",
            "\n",
            "Time (s): 0.6277196407318115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 344 / 499\n",
            "LR: 8.904055426349627e-05\n",
            "Train loss: 1.3810758590698242\n",
            "\n",
            "Time (s): 0.6253278255462646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 345 / 499\n",
            "LR: 8.904037354516512e-05\n",
            "Train loss: 0.3317820727825165\n",
            "\n",
            "Time (s): 0.6301500797271729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 346 / 499\n",
            "LR: 8.904019282793437e-05\n",
            "Train loss: 0.6281540393829346\n",
            "\n",
            "Time (s): 0.6276001930236816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 347 / 499\n",
            "LR: 8.904001211180395e-05\n",
            "Train loss: 0.576479971408844\n",
            "\n",
            "Time (s): 0.6338224411010742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 348 / 499\n",
            "LR: 8.903983139677388e-05\n",
            "Train loss: 0.6540408134460449\n",
            "\n",
            "Time (s): 0.6259043216705322\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 349 / 499\n",
            "LR: 8.903965068284413e-05\n",
            "Train loss: 0.996523916721344\n",
            "\n",
            "Time (s): 0.6301894187927246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 350 / 499\n",
            "LR: 8.90394699700147e-05\n",
            "Train loss: 1.0404590368270874\n",
            "\n",
            "Time (s): 0.6237719058990479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 351 / 499\n",
            "LR: 8.903928925828558e-05\n",
            "Train loss: 0.9634968638420105\n",
            "\n",
            "Time (s): 0.6274375915527344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 352 / 499\n",
            "LR: 8.903910854765673e-05\n",
            "Train loss: 1.1042726039886475\n",
            "\n",
            "Time (s): 0.6281955242156982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 353 / 499\n",
            "LR: 8.90389278381282e-05\n",
            "Train loss: 1.3626220226287842\n",
            "\n",
            "Time (s): 0.6277599334716797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 354 / 499\n",
            "LR: 8.903874712969994e-05\n",
            "Train loss: 0.5587262511253357\n",
            "\n",
            "Time (s): 0.6270344257354736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 355 / 499\n",
            "LR: 8.903856642237193e-05\n",
            "Train loss: 0.8147652745246887\n",
            "\n",
            "Time (s): 0.6283867359161377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 356 / 499\n",
            "LR: 8.903838571614417e-05\n",
            "Train loss: 0.47240930795669556\n",
            "\n",
            "Time (s): 0.6238322257995605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 357 / 499\n",
            "LR: 8.903820501101666e-05\n",
            "Train loss: 0.8899033665657043\n",
            "\n",
            "Time (s): 0.6263918876647949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 358 / 499\n",
            "LR: 8.903802430698939e-05\n",
            "Train loss: 1.2244659662246704\n",
            "\n",
            "Time (s): 0.6253478527069092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 359 / 499\n",
            "LR: 8.903784360406233e-05\n",
            "Train loss: 1.0060391426086426\n",
            "\n",
            "Time (s): 0.6270318031311035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 360 / 499\n",
            "LR: 8.903766290223547e-05\n",
            "Train loss: 0.6115689873695374\n",
            "\n",
            "Time (s): 0.6285429000854492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 361 / 499\n",
            "LR: 8.90374822015088e-05\n",
            "Train loss: 0.9657432436943054\n",
            "\n",
            "Time (s): 0.627220630645752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 362 / 499\n",
            "LR: 8.903730150188232e-05\n",
            "Train loss: 0.7977925539016724\n",
            "\n",
            "Time (s): 0.6235151290893555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 363 / 499\n",
            "LR: 8.903712080335603e-05\n",
            "Train loss: 0.511931836605072\n",
            "\n",
            "Time (s): 0.6280956268310547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 364 / 499\n",
            "LR: 8.903694010592988e-05\n",
            "Train loss: 1.0837982892990112\n",
            "\n",
            "Time (s): 0.6235432624816895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 365 / 499\n",
            "LR: 8.903675940960388e-05\n",
            "Train loss: 0.907992422580719\n",
            "\n",
            "Time (s): 0.6290700435638428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 366 / 499\n",
            "LR: 8.903657871437802e-05\n",
            "Train loss: 0.7709951400756836\n",
            "\n",
            "Time (s): 0.629446268081665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 367 / 499\n",
            "LR: 8.903639802025232e-05\n",
            "Train loss: 0.7649909257888794\n",
            "\n",
            "Time (s): 0.6273667812347412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 368 / 499\n",
            "LR: 8.90362173272267e-05\n",
            "Train loss: 0.5570410490036011\n",
            "\n",
            "Time (s): 0.6285891532897949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 369 / 499\n",
            "LR: 8.903603663530122e-05\n",
            "Train loss: 0.9608040452003479\n",
            "\n",
            "Time (s): 0.6241054534912109\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 370 / 499\n",
            "LR: 8.90358559444758e-05\n",
            "Train loss: 1.1223368644714355\n",
            "\n",
            "Time (s): 0.6288168430328369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 371 / 499\n",
            "LR: 8.903567525475049e-05\n",
            "Train loss: 0.7004987001419067\n",
            "\n",
            "Time (s): 0.6243188381195068\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 372 / 499\n",
            "LR: 8.903549456612524e-05\n",
            "Train loss: 1.4867552518844604\n",
            "\n",
            "Time (s): 0.6239793300628662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 373 / 499\n",
            "LR: 8.903531387860005e-05\n",
            "Train loss: 0.9466379880905151\n",
            "\n",
            "Time (s): 0.6291079521179199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 374 / 499\n",
            "LR: 8.903513319217492e-05\n",
            "Train loss: 0.7634591460227966\n",
            "\n",
            "Time (s): 0.6272842884063721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 375 / 499\n",
            "LR: 8.903495250684982e-05\n",
            "Train loss: 1.244640827178955\n",
            "\n",
            "Time (s): 0.6273910999298096\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 376 / 499\n",
            "LR: 8.903477182262478e-05\n",
            "Train loss: 0.5054130554199219\n",
            "\n",
            "Time (s): 0.6276834011077881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 377 / 499\n",
            "LR: 8.90345911394997e-05\n",
            "Train loss: 1.0333046913146973\n",
            "\n",
            "Time (s): 0.6260840892791748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 378 / 499\n",
            "LR: 8.903441045747468e-05\n",
            "Train loss: 0.3307962417602539\n",
            "\n",
            "Time (s): 0.6272895336151123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 379 / 499\n",
            "LR: 8.903422977654961e-05\n",
            "Train loss: 0.9114144444465637\n",
            "\n",
            "Time (s): 0.6277549266815186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 380 / 499\n",
            "LR: 8.903404909672456e-05\n",
            "Train loss: 1.3400627374649048\n",
            "\n",
            "Time (s): 0.62786865234375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 381 / 499\n",
            "LR: 8.903386841799947e-05\n",
            "Train loss: 0.9002025723457336\n",
            "\n",
            "Time (s): 0.6267993450164795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 382 / 499\n",
            "LR: 8.903368774037432e-05\n",
            "Train loss: 0.6815991997718811\n",
            "\n",
            "Time (s): 0.6238999366760254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 383 / 499\n",
            "LR: 8.903350706384915e-05\n",
            "Train loss: 0.9262198209762573\n",
            "\n",
            "Time (s): 0.6281840801239014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 384 / 499\n",
            "LR: 8.903332638842391e-05\n",
            "Train loss: 0.8493563532829285\n",
            "\n",
            "Time (s): 0.6277892589569092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 385 / 499\n",
            "LR: 8.903314571409858e-05\n",
            "Train loss: 0.7688872218132019\n",
            "\n",
            "Time (s): 0.628401517868042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 386 / 499\n",
            "LR: 8.903296504087319e-05\n",
            "Train loss: 0.5967864990234375\n",
            "\n",
            "Time (s): 0.6281323432922363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 387 / 499\n",
            "LR: 8.90327843687477e-05\n",
            "Train loss: 0.5006637573242188\n",
            "\n",
            "Time (s): 0.6289792060852051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 388 / 499\n",
            "LR: 8.90326036977221e-05\n",
            "Train loss: 0.5143029093742371\n",
            "\n",
            "Time (s): 0.6292574405670166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 389 / 499\n",
            "LR: 8.903242302779638e-05\n",
            "Train loss: 0.851230263710022\n",
            "\n",
            "Time (s): 0.6282391548156738\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 390 / 499\n",
            "LR: 8.903224235897055e-05\n",
            "Train loss: 1.017220377922058\n",
            "\n",
            "Time (s): 0.6255815029144287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 391 / 499\n",
            "LR: 8.903206169124457e-05\n",
            "Train loss: 0.8137354850769043\n",
            "\n",
            "Time (s): 0.6274328231811523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 392 / 499\n",
            "LR: 8.903188102461844e-05\n",
            "Train loss: 0.7577810287475586\n",
            "\n",
            "Time (s): 0.6296627521514893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 393 / 499\n",
            "LR: 8.903170035909214e-05\n",
            "Train loss: 1.2503471374511719\n",
            "\n",
            "Time (s): 0.6266496181488037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 394 / 499\n",
            "LR: 8.903151969466569e-05\n",
            "Train loss: 0.5303276777267456\n",
            "\n",
            "Time (s): 0.6287710666656494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 395 / 499\n",
            "LR: 8.903133903133904e-05\n",
            "Train loss: 0.44135046005249023\n",
            "\n",
            "Time (s): 0.6240246295928955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 396 / 499\n",
            "LR: 8.903115836911219e-05\n",
            "Train loss: 0.9262809753417969\n",
            "\n",
            "Time (s): 0.6282563209533691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 397 / 499\n",
            "LR: 8.903097770798512e-05\n",
            "Train loss: 1.1771072149276733\n",
            "\n",
            "Time (s): 0.6273849010467529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 398 / 499\n",
            "LR: 8.903079704795787e-05\n",
            "Train loss: 0.6917868852615356\n",
            "\n",
            "Time (s): 0.631138801574707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 399 / 499\n",
            "LR: 8.903061638903036e-05\n",
            "Train loss: 1.125349760055542\n",
            "\n",
            "Time (s): 0.6281170845031738\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 400 / 499\n",
            "LR: 8.903043573120262e-05\n",
            "Train loss: 1.4968056678771973\n",
            "\n",
            "Time (s): 0.6277756690979004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 401 / 499\n",
            "LR: 8.903025507447464e-05\n",
            "Train loss: 1.1496920585632324\n",
            "\n",
            "Time (s): 0.6274385452270508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 402 / 499\n",
            "LR: 8.903007441884639e-05\n",
            "Train loss: 0.8991892337799072\n",
            "\n",
            "Time (s): 0.6290364265441895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 403 / 499\n",
            "LR: 8.902989376431788e-05\n",
            "Train loss: 0.895537257194519\n",
            "\n",
            "Time (s): 0.629380464553833\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 404 / 499\n",
            "LR: 8.902971311088906e-05\n",
            "Train loss: 1.1435500383377075\n",
            "\n",
            "Time (s): 0.6295082569122314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 405 / 499\n",
            "LR: 8.902953245855995e-05\n",
            "Train loss: 0.6545537710189819\n",
            "\n",
            "Time (s): 0.6281135082244873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 406 / 499\n",
            "LR: 8.902935180733056e-05\n",
            "Train loss: 0.5842249393463135\n",
            "\n",
            "Time (s): 0.6297614574432373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 407 / 499\n",
            "LR: 8.902917115720083e-05\n",
            "Train loss: 0.7240380048751831\n",
            "\n",
            "Time (s): 0.6285769939422607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 408 / 499\n",
            "LR: 8.902899050817077e-05\n",
            "Train loss: 0.762317419052124\n",
            "\n",
            "Time (s): 0.6305427551269531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 409 / 499\n",
            "LR: 8.902880986024038e-05\n",
            "Train loss: 0.9897107481956482\n",
            "\n",
            "Time (s): 0.6279354095458984\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 410 / 499\n",
            "LR: 8.902862921340964e-05\n",
            "Train loss: 0.7451679110527039\n",
            "\n",
            "Time (s): 0.628227949142456\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 411 / 499\n",
            "LR: 8.902844856767853e-05\n",
            "Train loss: 1.5358881950378418\n",
            "\n",
            "Time (s): 0.63071608543396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 412 / 499\n",
            "LR: 8.902826792304703e-05\n",
            "Train loss: 0.5593262910842896\n",
            "\n",
            "Time (s): 0.628915548324585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 413 / 499\n",
            "LR: 8.902808727951516e-05\n",
            "Train loss: 0.977527379989624\n",
            "\n",
            "Time (s): 0.6233069896697998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 414 / 499\n",
            "LR: 8.902790663708291e-05\n",
            "Train loss: 1.23046875\n",
            "\n",
            "Time (s): 0.6282575130462646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 415 / 499\n",
            "LR: 8.902772599575025e-05\n",
            "Train loss: 0.5091838240623474\n",
            "\n",
            "Time (s): 0.6293025016784668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 416 / 499\n",
            "LR: 8.902754535551715e-05\n",
            "Train loss: 0.9553288817405701\n",
            "\n",
            "Time (s): 0.6284141540527344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 417 / 499\n",
            "LR: 8.902736471638364e-05\n",
            "Train loss: 0.7598024606704712\n",
            "\n",
            "Time (s): 0.6287045478820801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 418 / 499\n",
            "LR: 8.90271840783497e-05\n",
            "Train loss: 0.8517487049102783\n",
            "\n",
            "Time (s): 0.629124641418457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 419 / 499\n",
            "LR: 8.902700344141528e-05\n",
            "Train loss: 0.4201732575893402\n",
            "\n",
            "Time (s): 0.6298213005065918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 420 / 499\n",
            "LR: 8.90268228055804e-05\n",
            "Train loss: 0.6623440384864807\n",
            "\n",
            "Time (s): 0.6287736892700195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 421 / 499\n",
            "LR: 8.902664217084508e-05\n",
            "Train loss: 1.0517200231552124\n",
            "\n",
            "Time (s): 0.6281487941741943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 422 / 499\n",
            "LR: 8.902646153720923e-05\n",
            "Train loss: 0.36201250553131104\n",
            "\n",
            "Time (s): 0.6289732456207275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 423 / 499\n",
            "LR: 8.90262809046729e-05\n",
            "Train loss: 1.47136390209198\n",
            "\n",
            "Time (s): 0.6287751197814941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 424 / 499\n",
            "LR: 8.902610027323607e-05\n",
            "Train loss: 0.9889561533927917\n",
            "\n",
            "Time (s): 0.632089376449585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 425 / 499\n",
            "LR: 8.902591964289872e-05\n",
            "Train loss: 0.6960788369178772\n",
            "\n",
            "Time (s): 0.6304845809936523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 426 / 499\n",
            "LR: 8.902573901366084e-05\n",
            "Train loss: 0.48486021161079407\n",
            "\n",
            "Time (s): 0.6299049854278564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 427 / 499\n",
            "LR: 8.902555838552241e-05\n",
            "Train loss: 0.5120337605476379\n",
            "\n",
            "Time (s): 0.6288812160491943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 428 / 499\n",
            "LR: 8.902537775848344e-05\n",
            "Train loss: 1.036741018295288\n",
            "\n",
            "Time (s): 0.628382682800293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 429 / 499\n",
            "LR: 8.902519713254391e-05\n",
            "Train loss: 0.46905794739723206\n",
            "\n",
            "Time (s): 0.6280725002288818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 430 / 499\n",
            "LR: 8.90250165077038e-05\n",
            "Train loss: 0.6741321086883545\n",
            "\n",
            "Time (s): 0.629235029220581\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 431 / 499\n",
            "LR: 8.90248358839631e-05\n",
            "Train loss: 0.6632611751556396\n",
            "\n",
            "Time (s): 0.6339848041534424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 432 / 499\n",
            "LR: 8.90246552613218e-05\n",
            "Train loss: 0.5746957659721375\n",
            "\n",
            "Time (s): 0.6301908493041992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 433 / 499\n",
            "LR: 8.90244746397799e-05\n",
            "Train loss: 1.312185525894165\n",
            "\n",
            "Time (s): 0.6290161609649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 434 / 499\n",
            "LR: 8.90242940193374e-05\n",
            "Train loss: 0.7289350628852844\n",
            "\n",
            "Time (s): 0.6289474964141846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 435 / 499\n",
            "LR: 8.902411339999425e-05\n",
            "Train loss: 0.6468085050582886\n",
            "\n",
            "Time (s): 0.6288182735443115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 436 / 499\n",
            "LR: 8.902393278175045e-05\n",
            "Train loss: 1.456597089767456\n",
            "\n",
            "Time (s): 0.6287157535552979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 437 / 499\n",
            "LR: 8.902375216460601e-05\n",
            "Train loss: 0.8115982413291931\n",
            "\n",
            "Time (s): 0.629185676574707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 438 / 499\n",
            "LR: 8.90235715485609e-05\n",
            "Train loss: 1.0114662647247314\n",
            "\n",
            "Time (s): 0.6289246082305908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 439 / 499\n",
            "LR: 8.902339093361512e-05\n",
            "Train loss: 0.5660282373428345\n",
            "\n",
            "Time (s): 0.6285481452941895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 440 / 499\n",
            "LR: 8.902321031976863e-05\n",
            "Train loss: 1.0065791606903076\n",
            "\n",
            "Time (s): 0.6288754940032959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 441 / 499\n",
            "LR: 8.902302970702149e-05\n",
            "Train loss: 0.4635388255119324\n",
            "\n",
            "Time (s): 0.6289122104644775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 442 / 499\n",
            "LR: 8.90228490953736e-05\n",
            "Train loss: 0.45611417293548584\n",
            "\n",
            "Time (s): 0.6295368671417236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 443 / 499\n",
            "LR: 8.9022668484825e-05\n",
            "Train loss: 1.008557677268982\n",
            "\n",
            "Time (s): 0.629206657409668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 444 / 499\n",
            "LR: 8.90224878753757e-05\n",
            "Train loss: 1.5830802917480469\n",
            "\n",
            "Time (s): 0.6322758197784424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 445 / 499\n",
            "LR: 8.902230726702563e-05\n",
            "Train loss: 1.053084135055542\n",
            "\n",
            "Time (s): 0.6290121078491211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 446 / 499\n",
            "LR: 8.902212665977481e-05\n",
            "Train loss: 1.0326048135757446\n",
            "\n",
            "Time (s): 0.6281492710113525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 447 / 499\n",
            "LR: 8.902194605362324e-05\n",
            "Train loss: 0.5469955801963806\n",
            "\n",
            "Time (s): 0.6276719570159912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 448 / 499\n",
            "LR: 8.902176544857089e-05\n",
            "Train loss: 0.7302328944206238\n",
            "\n",
            "Time (s): 0.628502368927002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 449 / 499\n",
            "LR: 8.902158484461774e-05\n",
            "Train loss: 0.48256441950798035\n",
            "\n",
            "Time (s): 0.6276583671569824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 450 / 499\n",
            "LR: 8.902140424176379e-05\n",
            "Train loss: 0.5697246789932251\n",
            "\n",
            "Time (s): 0.6291265487670898\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 451 / 499\n",
            "LR: 8.902122364000906e-05\n",
            "Train loss: 0.826535165309906\n",
            "\n",
            "Time (s): 0.6290972232818604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 452 / 499\n",
            "LR: 8.90210430393535e-05\n",
            "Train loss: 0.8399744629859924\n",
            "\n",
            "Time (s): 0.6295328140258789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 453 / 499\n",
            "LR: 8.90208624397971e-05\n",
            "Train loss: 0.8277422785758972\n",
            "\n",
            "Time (s): 0.6292588710784912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 454 / 499\n",
            "LR: 8.902068184133986e-05\n",
            "Train loss: 0.35904550552368164\n",
            "\n",
            "Time (s): 0.6297433376312256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 455 / 499\n",
            "LR: 8.902050124398176e-05\n",
            "Train loss: 1.5421380996704102\n",
            "\n",
            "Time (s): 0.6290044784545898\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 456 / 499\n",
            "LR: 8.902032064772281e-05\n",
            "Train loss: 0.6696963906288147\n",
            "\n",
            "Time (s): 0.6303427219390869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 457 / 499\n",
            "LR: 8.902014005256297e-05\n",
            "Train loss: 1.462476372718811\n",
            "\n",
            "Time (s): 0.6294577121734619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 458 / 499\n",
            "LR: 8.901995945850227e-05\n",
            "Train loss: 0.9515572786331177\n",
            "\n",
            "Time (s): 0.6282918453216553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 459 / 499\n",
            "LR: 8.901977886554063e-05\n",
            "Train loss: 1.1802358627319336\n",
            "\n",
            "Time (s): 0.6283740997314453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 460 / 499\n",
            "LR: 8.901959827367811e-05\n",
            "Train loss: 0.5874836444854736\n",
            "\n",
            "Time (s): 0.6275899410247803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 461 / 499\n",
            "LR: 8.901941768291467e-05\n",
            "Train loss: 1.010991096496582\n",
            "\n",
            "Time (s): 0.6289951801300049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 462 / 499\n",
            "LR: 8.901923709325029e-05\n",
            "Train loss: 0.7370432019233704\n",
            "\n",
            "Time (s): 0.6269164085388184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 463 / 499\n",
            "LR: 8.901905650468499e-05\n",
            "Train loss: 0.8604804873466492\n",
            "\n",
            "Time (s): 0.6283488273620605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 464 / 499\n",
            "LR: 8.90188759172187e-05\n",
            "Train loss: 1.0946924686431885\n",
            "\n",
            "Time (s): 0.6285202503204346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 465 / 499\n",
            "LR: 8.901869533085148e-05\n",
            "Train loss: 0.7756454944610596\n",
            "\n",
            "Time (s): 0.6280572414398193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 466 / 499\n",
            "LR: 8.901851474558326e-05\n",
            "Train loss: 0.4913545548915863\n",
            "\n",
            "Time (s): 0.6282975673675537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 467 / 499\n",
            "LR: 8.901833416141407e-05\n",
            "Train loss: 0.6683905124664307\n",
            "\n",
            "Time (s): 0.6279716491699219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 468 / 499\n",
            "LR: 8.901815357834387e-05\n",
            "Train loss: 0.7221639752388\n",
            "\n",
            "Time (s): 0.6281204223632812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 469 / 499\n",
            "LR: 8.901797299637267e-05\n",
            "Train loss: 0.7019893527030945\n",
            "\n",
            "Time (s): 0.6276302337646484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 470 / 499\n",
            "LR: 8.901779241550044e-05\n",
            "Train loss: 0.8644425868988037\n",
            "\n",
            "Time (s): 0.6292643547058105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 471 / 499\n",
            "LR: 8.901761183572717e-05\n",
            "Train loss: 1.2439216375350952\n",
            "\n",
            "Time (s): 0.6297833919525146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 472 / 499\n",
            "LR: 8.901743125705287e-05\n",
            "Train loss: 0.7638274431228638\n",
            "\n",
            "Time (s): 0.6279628276824951\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 473 / 499\n",
            "LR: 8.901725067947752e-05\n",
            "Train loss: 0.7283018827438354\n",
            "\n",
            "Time (s): 0.6288831233978271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 474 / 499\n",
            "LR: 8.901707010300111e-05\n",
            "Train loss: 0.8610682487487793\n",
            "\n",
            "Time (s): 0.6281208992004395\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 475 / 499\n",
            "LR: 8.901688952762361e-05\n",
            "Train loss: 0.8428280353546143\n",
            "\n",
            "Time (s): 0.6277735233306885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 476 / 499\n",
            "LR: 8.901670895334503e-05\n",
            "Train loss: 1.214237928390503\n",
            "\n",
            "Time (s): 0.6284663677215576\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 477 / 499\n",
            "LR: 8.901652838016536e-05\n",
            "Train loss: 0.7459291219711304\n",
            "\n",
            "Time (s): 0.6281783580780029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 478 / 499\n",
            "LR: 8.901634780808457e-05\n",
            "Train loss: 1.3383588790893555\n",
            "\n",
            "Time (s): 0.628441572189331\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 479 / 499\n",
            "LR: 8.901616723710265e-05\n",
            "Train loss: 0.9704139828681946\n",
            "\n",
            "Time (s): 0.6292338371276855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 480 / 499\n",
            "LR: 8.901598666721961e-05\n",
            "Train loss: 0.9085792899131775\n",
            "\n",
            "Time (s): 0.6286184787750244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 481 / 499\n",
            "LR: 8.901580609843545e-05\n",
            "Train loss: 1.2697222232818604\n",
            "\n",
            "Time (s): 0.6241722106933594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 482 / 499\n",
            "LR: 8.901562553075011e-05\n",
            "Train loss: 0.43238240480422974\n",
            "\n",
            "Time (s): 0.6289949417114258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 483 / 499\n",
            "LR: 8.901544496416359e-05\n",
            "Train loss: 0.8417634963989258\n",
            "\n",
            "Time (s): 0.6299362182617188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 484 / 499\n",
            "LR: 8.90152643986759e-05\n",
            "Train loss: 0.7264336347579956\n",
            "\n",
            "Time (s): 0.6237409114837646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 485 / 499\n",
            "LR: 8.901508383428705e-05\n",
            "Train loss: 0.3856438398361206\n",
            "\n",
            "Time (s): 0.6277058124542236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 486 / 499\n",
            "LR: 8.901490327099699e-05\n",
            "Train loss: 0.401248961687088\n",
            "\n",
            "Time (s): 0.6282675266265869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 487 / 499\n",
            "LR: 8.901472270880571e-05\n",
            "Train loss: 0.452951043844223\n",
            "\n",
            "Time (s): 0.6289868354797363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 488 / 499\n",
            "LR: 8.901454214771322e-05\n",
            "Train loss: 1.2472195625305176\n",
            "\n",
            "Time (s): 0.6289775371551514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 489 / 499\n",
            "LR: 8.901436158771948e-05\n",
            "Train loss: 1.2610936164855957\n",
            "\n",
            "Time (s): 0.6278047561645508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 490 / 499\n",
            "LR: 8.901418102882451e-05\n",
            "Train loss: 1.1435264348983765\n",
            "\n",
            "Time (s): 0.6288747787475586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 491 / 499\n",
            "LR: 8.901400047102828e-05\n",
            "Train loss: 0.6100161671638489\n",
            "\n",
            "Time (s): 0.6291007995605469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 492 / 499\n",
            "LR: 8.901381991433079e-05\n",
            "Train loss: 0.9235273003578186\n",
            "\n",
            "Time (s): 0.6291861534118652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 493 / 499\n",
            "LR: 8.901363935873204e-05\n",
            "Train loss: 0.9549643397331238\n",
            "\n",
            "Time (s): 0.6302652359008789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 494 / 499\n",
            "LR: 8.901345880423198e-05\n",
            "Train loss: 1.0731784105300903\n",
            "\n",
            "Time (s): 0.6289832592010498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 495 / 499\n",
            "LR: 8.901327825083063e-05\n",
            "Train loss: 0.5890491604804993\n",
            "\n",
            "Time (s): 0.6286368370056152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 496 / 499\n",
            "LR: 8.901309769852796e-05\n",
            "Train loss: 1.3791265487670898\n",
            "\n",
            "Time (s): 0.6283712387084961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 497 / 499\n",
            "LR: 8.901291714732398e-05\n",
            "Train loss: 0.6889070868492126\n",
            "\n",
            "Time (s): 0.6293199062347412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 498 / 499\n",
            "LR: 8.901273659721865e-05\n",
            "Train loss: 1.1410189867019653\n",
            "\n",
            "Time (s): 0.6242341995239258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 494  Batch 499 / 499\n",
            "LR: 8.901255604821199e-05\n",
            "Train loss: 1.1860976219177246\n",
            "\n",
            "Time (s): 0.05384230613708496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 494\n",
            "Avg train loss: 0.6985556809810216\n",
            "Avg train acc: 0.7932849335288237\n",
            "Avg eval loss: 0.9149307626135209\n",
            "Avg eval acc: 0.751547610058504\n",
            "=========================\n",
            "\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 495\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 1 / 499\n",
            "LR: 8.901237550030398e-05\n",
            "Train loss: 0.6820660829544067\n",
            "\n",
            "Time (s): 0.6361973285675049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 2 / 499\n",
            "LR: 8.90121949534946e-05\n",
            "Train loss: 0.7543666362762451\n",
            "\n",
            "Time (s): 0.6277079582214355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 3 / 499\n",
            "LR: 8.901201440778385e-05\n",
            "Train loss: 0.9389725923538208\n",
            "\n",
            "Time (s): 0.6297011375427246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 4 / 499\n",
            "LR: 8.90118338631717e-05\n",
            "Train loss: 1.6001696586608887\n",
            "\n",
            "Time (s): 0.6286377906799316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 5 / 499\n",
            "LR: 8.901165331965814e-05\n",
            "Train loss: 0.41294604539871216\n",
            "\n",
            "Time (s): 0.6230826377868652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 6 / 499\n",
            "LR: 8.90114727772432e-05\n",
            "Train loss: 0.8377442359924316\n",
            "\n",
            "Time (s): 0.627899169921875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 7 / 499\n",
            "LR: 8.901129223592682e-05\n",
            "Train loss: 0.7694966793060303\n",
            "\n",
            "Time (s): 0.6281991004943848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 8 / 499\n",
            "LR: 8.9011111695709e-05\n",
            "Train loss: 0.9161458611488342\n",
            "\n",
            "Time (s): 0.6275634765625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 9 / 499\n",
            "LR: 8.901093115658976e-05\n",
            "Train loss: 1.2100024223327637\n",
            "\n",
            "Time (s): 0.6290080547332764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 10 / 499\n",
            "LR: 8.901075061856904e-05\n",
            "Train loss: 0.760540246963501\n",
            "\n",
            "Time (s): 0.6229729652404785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 11 / 499\n",
            "LR: 8.901057008164688e-05\n",
            "Train loss: 0.7859103083610535\n",
            "\n",
            "Time (s): 0.6279830932617188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 12 / 499\n",
            "LR: 8.901038954582321e-05\n",
            "Train loss: 1.1474825143814087\n",
            "\n",
            "Time (s): 0.6277635097503662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 13 / 499\n",
            "LR: 8.901020901109809e-05\n",
            "Train loss: 1.0382815599441528\n",
            "\n",
            "Time (s): 0.6237306594848633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 14 / 499\n",
            "LR: 8.901002847747144e-05\n",
            "Train loss: 1.2384871244430542\n",
            "\n",
            "Time (s): 0.6288397312164307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 15 / 499\n",
            "LR: 8.900984794494329e-05\n",
            "Train loss: 0.7663792371749878\n",
            "\n",
            "Time (s): 0.6304371356964111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 16 / 499\n",
            "LR: 8.900966741351363e-05\n",
            "Train loss: 0.5190267562866211\n",
            "\n",
            "Time (s): 0.6275560855865479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 17 / 499\n",
            "LR: 8.900948688318243e-05\n",
            "Train loss: 1.6845815181732178\n",
            "\n",
            "Time (s): 0.6287233829498291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 18 / 499\n",
            "LR: 8.900930635394967e-05\n",
            "Train loss: 0.6173058748245239\n",
            "\n",
            "Time (s): 0.6242880821228027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 19 / 499\n",
            "LR: 8.900912582581538e-05\n",
            "Train loss: 0.9096025824546814\n",
            "\n",
            "Time (s): 0.6274905204772949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 20 / 499\n",
            "LR: 8.90089452987795e-05\n",
            "Train loss: 0.9835001826286316\n",
            "\n",
            "Time (s): 0.6288769245147705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 21 / 499\n",
            "LR: 8.900876477284206e-05\n",
            "Train loss: 0.631436824798584\n",
            "\n",
            "Time (s): 0.6260166168212891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 22 / 499\n",
            "LR: 8.900858424800302e-05\n",
            "Train loss: 1.3680046796798706\n",
            "\n",
            "Time (s): 0.6276087760925293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 23 / 499\n",
            "LR: 8.900840372426238e-05\n",
            "Train loss: 0.7908205389976501\n",
            "\n",
            "Time (s): 0.6261696815490723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 24 / 499\n",
            "LR: 8.900822320162014e-05\n",
            "Train loss: 0.7585729360580444\n",
            "\n",
            "Time (s): 0.6239058971405029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 25 / 499\n",
            "LR: 8.900804268007627e-05\n",
            "Train loss: 1.1982042789459229\n",
            "\n",
            "Time (s): 0.628730058670044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 26 / 499\n",
            "LR: 8.900786215963078e-05\n",
            "Train loss: 0.8400615453720093\n",
            "\n",
            "Time (s): 0.6280374526977539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 27 / 499\n",
            "LR: 8.900768164028362e-05\n",
            "Train loss: 0.8069630861282349\n",
            "\n",
            "Time (s): 0.6266677379608154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 28 / 499\n",
            "LR: 8.900750112203482e-05\n",
            "Train loss: 0.9945688247680664\n",
            "\n",
            "Time (s): 0.6236841678619385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 29 / 499\n",
            "LR: 8.900732060488435e-05\n",
            "Train loss: 1.0873770713806152\n",
            "\n",
            "Time (s): 0.6270520687103271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 30 / 499\n",
            "LR: 8.900714008883221e-05\n",
            "Train loss: 0.6417627334594727\n",
            "\n",
            "Time (s): 0.6238281726837158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 31 / 499\n",
            "LR: 8.900695957387839e-05\n",
            "Train loss: 0.7933796644210815\n",
            "\n",
            "Time (s): 0.6274185180664062\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 32 / 499\n",
            "LR: 8.900677906002285e-05\n",
            "Train loss: 1.3712912797927856\n",
            "\n",
            "Time (s): 0.6239240169525146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 33 / 499\n",
            "LR: 8.900659854726559e-05\n",
            "Train loss: 0.501306414604187\n",
            "\n",
            "Time (s): 0.629122257232666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 34 / 499\n",
            "LR: 8.900641803560664e-05\n",
            "Train loss: 0.43398910760879517\n",
            "\n",
            "Time (s): 0.6234111785888672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 35 / 499\n",
            "LR: 8.900623752504593e-05\n",
            "Train loss: 0.6364971995353699\n",
            "\n",
            "Time (s): 0.6286125183105469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 36 / 499\n",
            "LR: 8.900605701558349e-05\n",
            "Train loss: 1.0733705759048462\n",
            "\n",
            "Time (s): 0.6288552284240723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 37 / 499\n",
            "LR: 8.900587650721928e-05\n",
            "Train loss: 1.0982075929641724\n",
            "\n",
            "Time (s): 0.6230700016021729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 38 / 499\n",
            "LR: 8.900569599995333e-05\n",
            "Train loss: 0.6472240090370178\n",
            "\n",
            "Time (s): 0.6232578754425049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 39 / 499\n",
            "LR: 8.900551549378559e-05\n",
            "Train loss: 1.4040439128875732\n",
            "\n",
            "Time (s): 0.6237843036651611\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 40 / 499\n",
            "LR: 8.900533498871604e-05\n",
            "Train loss: 1.232008934020996\n",
            "\n",
            "Time (s): 0.6272640228271484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 41 / 499\n",
            "LR: 8.900515448474472e-05\n",
            "Train loss: 0.4568139314651489\n",
            "\n",
            "Time (s): 0.6286532878875732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 42 / 499\n",
            "LR: 8.900497398187157e-05\n",
            "Train loss: 1.0575571060180664\n",
            "\n",
            "Time (s): 0.6232242584228516\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 43 / 499\n",
            "LR: 8.900479348009661e-05\n",
            "Train loss: 0.3589928150177002\n",
            "\n",
            "Time (s): 0.627741813659668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 44 / 499\n",
            "LR: 8.900461297941979e-05\n",
            "Train loss: 0.29663336277008057\n",
            "\n",
            "Time (s): 0.6278924942016602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 45 / 499\n",
            "LR: 8.900443247984115e-05\n",
            "Train loss: 0.9662668704986572\n",
            "\n",
            "Time (s): 0.6294398307800293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 46 / 499\n",
            "LR: 8.900425198136065e-05\n",
            "Train loss: 0.4579204022884369\n",
            "\n",
            "Time (s): 0.6275091171264648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 47 / 499\n",
            "LR: 8.900407148397829e-05\n",
            "Train loss: 1.2073180675506592\n",
            "\n",
            "Time (s): 0.6229343414306641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 48 / 499\n",
            "LR: 8.900389098769405e-05\n",
            "Train loss: 0.7612848877906799\n",
            "\n",
            "Time (s): 0.6288042068481445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 49 / 499\n",
            "LR: 8.90037104925079e-05\n",
            "Train loss: 0.5868049263954163\n",
            "\n",
            "Time (s): 0.6277115345001221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 50 / 499\n",
            "LR: 8.900352999841987e-05\n",
            "Train loss: 0.48448699712753296\n",
            "\n",
            "Time (s): 0.6268608570098877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 51 / 499\n",
            "LR: 8.900334950542992e-05\n",
            "Train loss: 1.3822745084762573\n",
            "\n",
            "Time (s): 0.6229267120361328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 52 / 499\n",
            "LR: 8.900316901353804e-05\n",
            "Train loss: 0.9377633333206177\n",
            "\n",
            "Time (s): 0.6272969245910645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 53 / 499\n",
            "LR: 8.900298852274424e-05\n",
            "Train loss: 0.7385987043380737\n",
            "\n",
            "Time (s): 0.6270849704742432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 54 / 499\n",
            "LR: 8.90028080330485e-05\n",
            "Train loss: 0.6971916556358337\n",
            "\n",
            "Time (s): 0.6279878616333008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 55 / 499\n",
            "LR: 8.900262754445078e-05\n",
            "Train loss: 1.5206575393676758\n",
            "\n",
            "Time (s): 0.6276273727416992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 56 / 499\n",
            "LR: 8.900244705695114e-05\n",
            "Train loss: 0.44301679730415344\n",
            "\n",
            "Time (s): 0.6279256343841553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 57 / 499\n",
            "LR: 8.900226657054947e-05\n",
            "Train loss: 0.9823102951049805\n",
            "\n",
            "Time (s): 0.6267883777618408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 58 / 499\n",
            "LR: 8.900208608524584e-05\n",
            "Train loss: 0.803817868232727\n",
            "\n",
            "Time (s): 0.627263069152832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 59 / 499\n",
            "LR: 8.900190560104019e-05\n",
            "Train loss: 1.4012089967727661\n",
            "\n",
            "Time (s): 0.6272168159484863\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 60 / 499\n",
            "LR: 8.900172511793255e-05\n",
            "Train loss: 1.002710223197937\n",
            "\n",
            "Time (s): 0.6273174285888672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 61 / 499\n",
            "LR: 8.900154463592287e-05\n",
            "Train loss: 0.7825746536254883\n",
            "\n",
            "Time (s): 0.6292202472686768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 62 / 499\n",
            "LR: 8.900136415501116e-05\n",
            "Train loss: 0.6522340178489685\n",
            "\n",
            "Time (s): 0.6270387172698975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 63 / 499\n",
            "LR: 8.90011836751974e-05\n",
            "Train loss: 1.0486057996749878\n",
            "\n",
            "Time (s): 0.6267695426940918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 64 / 499\n",
            "LR: 8.900100319648158e-05\n",
            "Train loss: 0.500282347202301\n",
            "\n",
            "Time (s): 0.627002477645874\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 65 / 499\n",
            "LR: 8.900082271886372e-05\n",
            "Train loss: 0.5823507308959961\n",
            "\n",
            "Time (s): 0.6269943714141846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 66 / 499\n",
            "LR: 8.900064224234375e-05\n",
            "Train loss: 1.1510480642318726\n",
            "\n",
            "Time (s): 0.6226544380187988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 67 / 499\n",
            "LR: 8.90004617669217e-05\n",
            "Train loss: 1.004082441329956\n",
            "\n",
            "Time (s): 0.6281979084014893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 68 / 499\n",
            "LR: 8.900028129259757e-05\n",
            "Train loss: 0.6129439473152161\n",
            "\n",
            "Time (s): 0.6264901161193848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 69 / 499\n",
            "LR: 8.90001008193713e-05\n",
            "Train loss: 1.307462215423584\n",
            "\n",
            "Time (s): 0.6279339790344238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 70 / 499\n",
            "LR: 8.899992034724293e-05\n",
            "Train loss: 1.2109166383743286\n",
            "\n",
            "Time (s): 0.6240341663360596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 71 / 499\n",
            "LR: 8.89997398762124e-05\n",
            "Train loss: 0.32901647686958313\n",
            "\n",
            "Time (s): 0.6280498504638672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 72 / 499\n",
            "LR: 8.899955940627974e-05\n",
            "Train loss: 1.0082942247390747\n",
            "\n",
            "Time (s): 0.6274933815002441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 73 / 499\n",
            "LR: 8.899937893744493e-05\n",
            "Train loss: 0.39242318272590637\n",
            "\n",
            "Time (s): 0.6287722587585449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 74 / 499\n",
            "LR: 8.899919846970795e-05\n",
            "Train loss: 0.8660176396369934\n",
            "\n",
            "Time (s): 0.6274936199188232\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 75 / 499\n",
            "LR: 8.899901800306877e-05\n",
            "Train loss: 0.6119842529296875\n",
            "\n",
            "Time (s): 0.6275596618652344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 76 / 499\n",
            "LR: 8.899883753752743e-05\n",
            "Train loss: 0.5252685546875\n",
            "\n",
            "Time (s): 0.6290237903594971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 77 / 499\n",
            "LR: 8.899865707308387e-05\n",
            "Train loss: 0.4434695839881897\n",
            "\n",
            "Time (s): 0.6275594234466553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 78 / 499\n",
            "LR: 8.899847660973812e-05\n",
            "Train loss: 0.4552825391292572\n",
            "\n",
            "Time (s): 0.6272521018981934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 79 / 499\n",
            "LR: 8.899829614749011e-05\n",
            "Train loss: 0.4741903245449066\n",
            "\n",
            "Time (s): 0.6274027824401855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 80 / 499\n",
            "LR: 8.899811568633989e-05\n",
            "Train loss: 1.2347592115402222\n",
            "\n",
            "Time (s): 0.6290464401245117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 81 / 499\n",
            "LR: 8.899793522628742e-05\n",
            "Train loss: 0.2836686968803406\n",
            "\n",
            "Time (s): 0.6235220432281494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 82 / 499\n",
            "LR: 8.89977547673327e-05\n",
            "Train loss: 0.22155195474624634\n",
            "\n",
            "Time (s): 0.6273343563079834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 83 / 499\n",
            "LR: 8.899757430947571e-05\n",
            "Train loss: 0.9063347578048706\n",
            "\n",
            "Time (s): 0.6274592876434326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 84 / 499\n",
            "LR: 8.899739385271642e-05\n",
            "Train loss: 0.8698371648788452\n",
            "\n",
            "Time (s): 0.627737283706665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 85 / 499\n",
            "LR: 8.899721339705487e-05\n",
            "Train loss: 1.0620896816253662\n",
            "\n",
            "Time (s): 0.6230344772338867\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 86 / 499\n",
            "LR: 8.899703294249102e-05\n",
            "Train loss: 1.0743159055709839\n",
            "\n",
            "Time (s): 0.6278336048126221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 87 / 499\n",
            "LR: 8.899685248902485e-05\n",
            "Train loss: 0.9666828513145447\n",
            "\n",
            "Time (s): 0.624143123626709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 88 / 499\n",
            "LR: 8.899667203665633e-05\n",
            "Train loss: 0.9893632531166077\n",
            "\n",
            "Time (s): 0.6288094520568848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 89 / 499\n",
            "LR: 8.89964915853855e-05\n",
            "Train loss: 0.7950251698493958\n",
            "\n",
            "Time (s): 0.6279737949371338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 90 / 499\n",
            "LR: 8.899631113521232e-05\n",
            "Train loss: 1.1643991470336914\n",
            "\n",
            "Time (s): 0.6286885738372803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 91 / 499\n",
            "LR: 8.89961306861368e-05\n",
            "Train loss: 1.0383961200714111\n",
            "\n",
            "Time (s): 0.6279630661010742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 92 / 499\n",
            "LR: 8.899595023815887e-05\n",
            "Train loss: 0.5724015235900879\n",
            "\n",
            "Time (s): 0.6275758743286133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 93 / 499\n",
            "LR: 8.899576979127858e-05\n",
            "Train loss: 0.8563570976257324\n",
            "\n",
            "Time (s): 0.6282265186309814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 94 / 499\n",
            "LR: 8.899558934549592e-05\n",
            "Train loss: 0.85396808385849\n",
            "\n",
            "Time (s): 0.6297433376312256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 95 / 499\n",
            "LR: 8.899540890081086e-05\n",
            "Train loss: 1.1727988719940186\n",
            "\n",
            "Time (s): 0.6274337768554688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 96 / 499\n",
            "LR: 8.899522845722336e-05\n",
            "Train loss: 0.699804961681366\n",
            "\n",
            "Time (s): 0.6270239353179932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 97 / 499\n",
            "LR: 8.899504801473344e-05\n",
            "Train loss: 0.6651371121406555\n",
            "\n",
            "Time (s): 0.62680983543396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 98 / 499\n",
            "LR: 8.899486757334111e-05\n",
            "Train loss: 0.45186322927474976\n",
            "\n",
            "Time (s): 0.6273176670074463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 99 / 499\n",
            "LR: 8.899468713304633e-05\n",
            "Train loss: 0.7135893106460571\n",
            "\n",
            "Time (s): 0.628284215927124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 100 / 499\n",
            "LR: 8.899450669384908e-05\n",
            "Train loss: 0.8116372227668762\n",
            "\n",
            "Time (s): 0.6227900981903076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 101 / 499\n",
            "LR: 8.899432625574935e-05\n",
            "Train loss: 0.3960026502609253\n",
            "\n",
            "Time (s): 0.627286434173584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 102 / 499\n",
            "LR: 8.899414581874717e-05\n",
            "Train loss: 0.43399202823638916\n",
            "\n",
            "Time (s): 0.6265630722045898\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 103 / 499\n",
            "LR: 8.899396538284247e-05\n",
            "Train loss: 1.3697302341461182\n",
            "\n",
            "Time (s): 0.6283013820648193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 104 / 499\n",
            "LR: 8.899378494803529e-05\n",
            "Train loss: 0.5802043676376343\n",
            "\n",
            "Time (s): 0.6274564266204834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 105 / 499\n",
            "LR: 8.89936045143256e-05\n",
            "Train loss: 1.2578179836273193\n",
            "\n",
            "Time (s): 0.6287155151367188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 106 / 499\n",
            "LR: 8.899342408171336e-05\n",
            "Train loss: 0.9592581391334534\n",
            "\n",
            "Time (s): 0.6290454864501953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 107 / 499\n",
            "LR: 8.899324365019862e-05\n",
            "Train loss: 0.8057828545570374\n",
            "\n",
            "Time (s): 0.627619743347168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 108 / 499\n",
            "LR: 8.89930632197813e-05\n",
            "Train loss: 0.8147855401039124\n",
            "\n",
            "Time (s): 0.6233737468719482\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 109 / 499\n",
            "LR: 8.899288279046146e-05\n",
            "Train loss: 0.72958904504776\n",
            "\n",
            "Time (s): 0.6270961761474609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 110 / 499\n",
            "LR: 8.899270236223903e-05\n",
            "Train loss: 1.1250656843185425\n",
            "\n",
            "Time (s): 0.6226346492767334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 111 / 499\n",
            "LR: 8.899252193511402e-05\n",
            "Train loss: 0.8358526229858398\n",
            "\n",
            "Time (s): 0.6268856525421143\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 112 / 499\n",
            "LR: 8.899234150908642e-05\n",
            "Train loss: 0.6949754357337952\n",
            "\n",
            "Time (s): 0.6283483505249023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 113 / 499\n",
            "LR: 8.899216108415622e-05\n",
            "Train loss: 0.920589804649353\n",
            "\n",
            "Time (s): 0.6230463981628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 114 / 499\n",
            "LR: 8.89919806603234e-05\n",
            "Train loss: 1.0325264930725098\n",
            "\n",
            "Time (s): 0.6268761157989502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 115 / 499\n",
            "LR: 8.899180023758798e-05\n",
            "Train loss: 1.4783190488815308\n",
            "\n",
            "Time (s): 0.6271400451660156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 116 / 499\n",
            "LR: 8.899161981594991e-05\n",
            "Train loss: 1.1499247550964355\n",
            "\n",
            "Time (s): 0.6276874542236328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 117 / 499\n",
            "LR: 8.899143939540919e-05\n",
            "Train loss: 0.7091953754425049\n",
            "\n",
            "Time (s): 0.6287000179290771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 118 / 499\n",
            "LR: 8.899125897596582e-05\n",
            "Train loss: 1.3936518430709839\n",
            "\n",
            "Time (s): 0.6289103031158447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 119 / 499\n",
            "LR: 8.899107855761976e-05\n",
            "Train loss: 0.8839264512062073\n",
            "\n",
            "Time (s): 0.6277132034301758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 120 / 499\n",
            "LR: 8.899089814037105e-05\n",
            "Train loss: 0.4774217903614044\n",
            "\n",
            "Time (s): 0.626389741897583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 121 / 499\n",
            "LR: 8.899071772421963e-05\n",
            "Train loss: 0.9208499789237976\n",
            "\n",
            "Time (s): 0.6276817321777344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 122 / 499\n",
            "LR: 8.899053730916552e-05\n",
            "Train loss: 0.7495957612991333\n",
            "\n",
            "Time (s): 0.6285505294799805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 123 / 499\n",
            "LR: 8.899035689520871e-05\n",
            "Train loss: 1.0598877668380737\n",
            "\n",
            "Time (s): 0.6275842189788818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 124 / 499\n",
            "LR: 8.899017648234915e-05\n",
            "Train loss: 0.6885045170783997\n",
            "\n",
            "Time (s): 0.6285552978515625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 125 / 499\n",
            "LR: 8.898999607058686e-05\n",
            "Train loss: 0.5970269441604614\n",
            "\n",
            "Time (s): 0.6273064613342285\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 126 / 499\n",
            "LR: 8.898981565992182e-05\n",
            "Train loss: 0.8687736988067627\n",
            "\n",
            "Time (s): 0.6284549236297607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 127 / 499\n",
            "LR: 8.898963525035403e-05\n",
            "Train loss: 0.5655726194381714\n",
            "\n",
            "Time (s): 0.628251314163208\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 128 / 499\n",
            "LR: 8.898945484188347e-05\n",
            "Train loss: 1.00202214717865\n",
            "\n",
            "Time (s): 0.6277961730957031\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 129 / 499\n",
            "LR: 8.898927443451015e-05\n",
            "Train loss: 1.03593111038208\n",
            "\n",
            "Time (s): 0.6287024021148682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 130 / 499\n",
            "LR: 8.898909402823402e-05\n",
            "Train loss: 1.0485858917236328\n",
            "\n",
            "Time (s): 0.6276865005493164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 131 / 499\n",
            "LR: 8.898891362305511e-05\n",
            "Train loss: 0.9609692096710205\n",
            "\n",
            "Time (s): 0.627068042755127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 132 / 499\n",
            "LR: 8.898873321897335e-05\n",
            "Train loss: 0.9709017872810364\n",
            "\n",
            "Time (s): 0.6279759407043457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 133 / 499\n",
            "LR: 8.89885528159888e-05\n",
            "Train loss: 0.6318803429603577\n",
            "\n",
            "Time (s): 0.6281566619873047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 134 / 499\n",
            "LR: 8.898837241410138e-05\n",
            "Train loss: 0.4480611979961395\n",
            "\n",
            "Time (s): 0.6279897689819336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 135 / 499\n",
            "LR: 8.898819201331114e-05\n",
            "Train loss: 0.8256223797798157\n",
            "\n",
            "Time (s): 0.6281571388244629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 136 / 499\n",
            "LR: 8.898801161361804e-05\n",
            "Train loss: 0.7165943384170532\n",
            "\n",
            "Time (s): 0.627605676651001\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 137 / 499\n",
            "LR: 8.898783121502206e-05\n",
            "Train loss: 0.5225512981414795\n",
            "\n",
            "Time (s): 0.6282041072845459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 138 / 499\n",
            "LR: 8.89876508175232e-05\n",
            "Train loss: 1.2053825855255127\n",
            "\n",
            "Time (s): 0.6273565292358398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 139 / 499\n",
            "LR: 8.898747042112147e-05\n",
            "Train loss: 0.5524033904075623\n",
            "\n",
            "Time (s): 0.6283063888549805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 140 / 499\n",
            "LR: 8.898729002581683e-05\n",
            "Train loss: 0.5707383155822754\n",
            "\n",
            "Time (s): 0.627532958984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 141 / 499\n",
            "LR: 8.898710963160926e-05\n",
            "Train loss: 0.6801881790161133\n",
            "\n",
            "Time (s): 0.627946138381958\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 142 / 499\n",
            "LR: 8.898692923849879e-05\n",
            "Train loss: 0.5271783471107483\n",
            "\n",
            "Time (s): 0.6229691505432129\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 143 / 499\n",
            "LR: 8.898674884648535e-05\n",
            "Train loss: 0.5996405482292175\n",
            "\n",
            "Time (s): 0.6270232200622559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 144 / 499\n",
            "LR: 8.898656845556901e-05\n",
            "Train loss: 1.0716508626937866\n",
            "\n",
            "Time (s): 0.6266458034515381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 145 / 499\n",
            "LR: 8.898638806574966e-05\n",
            "Train loss: 0.7324066162109375\n",
            "\n",
            "Time (s): 0.6274895668029785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 146 / 499\n",
            "LR: 8.898620767702738e-05\n",
            "Train loss: 0.6241634488105774\n",
            "\n",
            "Time (s): 0.6277036666870117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 147 / 499\n",
            "LR: 8.898602728940213e-05\n",
            "Train loss: 1.0982410907745361\n",
            "\n",
            "Time (s): 0.6279082298278809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 148 / 499\n",
            "LR: 8.898584690287387e-05\n",
            "Train loss: 0.48878124356269836\n",
            "\n",
            "Time (s): 0.623380184173584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 149 / 499\n",
            "LR: 8.898566651744259e-05\n",
            "Train loss: 0.960433840751648\n",
            "\n",
            "Time (s): 0.6279866695404053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 150 / 499\n",
            "LR: 8.898548613310831e-05\n",
            "Train loss: 0.4229000508785248\n",
            "\n",
            "Time (s): 0.6264467239379883\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 151 / 499\n",
            "LR: 8.898530574987102e-05\n",
            "Train loss: 1.1755414009094238\n",
            "\n",
            "Time (s): 0.6290912628173828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 152 / 499\n",
            "LR: 8.898512536773069e-05\n",
            "Train loss: 0.5142804384231567\n",
            "\n",
            "Time (s): 0.6270127296447754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 153 / 499\n",
            "LR: 8.89849449866873e-05\n",
            "Train loss: 1.3289088010787964\n",
            "\n",
            "Time (s): 0.6283674240112305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 154 / 499\n",
            "LR: 8.898476460674086e-05\n",
            "Train loss: 0.3728953003883362\n",
            "\n",
            "Time (s): 0.6227672100067139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 155 / 499\n",
            "LR: 8.898458422789135e-05\n",
            "Train loss: 1.5435011386871338\n",
            "\n",
            "Time (s): 0.6271960735321045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 156 / 499\n",
            "LR: 8.898440385013878e-05\n",
            "Train loss: 1.4222378730773926\n",
            "\n",
            "Time (s): 0.6275196075439453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 157 / 499\n",
            "LR: 8.89842234734831e-05\n",
            "Train loss: 0.8988367915153503\n",
            "\n",
            "Time (s): 0.6266884803771973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 158 / 499\n",
            "LR: 8.898404309792433e-05\n",
            "Train loss: 0.7917708158493042\n",
            "\n",
            "Time (s): 0.6230654716491699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 159 / 499\n",
            "LR: 8.898386272346244e-05\n",
            "Train loss: 1.0523782968521118\n",
            "\n",
            "Time (s): 0.6275897026062012\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 160 / 499\n",
            "LR: 8.89836823500974e-05\n",
            "Train loss: 0.9001685976982117\n",
            "\n",
            "Time (s): 0.6275086402893066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 161 / 499\n",
            "LR: 8.898350197782926e-05\n",
            "Train loss: 0.7654446363449097\n",
            "\n",
            "Time (s): 0.6273152828216553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 162 / 499\n",
            "LR: 8.898332160665797e-05\n",
            "Train loss: 0.43641728162765503\n",
            "\n",
            "Time (s): 0.6286942958831787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 163 / 499\n",
            "LR: 8.898314123658352e-05\n",
            "Train loss: 0.6597524881362915\n",
            "\n",
            "Time (s): 0.6295535564422607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 164 / 499\n",
            "LR: 8.89829608676059e-05\n",
            "Train loss: 0.7413672804832458\n",
            "\n",
            "Time (s): 0.6277642250061035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 165 / 499\n",
            "LR: 8.898278049972508e-05\n",
            "Train loss: 1.3876502513885498\n",
            "\n",
            "Time (s): 0.627500057220459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 166 / 499\n",
            "LR: 8.898260013294109e-05\n",
            "Train loss: 0.44505438208580017\n",
            "\n",
            "Time (s): 0.6276280879974365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 167 / 499\n",
            "LR: 8.898241976725388e-05\n",
            "Train loss: 0.47154954075813293\n",
            "\n",
            "Time (s): 0.6231794357299805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 168 / 499\n",
            "LR: 8.898223940266347e-05\n",
            "Train loss: 0.5641208291053772\n",
            "\n",
            "Time (s): 0.6272845268249512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 169 / 499\n",
            "LR: 8.898205903916984e-05\n",
            "Train loss: 0.9610810875892639\n",
            "\n",
            "Time (s): 0.6257109642028809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 170 / 499\n",
            "LR: 8.898187867677298e-05\n",
            "Train loss: 0.7312108874320984\n",
            "\n",
            "Time (s): 0.6257750988006592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 171 / 499\n",
            "LR: 8.898169831547286e-05\n",
            "Train loss: 0.594367265701294\n",
            "\n",
            "Time (s): 0.626955509185791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 172 / 499\n",
            "LR: 8.898151795526949e-05\n",
            "Train loss: 1.370000958442688\n",
            "\n",
            "Time (s): 0.6270585060119629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 173 / 499\n",
            "LR: 8.898133759616284e-05\n",
            "Train loss: 1.0190513134002686\n",
            "\n",
            "Time (s): 0.6286301612854004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 174 / 499\n",
            "LR: 8.898115723815291e-05\n",
            "Train loss: 0.6706908941268921\n",
            "\n",
            "Time (s): 0.6281266212463379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 175 / 499\n",
            "LR: 8.898097688123971e-05\n",
            "Train loss: 1.3868180513381958\n",
            "\n",
            "Time (s): 0.6274728775024414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 176 / 499\n",
            "LR: 8.898079652542319e-05\n",
            "Train loss: 0.32552650570869446\n",
            "\n",
            "Time (s): 0.6226375102996826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 177 / 499\n",
            "LR: 8.898061617070336e-05\n",
            "Train loss: 0.8669047355651855\n",
            "\n",
            "Time (s): 0.6230061054229736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 178 / 499\n",
            "LR: 8.898043581708021e-05\n",
            "Train loss: 0.8156968951225281\n",
            "\n",
            "Time (s): 0.623798131942749\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 179 / 499\n",
            "LR: 8.89802554645537e-05\n",
            "Train loss: 0.4006967842578888\n",
            "\n",
            "Time (s): 0.6275451183319092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 180 / 499\n",
            "LR: 8.898007511312388e-05\n",
            "Train loss: 0.626431405544281\n",
            "\n",
            "Time (s): 0.6283891201019287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 181 / 499\n",
            "LR: 8.89798947627907e-05\n",
            "Train loss: 1.1341203451156616\n",
            "\n",
            "Time (s): 0.6269059181213379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 182 / 499\n",
            "LR: 8.897971441355413e-05\n",
            "Train loss: 0.9890315532684326\n",
            "\n",
            "Time (s): 0.6276824474334717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 183 / 499\n",
            "LR: 8.89795340654142e-05\n",
            "Train loss: 0.4548332989215851\n",
            "\n",
            "Time (s): 0.6277551651000977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 184 / 499\n",
            "LR: 8.897935371837087e-05\n",
            "Train loss: 1.06691312789917\n",
            "\n",
            "Time (s): 0.6227705478668213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 185 / 499\n",
            "LR: 8.897917337242413e-05\n",
            "Train loss: 1.139000415802002\n",
            "\n",
            "Time (s): 0.6230661869049072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 186 / 499\n",
            "LR: 8.897899302757399e-05\n",
            "Train loss: 0.784329354763031\n",
            "\n",
            "Time (s): 0.6229848861694336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 187 / 499\n",
            "LR: 8.897881268382041e-05\n",
            "Train loss: 0.927137017250061\n",
            "\n",
            "Time (s): 0.6270661354064941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 188 / 499\n",
            "LR: 8.89786323411634e-05\n",
            "Train loss: 1.362572431564331\n",
            "\n",
            "Time (s): 0.6271162033081055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 189 / 499\n",
            "LR: 8.897845199960296e-05\n",
            "Train loss: 1.2861279249191284\n",
            "\n",
            "Time (s): 0.6277031898498535\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 190 / 499\n",
            "LR: 8.897827165913905e-05\n",
            "Train loss: 0.4744724631309509\n",
            "\n",
            "Time (s): 0.6282126903533936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 191 / 499\n",
            "LR: 8.897809131977165e-05\n",
            "Train loss: 1.213636875152588\n",
            "\n",
            "Time (s): 0.6231639385223389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 192 / 499\n",
            "LR: 8.89779109815008e-05\n",
            "Train loss: 0.9431767463684082\n",
            "\n",
            "Time (s): 0.623286247253418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 193 / 499\n",
            "LR: 8.897773064432645e-05\n",
            "Train loss: 0.8001953959465027\n",
            "\n",
            "Time (s): 0.6281874179840088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 194 / 499\n",
            "LR: 8.89775503082486e-05\n",
            "Train loss: 1.0993340015411377\n",
            "\n",
            "Time (s): 0.6283817291259766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 195 / 499\n",
            "LR: 8.897736997326723e-05\n",
            "Train loss: 1.315186619758606\n",
            "\n",
            "Time (s): 0.6228861808776855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 196 / 499\n",
            "LR: 8.897718963938233e-05\n",
            "Train loss: 1.0169482231140137\n",
            "\n",
            "Time (s): 0.6278965473175049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 197 / 499\n",
            "LR: 8.897700930659392e-05\n",
            "Train loss: 0.5939649343490601\n",
            "\n",
            "Time (s): 0.6231720447540283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 198 / 499\n",
            "LR: 8.897682897490194e-05\n",
            "Train loss: 0.8008503913879395\n",
            "\n",
            "Time (s): 0.6226806640625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 199 / 499\n",
            "LR: 8.897664864430641e-05\n",
            "Train loss: 0.3387570381164551\n",
            "\n",
            "Time (s): 0.6230812072753906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 200 / 499\n",
            "LR: 8.897646831480731e-05\n",
            "Train loss: 0.35178959369659424\n",
            "\n",
            "Time (s): 0.6230840682983398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 201 / 499\n",
            "LR: 8.897628798640463e-05\n",
            "Train loss: 0.5652818083763123\n",
            "\n",
            "Time (s): 0.6276333332061768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 202 / 499\n",
            "LR: 8.897610765909836e-05\n",
            "Train loss: 0.551437497138977\n",
            "\n",
            "Time (s): 0.6231627464294434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 203 / 499\n",
            "LR: 8.89759273328885e-05\n",
            "Train loss: 1.1326910257339478\n",
            "\n",
            "Time (s): 0.6235442161560059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 204 / 499\n",
            "LR: 8.897574700777501e-05\n",
            "Train loss: 0.8459605574607849\n",
            "\n",
            "Time (s): 0.6273148059844971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 205 / 499\n",
            "LR: 8.89755666837579e-05\n",
            "Train loss: 0.9573679566383362\n",
            "\n",
            "Time (s): 0.6254103183746338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 206 / 499\n",
            "LR: 8.897538636083717e-05\n",
            "Train loss: 1.0001444816589355\n",
            "\n",
            "Time (s): 0.6270756721496582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 207 / 499\n",
            "LR: 8.897520603901276e-05\n",
            "Train loss: 0.9875190258026123\n",
            "\n",
            "Time (s): 0.6287248134613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 208 / 499\n",
            "LR: 8.897502571828471e-05\n",
            "Train loss: 0.844489336013794\n",
            "\n",
            "Time (s): 0.6234962940216064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 209 / 499\n",
            "LR: 8.8974845398653e-05\n",
            "Train loss: 0.6051387190818787\n",
            "\n",
            "Time (s): 0.6272563934326172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 210 / 499\n",
            "LR: 8.89746650801176e-05\n",
            "Train loss: 1.0694153308868408\n",
            "\n",
            "Time (s): 0.6272809505462646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 211 / 499\n",
            "LR: 8.897448476267852e-05\n",
            "Train loss: 0.8812050819396973\n",
            "\n",
            "Time (s): 0.6231658458709717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 212 / 499\n",
            "LR: 8.897430444633574e-05\n",
            "Train loss: 0.3591119647026062\n",
            "\n",
            "Time (s): 0.626826286315918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 213 / 499\n",
            "LR: 8.897412413108923e-05\n",
            "Train loss: 0.889545738697052\n",
            "\n",
            "Time (s): 0.6273853778839111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 214 / 499\n",
            "LR: 8.8973943816939e-05\n",
            "Train loss: 0.9312834739685059\n",
            "\n",
            "Time (s): 0.6268024444580078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 215 / 499\n",
            "LR: 8.897376350388502e-05\n",
            "Train loss: 0.3176816403865814\n",
            "\n",
            "Time (s): 0.6255264282226562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 216 / 499\n",
            "LR: 8.897358319192733e-05\n",
            "Train loss: 0.6265208721160889\n",
            "\n",
            "Time (s): 0.6269881725311279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 217 / 499\n",
            "LR: 8.897340288106585e-05\n",
            "Train loss: 0.843997061252594\n",
            "\n",
            "Time (s): 0.6276237964630127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 218 / 499\n",
            "LR: 8.897322257130063e-05\n",
            "Train loss: 1.32283616065979\n",
            "\n",
            "Time (s): 0.6283957958221436\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 219 / 499\n",
            "LR: 8.89730422626316e-05\n",
            "Train loss: 0.5586920380592346\n",
            "\n",
            "Time (s): 0.6278121471405029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 220 / 499\n",
            "LR: 8.89728619550588e-05\n",
            "Train loss: 0.4401782751083374\n",
            "\n",
            "Time (s): 0.6232330799102783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 221 / 499\n",
            "LR: 8.89726816485822e-05\n",
            "Train loss: 0.8590034246444702\n",
            "\n",
            "Time (s): 0.6232109069824219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 222 / 499\n",
            "LR: 8.897250134320176e-05\n",
            "Train loss: 0.3478577136993408\n",
            "\n",
            "Time (s): 0.6232130527496338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 223 / 499\n",
            "LR: 8.897232103891752e-05\n",
            "Train loss: 0.822874903678894\n",
            "\n",
            "Time (s): 0.6275942325592041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 224 / 499\n",
            "LR: 8.897214073572944e-05\n",
            "Train loss: 1.079676866531372\n",
            "\n",
            "Time (s): 0.627509355545044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 225 / 499\n",
            "LR: 8.897196043363753e-05\n",
            "Train loss: 0.9640359878540039\n",
            "\n",
            "Time (s): 0.6287624835968018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 226 / 499\n",
            "LR: 8.897178013264174e-05\n",
            "Train loss: 0.39482009410858154\n",
            "\n",
            "Time (s): 0.6281187534332275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 227 / 499\n",
            "LR: 8.897159983274207e-05\n",
            "Train loss: 0.48352479934692383\n",
            "\n",
            "Time (s): 0.6296865940093994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 228 / 499\n",
            "LR: 8.897141953393854e-05\n",
            "Train loss: 1.5373330116271973\n",
            "\n",
            "Time (s): 0.6278712749481201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 229 / 499\n",
            "LR: 8.897123923623111e-05\n",
            "Train loss: 1.1477309465408325\n",
            "\n",
            "Time (s): 0.6284534931182861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 230 / 499\n",
            "LR: 8.897105893961979e-05\n",
            "Train loss: 0.4730982482433319\n",
            "\n",
            "Time (s): 0.6232643127441406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 231 / 499\n",
            "LR: 8.897087864410455e-05\n",
            "Train loss: 1.2822496891021729\n",
            "\n",
            "Time (s): 0.6268346309661865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 232 / 499\n",
            "LR: 8.897069834968538e-05\n",
            "Train loss: 0.6379261612892151\n",
            "\n",
            "Time (s): 0.6279549598693848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 233 / 499\n",
            "LR: 8.897051805636228e-05\n",
            "Train loss: 1.0204176902770996\n",
            "\n",
            "Time (s): 0.6259093284606934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 234 / 499\n",
            "LR: 8.897033776413523e-05\n",
            "Train loss: 1.0100127458572388\n",
            "\n",
            "Time (s): 0.6227672100067139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 235 / 499\n",
            "LR: 8.897015747300422e-05\n",
            "Train loss: 0.7217180728912354\n",
            "\n",
            "Time (s): 0.627504825592041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 236 / 499\n",
            "LR: 8.896997718296926e-05\n",
            "Train loss: 0.6624696254730225\n",
            "\n",
            "Time (s): 0.623532772064209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 237 / 499\n",
            "LR: 8.89697968940303e-05\n",
            "Train loss: 1.199138879776001\n",
            "\n",
            "Time (s): 0.6290316581726074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 238 / 499\n",
            "LR: 8.896961660618738e-05\n",
            "Train loss: 0.49892914295196533\n",
            "\n",
            "Time (s): 0.6310310363769531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 239 / 499\n",
            "LR: 8.896943631944042e-05\n",
            "Train loss: 0.7308108806610107\n",
            "\n",
            "Time (s): 0.6282408237457275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 240 / 499\n",
            "LR: 8.896925603378947e-05\n",
            "Train loss: 1.0434691905975342\n",
            "\n",
            "Time (s): 0.623889684677124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 241 / 499\n",
            "LR: 8.896907574923449e-05\n",
            "Train loss: 1.2265994548797607\n",
            "\n",
            "Time (s): 0.6272952556610107\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 242 / 499\n",
            "LR: 8.896889546577548e-05\n",
            "Train loss: 1.0220385789871216\n",
            "\n",
            "Time (s): 0.6280450820922852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 243 / 499\n",
            "LR: 8.896871518341242e-05\n",
            "Train loss: 0.6820751428604126\n",
            "\n",
            "Time (s): 0.6279070377349854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 244 / 499\n",
            "LR: 8.896853490214527e-05\n",
            "Train loss: 0.7031700015068054\n",
            "\n",
            "Time (s): 0.6276035308837891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 245 / 499\n",
            "LR: 8.89683546219741e-05\n",
            "Train loss: 1.0264475345611572\n",
            "\n",
            "Time (s): 0.629260778427124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 246 / 499\n",
            "LR: 8.896817434289882e-05\n",
            "Train loss: 0.4938404858112335\n",
            "\n",
            "Time (s): 0.628671407699585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 247 / 499\n",
            "LR: 8.896799406491947e-05\n",
            "Train loss: 0.3814796209335327\n",
            "\n",
            "Time (s): 0.627429723739624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 248 / 499\n",
            "LR: 8.8967813788036e-05\n",
            "Train loss: 0.8362294435501099\n",
            "\n",
            "Time (s): 0.6286110877990723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 249 / 499\n",
            "LR: 8.896763351224841e-05\n",
            "Train loss: 0.32843565940856934\n",
            "\n",
            "Time (s): 0.6277322769165039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 250 / 499\n",
            "LR: 8.896745323755673e-05\n",
            "Train loss: 0.4730508327484131\n",
            "\n",
            "Time (s): 0.6280224323272705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 251 / 499\n",
            "LR: 8.896727296396089e-05\n",
            "Train loss: 1.1134575605392456\n",
            "\n",
            "Time (s): 0.6295652389526367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 252 / 499\n",
            "LR: 8.896709269146093e-05\n",
            "Train loss: 1.0741735696792603\n",
            "\n",
            "Time (s): 0.6290102005004883\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 253 / 499\n",
            "LR: 8.896691242005679e-05\n",
            "Train loss: 0.9762872457504272\n",
            "\n",
            "Time (s): 0.6276707649230957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 254 / 499\n",
            "LR: 8.896673214974846e-05\n",
            "Train loss: 0.5210853815078735\n",
            "\n",
            "Time (s): 0.627657413482666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 255 / 499\n",
            "LR: 8.8966551880536e-05\n",
            "Train loss: 0.9301578998565674\n",
            "\n",
            "Time (s): 0.6291043758392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 256 / 499\n",
            "LR: 8.89663716124193e-05\n",
            "Train loss: 0.7158637046813965\n",
            "\n",
            "Time (s): 0.6279327869415283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 257 / 499\n",
            "LR: 8.896619134539843e-05\n",
            "Train loss: 0.9575815200805664\n",
            "\n",
            "Time (s): 0.628462553024292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 258 / 499\n",
            "LR: 8.896601107947335e-05\n",
            "Train loss: 0.5564684271812439\n",
            "\n",
            "Time (s): 0.6296398639678955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 259 / 499\n",
            "LR: 8.896583081464402e-05\n",
            "Train loss: 0.8177423477172852\n",
            "\n",
            "Time (s): 0.6288673877716064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 260 / 499\n",
            "LR: 8.896565055091048e-05\n",
            "Train loss: 0.2847936749458313\n",
            "\n",
            "Time (s): 0.6292729377746582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 261 / 499\n",
            "LR: 8.896547028827268e-05\n",
            "Train loss: 1.2351816892623901\n",
            "\n",
            "Time (s): 0.6282830238342285\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 262 / 499\n",
            "LR: 8.896529002673064e-05\n",
            "Train loss: 0.5855305194854736\n",
            "\n",
            "Time (s): 0.6278104782104492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 263 / 499\n",
            "LR: 8.896510976628432e-05\n",
            "Train loss: 1.1325129270553589\n",
            "\n",
            "Time (s): 0.6294403076171875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 264 / 499\n",
            "LR: 8.89649295069337e-05\n",
            "Train loss: 1.1292455196380615\n",
            "\n",
            "Time (s): 0.6285097599029541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 265 / 499\n",
            "LR: 8.89647492486788e-05\n",
            "Train loss: 0.7209923267364502\n",
            "\n",
            "Time (s): 0.6280367374420166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 266 / 499\n",
            "LR: 8.896456899151962e-05\n",
            "Train loss: 0.7760984301567078\n",
            "\n",
            "Time (s): 0.6284060478210449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 267 / 499\n",
            "LR: 8.896438873545611e-05\n",
            "Train loss: 1.2852662801742554\n",
            "\n",
            "Time (s): 0.6281371116638184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 268 / 499\n",
            "LR: 8.896420848048828e-05\n",
            "Train loss: 0.6092570424079895\n",
            "\n",
            "Time (s): 0.6286592483520508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 269 / 499\n",
            "LR: 8.89640282266161e-05\n",
            "Train loss: 1.0721404552459717\n",
            "\n",
            "Time (s): 0.6278190612792969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 270 / 499\n",
            "LR: 8.896384797383959e-05\n",
            "Train loss: 0.9997828602790833\n",
            "\n",
            "Time (s): 0.6288025379180908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 271 / 499\n",
            "LR: 8.896366772215873e-05\n",
            "Train loss: 0.7958808541297913\n",
            "\n",
            "Time (s): 0.6285214424133301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 272 / 499\n",
            "LR: 8.896348747157349e-05\n",
            "Train loss: 1.1864001750946045\n",
            "\n",
            "Time (s): 0.6288251876831055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 273 / 499\n",
            "LR: 8.896330722208387e-05\n",
            "Train loss: 0.5152522921562195\n",
            "\n",
            "Time (s): 0.6280956268310547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 274 / 499\n",
            "LR: 8.896312697368986e-05\n",
            "Train loss: 1.4399439096450806\n",
            "\n",
            "Time (s): 0.6285707950592041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 275 / 499\n",
            "LR: 8.896294672639146e-05\n",
            "Train loss: 0.8088126182556152\n",
            "\n",
            "Time (s): 0.6285958290100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 276 / 499\n",
            "LR: 8.896276648018862e-05\n",
            "Train loss: 1.3359442949295044\n",
            "\n",
            "Time (s): 0.6281986236572266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 277 / 499\n",
            "LR: 8.896258623508139e-05\n",
            "Train loss: 0.5191667675971985\n",
            "\n",
            "Time (s): 0.6287491321563721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 278 / 499\n",
            "LR: 8.896240599106971e-05\n",
            "Train loss: 0.3975277543067932\n",
            "\n",
            "Time (s): 0.6288037300109863\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 279 / 499\n",
            "LR: 8.896222574815358e-05\n",
            "Train loss: 0.8547706604003906\n",
            "\n",
            "Time (s): 0.6283326148986816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 280 / 499\n",
            "LR: 8.896204550633299e-05\n",
            "Train loss: 0.9133371114730835\n",
            "\n",
            "Time (s): 0.6288654804229736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 281 / 499\n",
            "LR: 8.896186526560795e-05\n",
            "Train loss: 1.0448089838027954\n",
            "\n",
            "Time (s): 0.6291756629943848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 282 / 499\n",
            "LR: 8.896168502597841e-05\n",
            "Train loss: 1.349631905555725\n",
            "\n",
            "Time (s): 0.6288402080535889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 283 / 499\n",
            "LR: 8.89615047874444e-05\n",
            "Train loss: 0.5721067190170288\n",
            "\n",
            "Time (s): 0.6284749507904053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 284 / 499\n",
            "LR: 8.896132455000587e-05\n",
            "Train loss: 0.6652515530586243\n",
            "\n",
            "Time (s): 0.6286730766296387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 285 / 499\n",
            "LR: 8.896114431366283e-05\n",
            "Train loss: 0.8053032755851746\n",
            "\n",
            "Time (s): 0.6289057731628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 286 / 499\n",
            "LR: 8.896096407841527e-05\n",
            "Train loss: 0.47854119539260864\n",
            "\n",
            "Time (s): 0.627941370010376\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 287 / 499\n",
            "LR: 8.896078384426318e-05\n",
            "Train loss: 0.43230560421943665\n",
            "\n",
            "Time (s): 0.6290688514709473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 288 / 499\n",
            "LR: 8.896060361120654e-05\n",
            "Train loss: 1.3645983934402466\n",
            "\n",
            "Time (s): 0.6282713413238525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 289 / 499\n",
            "LR: 8.896042337924535e-05\n",
            "Train loss: 0.4535711705684662\n",
            "\n",
            "Time (s): 0.628692626953125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 290 / 499\n",
            "LR: 8.896024314837957e-05\n",
            "Train loss: 0.6432310938835144\n",
            "\n",
            "Time (s): 0.6286907196044922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 291 / 499\n",
            "LR: 8.896006291860922e-05\n",
            "Train loss: 1.3457300662994385\n",
            "\n",
            "Time (s): 0.6289646625518799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 292 / 499\n",
            "LR: 8.895988268993429e-05\n",
            "Train loss: 0.38098058104515076\n",
            "\n",
            "Time (s): 0.6292762756347656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 293 / 499\n",
            "LR: 8.895970246235476e-05\n",
            "Train loss: 1.0587643384933472\n",
            "\n",
            "Time (s): 0.6317517757415771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 294 / 499\n",
            "LR: 8.895952223587061e-05\n",
            "Train loss: 1.11430823802948\n",
            "\n",
            "Time (s): 0.6293530464172363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 295 / 499\n",
            "LR: 8.895934201048184e-05\n",
            "Train loss: 0.664269745349884\n",
            "\n",
            "Time (s): 0.6288268566131592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 296 / 499\n",
            "LR: 8.895916178618844e-05\n",
            "Train loss: 0.5450124740600586\n",
            "\n",
            "Time (s): 0.623668909072876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 297 / 499\n",
            "LR: 8.895898156299039e-05\n",
            "Train loss: 0.573765218257904\n",
            "\n",
            "Time (s): 0.6285929679870605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 298 / 499\n",
            "LR: 8.895880134088767e-05\n",
            "Train loss: 0.533821702003479\n",
            "\n",
            "Time (s): 0.6277320384979248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 299 / 499\n",
            "LR: 8.89586211198803e-05\n",
            "Train loss: 1.1352664232254028\n",
            "\n",
            "Time (s): 0.6294059753417969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 300 / 499\n",
            "LR: 8.895844089996823e-05\n",
            "Train loss: 0.8492898941040039\n",
            "\n",
            "Time (s): 0.6298854351043701\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 301 / 499\n",
            "LR: 8.895826068115151e-05\n",
            "Train loss: 1.1405142545700073\n",
            "\n",
            "Time (s): 0.6264071464538574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 302 / 499\n",
            "LR: 8.895808046343004e-05\n",
            "Train loss: 0.8385412096977234\n",
            "\n",
            "Time (s): 0.6281185150146484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 303 / 499\n",
            "LR: 8.89579002468039e-05\n",
            "Train loss: 0.7584962844848633\n",
            "\n",
            "Time (s): 0.6275832653045654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 304 / 499\n",
            "LR: 8.8957720031273e-05\n",
            "Train loss: 0.7992767691612244\n",
            "\n",
            "Time (s): 0.6245298385620117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 305 / 499\n",
            "LR: 8.895753981683738e-05\n",
            "Train loss: 0.9879025816917419\n",
            "\n",
            "Time (s): 0.628615140914917\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 306 / 499\n",
            "LR: 8.895735960349703e-05\n",
            "Train loss: 0.47615599632263184\n",
            "\n",
            "Time (s): 0.6282145977020264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 307 / 499\n",
            "LR: 8.89571793912519e-05\n",
            "Train loss: 1.0714366436004639\n",
            "\n",
            "Time (s): 0.6291146278381348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 308 / 499\n",
            "LR: 8.895699918010201e-05\n",
            "Train loss: 0.8185602426528931\n",
            "\n",
            "Time (s): 0.628281831741333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 309 / 499\n",
            "LR: 8.895681897004734e-05\n",
            "Train loss: 0.9530655145645142\n",
            "\n",
            "Time (s): 0.6263422966003418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 310 / 499\n",
            "LR: 8.89566387610879e-05\n",
            "Train loss: 0.6236953139305115\n",
            "\n",
            "Time (s): 0.6292579174041748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 311 / 499\n",
            "LR: 8.895645855322362e-05\n",
            "Train loss: 0.7149176597595215\n",
            "\n",
            "Time (s): 0.6282577514648438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 312 / 499\n",
            "LR: 8.895627834645456e-05\n",
            "Train loss: 0.36876001954078674\n",
            "\n",
            "Time (s): 0.6300902366638184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 313 / 499\n",
            "LR: 8.895609814078068e-05\n",
            "Train loss: 0.7147390842437744\n",
            "\n",
            "Time (s): 0.627948522567749\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 314 / 499\n",
            "LR: 8.895591793620195e-05\n",
            "Train loss: 1.5811084508895874\n",
            "\n",
            "Time (s): 0.6286821365356445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 315 / 499\n",
            "LR: 8.895573773271837e-05\n",
            "Train loss: 0.8696097135543823\n",
            "\n",
            "Time (s): 0.629141092300415\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 316 / 499\n",
            "LR: 8.895555753032993e-05\n",
            "Train loss: 0.6632353663444519\n",
            "\n",
            "Time (s): 0.628253698348999\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 317 / 499\n",
            "LR: 8.895537732903665e-05\n",
            "Train loss: 0.771801233291626\n",
            "\n",
            "Time (s): 0.6280624866485596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 318 / 499\n",
            "LR: 8.895519712883846e-05\n",
            "Train loss: 0.5396332740783691\n",
            "\n",
            "Time (s): 0.6294865608215332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 319 / 499\n",
            "LR: 8.895501692973541e-05\n",
            "Train loss: 0.9702878594398499\n",
            "\n",
            "Time (s): 0.627723217010498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 320 / 499\n",
            "LR: 8.895483673172743e-05\n",
            "Train loss: 1.3869519233703613\n",
            "\n",
            "Time (s): 0.627938985824585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 321 / 499\n",
            "LR: 8.895465653481455e-05\n",
            "Train loss: 0.5455029606819153\n",
            "\n",
            "Time (s): 0.6294734477996826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 322 / 499\n",
            "LR: 8.895447633899676e-05\n",
            "Train loss: 0.5957372188568115\n",
            "\n",
            "Time (s): 0.6278486251831055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 323 / 499\n",
            "LR: 8.895429614427402e-05\n",
            "Train loss: 1.009477138519287\n",
            "\n",
            "Time (s): 0.628645658493042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 324 / 499\n",
            "LR: 8.895411595064634e-05\n",
            "Train loss: 0.7942943572998047\n",
            "\n",
            "Time (s): 0.6297564506530762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 325 / 499\n",
            "LR: 8.89539357581137e-05\n",
            "Train loss: 1.2200247049331665\n",
            "\n",
            "Time (s): 0.6291043758392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 326 / 499\n",
            "LR: 8.895375556667608e-05\n",
            "Train loss: 0.81606125831604\n",
            "\n",
            "Time (s): 0.628211498260498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 327 / 499\n",
            "LR: 8.895357537633349e-05\n",
            "Train loss: 0.45719072222709656\n",
            "\n",
            "Time (s): 0.6289675235748291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 328 / 499\n",
            "LR: 8.895339518708592e-05\n",
            "Train loss: 1.226416826248169\n",
            "\n",
            "Time (s): 0.6280837059020996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 329 / 499\n",
            "LR: 8.895321499893336e-05\n",
            "Train loss: 0.5694014430046082\n",
            "\n",
            "Time (s): 0.6270871162414551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 330 / 499\n",
            "LR: 8.895303481187578e-05\n",
            "Train loss: 0.38551753759384155\n",
            "\n",
            "Time (s): 0.6290881633758545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 331 / 499\n",
            "LR: 8.895285462591317e-05\n",
            "Train loss: 0.7998021245002747\n",
            "\n",
            "Time (s): 0.6279370784759521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 332 / 499\n",
            "LR: 8.895267444104553e-05\n",
            "Train loss: 0.6672868132591248\n",
            "\n",
            "Time (s): 0.6281447410583496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 333 / 499\n",
            "LR: 8.895249425727284e-05\n",
            "Train loss: 1.054503083229065\n",
            "\n",
            "Time (s): 0.6290695667266846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 334 / 499\n",
            "LR: 8.895231407459508e-05\n",
            "Train loss: 1.5847506523132324\n",
            "\n",
            "Time (s): 0.628061056137085\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 335 / 499\n",
            "LR: 8.895213389301228e-05\n",
            "Train loss: 1.0682682991027832\n",
            "\n",
            "Time (s): 0.6289551258087158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 336 / 499\n",
            "LR: 8.895195371252438e-05\n",
            "Train loss: 0.45269685983657837\n",
            "\n",
            "Time (s): 0.6276090145111084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 337 / 499\n",
            "LR: 8.895177353313142e-05\n",
            "Train loss: 0.5076963901519775\n",
            "\n",
            "Time (s): 0.6278500556945801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 338 / 499\n",
            "LR: 8.895159335483333e-05\n",
            "Train loss: 1.2627116441726685\n",
            "\n",
            "Time (s): 0.6286470890045166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 339 / 499\n",
            "LR: 8.895141317763014e-05\n",
            "Train loss: 0.9381310939788818\n",
            "\n",
            "Time (s): 0.6297969818115234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 340 / 499\n",
            "LR: 8.895123300152181e-05\n",
            "Train loss: 0.6049107313156128\n",
            "\n",
            "Time (s): 0.6291184425354004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 341 / 499\n",
            "LR: 8.895105282650837e-05\n",
            "Train loss: 0.7565283179283142\n",
            "\n",
            "Time (s): 0.6293718814849854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 342 / 499\n",
            "LR: 8.895087265258978e-05\n",
            "Train loss: 0.3144187033176422\n",
            "\n",
            "Time (s): 0.6289286613464355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 343 / 499\n",
            "LR: 8.895069247976604e-05\n",
            "Train loss: 0.6775045394897461\n",
            "\n",
            "Time (s): 0.6287405490875244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 344 / 499\n",
            "LR: 8.895051230803712e-05\n",
            "Train loss: 0.9989228248596191\n",
            "\n",
            "Time (s): 0.628889799118042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 345 / 499\n",
            "LR: 8.895033213740304e-05\n",
            "Train loss: 0.5314111113548279\n",
            "\n",
            "Time (s): 0.6286509037017822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 346 / 499\n",
            "LR: 8.895015196786374e-05\n",
            "Train loss: 1.1724342107772827\n",
            "\n",
            "Time (s): 0.6294198036193848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 347 / 499\n",
            "LR: 8.894997179941925e-05\n",
            "Train loss: 0.23497699201107025\n",
            "\n",
            "Time (s): 0.6297926902770996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 348 / 499\n",
            "LR: 8.894979163206955e-05\n",
            "Train loss: 1.3476229906082153\n",
            "\n",
            "Time (s): 0.6282558441162109\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 349 / 499\n",
            "LR: 8.894961146581463e-05\n",
            "Train loss: 0.5543862581253052\n",
            "\n",
            "Time (s): 0.6283326148986816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 350 / 499\n",
            "LR: 8.89494313006545e-05\n",
            "Train loss: 0.7534899711608887\n",
            "\n",
            "Time (s): 0.62957763671875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 351 / 499\n",
            "LR: 8.89492511365891e-05\n",
            "Train loss: 0.516386866569519\n",
            "\n",
            "Time (s): 0.6307308673858643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 352 / 499\n",
            "LR: 8.894907097361845e-05\n",
            "Train loss: 0.512037992477417\n",
            "\n",
            "Time (s): 0.6288866996765137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 353 / 499\n",
            "LR: 8.894889081174254e-05\n",
            "Train loss: 0.7629011869430542\n",
            "\n",
            "Time (s): 0.6296596527099609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 354 / 499\n",
            "LR: 8.894871065096134e-05\n",
            "Train loss: 0.48700323700904846\n",
            "\n",
            "Time (s): 0.6238515377044678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 355 / 499\n",
            "LR: 8.894853049127485e-05\n",
            "Train loss: 0.4428728222846985\n",
            "\n",
            "Time (s): 0.6279268264770508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 356 / 499\n",
            "LR: 8.894835033268306e-05\n",
            "Train loss: 0.773633599281311\n",
            "\n",
            "Time (s): 0.6237242221832275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 357 / 499\n",
            "LR: 8.894817017518596e-05\n",
            "Train loss: 0.7422587871551514\n",
            "\n",
            "Time (s): 0.6282036304473877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 358 / 499\n",
            "LR: 8.894799001878355e-05\n",
            "Train loss: 0.448350191116333\n",
            "\n",
            "Time (s): 0.6283226013183594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 359 / 499\n",
            "LR: 8.89478098634758e-05\n",
            "Train loss: 1.4754372835159302\n",
            "\n",
            "Time (s): 0.6285369396209717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 360 / 499\n",
            "LR: 8.894762970926268e-05\n",
            "Train loss: 0.5788834691047668\n",
            "\n",
            "Time (s): 0.6242320537567139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 361 / 499\n",
            "LR: 8.894744955614424e-05\n",
            "Train loss: 0.4657416045665741\n",
            "\n",
            "Time (s): 0.6242363452911377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 362 / 499\n",
            "LR: 8.894726940412042e-05\n",
            "Train loss: 1.1208057403564453\n",
            "\n",
            "Time (s): 0.6236820220947266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 363 / 499\n",
            "LR: 8.894708925319122e-05\n",
            "Train loss: 0.6938238143920898\n",
            "\n",
            "Time (s): 0.6239118576049805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 364 / 499\n",
            "LR: 8.894690910335665e-05\n",
            "Train loss: 0.7775436639785767\n",
            "\n",
            "Time (s): 0.6242020130157471\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 365 / 499\n",
            "LR: 8.894672895461667e-05\n",
            "Train loss: 0.28191497921943665\n",
            "\n",
            "Time (s): 0.6289410591125488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 366 / 499\n",
            "LR: 8.894654880697127e-05\n",
            "Train loss: 0.8461225628852844\n",
            "\n",
            "Time (s): 0.6242306232452393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 367 / 499\n",
            "LR: 8.894636866042045e-05\n",
            "Train loss: 1.3590470552444458\n",
            "\n",
            "Time (s): 0.6311068534851074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 368 / 499\n",
            "LR: 8.894618851496419e-05\n",
            "Train loss: 1.3317797183990479\n",
            "\n",
            "Time (s): 0.6338775157928467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 369 / 499\n",
            "LR: 8.89460083706025e-05\n",
            "Train loss: 0.522625744342804\n",
            "\n",
            "Time (s): 0.6310350894927979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 370 / 499\n",
            "LR: 8.894582822733536e-05\n",
            "Train loss: 0.7843645811080933\n",
            "\n",
            "Time (s): 0.628197193145752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 371 / 499\n",
            "LR: 8.894564808516272e-05\n",
            "Train loss: 0.6204622387886047\n",
            "\n",
            "Time (s): 0.6247949600219727\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 372 / 499\n",
            "LR: 8.894546794408463e-05\n",
            "Train loss: 1.162906527519226\n",
            "\n",
            "Time (s): 0.6284923553466797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 373 / 499\n",
            "LR: 8.894528780410106e-05\n",
            "Train loss: 0.3457968533039093\n",
            "\n",
            "Time (s): 0.628849983215332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 374 / 499\n",
            "LR: 8.894510766521197e-05\n",
            "Train loss: 0.6071364283561707\n",
            "\n",
            "Time (s): 0.6242406368255615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 375 / 499\n",
            "LR: 8.894492752741737e-05\n",
            "Train loss: 0.8275147676467896\n",
            "\n",
            "Time (s): 0.6294069290161133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 376 / 499\n",
            "LR: 8.894474739071725e-05\n",
            "Train loss: 0.579293966293335\n",
            "\n",
            "Time (s): 0.6255290508270264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 377 / 499\n",
            "LR: 8.894456725511161e-05\n",
            "Train loss: 1.3869760036468506\n",
            "\n",
            "Time (s): 0.6286723613739014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 378 / 499\n",
            "LR: 8.894438712060042e-05\n",
            "Train loss: 0.42207759618759155\n",
            "\n",
            "Time (s): 0.6283519268035889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 379 / 499\n",
            "LR: 8.894420698718368e-05\n",
            "Train loss: 1.0913443565368652\n",
            "\n",
            "Time (s): 0.6282627582550049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 380 / 499\n",
            "LR: 8.894402685486137e-05\n",
            "Train loss: 1.3545540571212769\n",
            "\n",
            "Time (s): 0.6292362213134766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 381 / 499\n",
            "LR: 8.894384672363346e-05\n",
            "Train loss: 0.6312752962112427\n",
            "\n",
            "Time (s): 0.6289973258972168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 382 / 499\n",
            "LR: 8.89436665935e-05\n",
            "Train loss: 1.4226802587509155\n",
            "\n",
            "Time (s): 0.6293513774871826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 383 / 499\n",
            "LR: 8.89434864644609e-05\n",
            "Train loss: 0.24977505207061768\n",
            "\n",
            "Time (s): 0.6284003257751465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 384 / 499\n",
            "LR: 8.894330633651622e-05\n",
            "Train loss: 1.0746277570724487\n",
            "\n",
            "Time (s): 0.6286725997924805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 385 / 499\n",
            "LR: 8.894312620966592e-05\n",
            "Train loss: 1.1260476112365723\n",
            "\n",
            "Time (s): 0.6241433620452881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 386 / 499\n",
            "LR: 8.894294608390996e-05\n",
            "Train loss: 0.8126161098480225\n",
            "\n",
            "Time (s): 0.624030590057373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 387 / 499\n",
            "LR: 8.894276595924838e-05\n",
            "Train loss: 0.8697413206100464\n",
            "\n",
            "Time (s): 0.6276664733886719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 388 / 499\n",
            "LR: 8.894258583568113e-05\n",
            "Train loss: 0.8169611692428589\n",
            "\n",
            "Time (s): 0.6245589256286621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 389 / 499\n",
            "LR: 8.894240571320823e-05\n",
            "Train loss: 0.47680333256721497\n",
            "\n",
            "Time (s): 0.6277828216552734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 390 / 499\n",
            "LR: 8.894222559182964e-05\n",
            "Train loss: 0.5088850259780884\n",
            "\n",
            "Time (s): 0.6241486072540283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 391 / 499\n",
            "LR: 8.894204547154537e-05\n",
            "Train loss: 0.7487770318984985\n",
            "\n",
            "Time (s): 0.6281833648681641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 392 / 499\n",
            "LR: 8.89418653523554e-05\n",
            "Train loss: 0.4248041808605194\n",
            "\n",
            "Time (s): 0.627633810043335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 393 / 499\n",
            "LR: 8.894168523425972e-05\n",
            "Train loss: 0.871204674243927\n",
            "\n",
            "Time (s): 0.6268203258514404\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 394 / 499\n",
            "LR: 8.894150511725831e-05\n",
            "Train loss: 1.094396710395813\n",
            "\n",
            "Time (s): 0.6283063888549805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 395 / 499\n",
            "LR: 8.894132500135118e-05\n",
            "Train loss: 0.9907602667808533\n",
            "\n",
            "Time (s): 0.6245038509368896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 396 / 499\n",
            "LR: 8.89411448865383e-05\n",
            "Train loss: 0.8979353904724121\n",
            "\n",
            "Time (s): 0.6281003952026367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 397 / 499\n",
            "LR: 8.894096477281968e-05\n",
            "Train loss: 0.7330204248428345\n",
            "\n",
            "Time (s): 0.6274893283843994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 398 / 499\n",
            "LR: 8.894078466019528e-05\n",
            "Train loss: 1.1392626762390137\n",
            "\n",
            "Time (s): 0.628016471862793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 399 / 499\n",
            "LR: 8.894060454866509e-05\n",
            "Train loss: 0.49760034680366516\n",
            "\n",
            "Time (s): 0.6240885257720947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 400 / 499\n",
            "LR: 8.894042443822912e-05\n",
            "Train loss: 1.036975622177124\n",
            "\n",
            "Time (s): 0.6292750835418701\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 401 / 499\n",
            "LR: 8.894024432888736e-05\n",
            "Train loss: 0.9067560434341431\n",
            "\n",
            "Time (s): 0.6236908435821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 402 / 499\n",
            "LR: 8.894006422063979e-05\n",
            "Train loss: 0.9127190113067627\n",
            "\n",
            "Time (s): 0.6242237091064453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 403 / 499\n",
            "LR: 8.893988411348641e-05\n",
            "Train loss: 0.8720724582672119\n",
            "\n",
            "Time (s): 0.6268875598907471\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 404 / 499\n",
            "LR: 8.893970400742718e-05\n",
            "Train loss: 1.2033379077911377\n",
            "\n",
            "Time (s): 0.6289522647857666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 405 / 499\n",
            "LR: 8.893952390246211e-05\n",
            "Train loss: 0.9002601504325867\n",
            "\n",
            "Time (s): 0.6241574287414551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 406 / 499\n",
            "LR: 8.89393437985912e-05\n",
            "Train loss: 1.12686288356781\n",
            "\n",
            "Time (s): 0.6241755485534668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 407 / 499\n",
            "LR: 8.89391636958144e-05\n",
            "Train loss: 0.35148999094963074\n",
            "\n",
            "Time (s): 0.6288814544677734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 408 / 499\n",
            "LR: 8.893898359413173e-05\n",
            "Train loss: 0.41631799936294556\n",
            "\n",
            "Time (s): 0.6292338371276855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 409 / 499\n",
            "LR: 8.893880349354319e-05\n",
            "Train loss: 1.0312714576721191\n",
            "\n",
            "Time (s): 0.6240041255950928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 410 / 499\n",
            "LR: 8.893862339404872e-05\n",
            "Train loss: 1.0394245386123657\n",
            "\n",
            "Time (s): 0.6283450126647949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 411 / 499\n",
            "LR: 8.893844329564838e-05\n",
            "Train loss: 1.1443411111831665\n",
            "\n",
            "Time (s): 0.6254827976226807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 412 / 499\n",
            "LR: 8.893826319834209e-05\n",
            "Train loss: 0.7026663422584534\n",
            "\n",
            "Time (s): 0.6238656044006348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 413 / 499\n",
            "LR: 8.893808310212987e-05\n",
            "Train loss: 0.46161946654319763\n",
            "\n",
            "Time (s): 0.6238100528717041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 414 / 499\n",
            "LR: 8.893790300701173e-05\n",
            "Train loss: 1.053598403930664\n",
            "\n",
            "Time (s): 0.6242842674255371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 415 / 499\n",
            "LR: 8.893772291298762e-05\n",
            "Train loss: 0.33552107214927673\n",
            "\n",
            "Time (s): 0.6284277439117432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 416 / 499\n",
            "LR: 8.893754282005754e-05\n",
            "Train loss: 1.002610206604004\n",
            "\n",
            "Time (s): 0.6308012008666992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 417 / 499\n",
            "LR: 8.893736272822149e-05\n",
            "Train loss: 0.8876672387123108\n",
            "\n",
            "Time (s): 0.6242303848266602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 418 / 499\n",
            "LR: 8.893718263747945e-05\n",
            "Train loss: 0.512201726436615\n",
            "\n",
            "Time (s): 0.6237149238586426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 419 / 499\n",
            "LR: 8.893700254783143e-05\n",
            "Train loss: 1.1009926795959473\n",
            "\n",
            "Time (s): 0.6282246112823486\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 420 / 499\n",
            "LR: 8.893682245927738e-05\n",
            "Train loss: 0.8662616610527039\n",
            "\n",
            "Time (s): 0.6268525123596191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 421 / 499\n",
            "LR: 8.893664237181731e-05\n",
            "Train loss: 0.3572290241718292\n",
            "\n",
            "Time (s): 0.6243147850036621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 422 / 499\n",
            "LR: 8.893646228545123e-05\n",
            "Train loss: 0.7047236561775208\n",
            "\n",
            "Time (s): 0.6240413188934326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 423 / 499\n",
            "LR: 8.893628220017907e-05\n",
            "Train loss: 1.0558844804763794\n",
            "\n",
            "Time (s): 0.6281082630157471\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 424 / 499\n",
            "LR: 8.893610211600088e-05\n",
            "Train loss: 1.4278441667556763\n",
            "\n",
            "Time (s): 0.6281483173370361\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 425 / 499\n",
            "LR: 8.893592203291663e-05\n",
            "Train loss: 1.23869788646698\n",
            "\n",
            "Time (s): 0.6262850761413574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 426 / 499\n",
            "LR: 8.893574195092629e-05\n",
            "Train loss: 1.0484859943389893\n",
            "\n",
            "Time (s): 0.6242129802703857\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 427 / 499\n",
            "LR: 8.893556187002987e-05\n",
            "Train loss: 0.932994544506073\n",
            "\n",
            "Time (s): 0.6288051605224609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 428 / 499\n",
            "LR: 8.893538179022734e-05\n",
            "Train loss: 0.8612799644470215\n",
            "\n",
            "Time (s): 0.6283001899719238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 429 / 499\n",
            "LR: 8.893520171151872e-05\n",
            "Train loss: 1.0159296989440918\n",
            "\n",
            "Time (s): 0.6288347244262695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 430 / 499\n",
            "LR: 8.893502163390398e-05\n",
            "Train loss: 0.4645281136035919\n",
            "\n",
            "Time (s): 0.6282930374145508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 431 / 499\n",
            "LR: 8.89348415573831e-05\n",
            "Train loss: 0.2936341166496277\n",
            "\n",
            "Time (s): 0.6265718936920166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 432 / 499\n",
            "LR: 8.893466148195607e-05\n",
            "Train loss: 0.9921926259994507\n",
            "\n",
            "Time (s): 0.6243875026702881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 433 / 499\n",
            "LR: 8.89344814076229e-05\n",
            "Train loss: 1.123153567314148\n",
            "\n",
            "Time (s): 0.628995418548584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 434 / 499\n",
            "LR: 8.893430133438357e-05\n",
            "Train loss: 1.19877028465271\n",
            "\n",
            "Time (s): 0.6280517578125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 435 / 499\n",
            "LR: 8.893412126223806e-05\n",
            "Train loss: 1.249722957611084\n",
            "\n",
            "Time (s): 0.6298744678497314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 436 / 499\n",
            "LR: 8.893394119118635e-05\n",
            "Train loss: 0.4962480962276459\n",
            "\n",
            "Time (s): 0.6235983371734619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 437 / 499\n",
            "LR: 8.893376112122845e-05\n",
            "Train loss: 0.7385706305503845\n",
            "\n",
            "Time (s): 0.6236729621887207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 438 / 499\n",
            "LR: 8.893358105236436e-05\n",
            "Train loss: 1.0215449333190918\n",
            "\n",
            "Time (s): 0.6284890174865723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 439 / 499\n",
            "LR: 8.893340098459404e-05\n",
            "Train loss: 0.9678451418876648\n",
            "\n",
            "Time (s): 0.625269889831543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 440 / 499\n",
            "LR: 8.893322091791747e-05\n",
            "Train loss: 0.8739402890205383\n",
            "\n",
            "Time (s): 0.6274936199188232\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 441 / 499\n",
            "LR: 8.893304085233467e-05\n",
            "Train loss: 0.66860431432724\n",
            "\n",
            "Time (s): 0.6297850608825684\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 442 / 499\n",
            "LR: 8.89328607878456e-05\n",
            "Train loss: 0.3356201946735382\n",
            "\n",
            "Time (s): 0.629141092300415\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 443 / 499\n",
            "LR: 8.89326807244503e-05\n",
            "Train loss: 1.2553737163543701\n",
            "\n",
            "Time (s): 0.6242280006408691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 444 / 499\n",
            "LR: 8.89325006621487e-05\n",
            "Train loss: 1.3279640674591064\n",
            "\n",
            "Time (s): 0.6285386085510254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 445 / 499\n",
            "LR: 8.893232060094084e-05\n",
            "Train loss: 1.0272103548049927\n",
            "\n",
            "Time (s): 0.6233117580413818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 446 / 499\n",
            "LR: 8.893214054082665e-05\n",
            "Train loss: 0.43839120864868164\n",
            "\n",
            "Time (s): 0.62445068359375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 447 / 499\n",
            "LR: 8.893196048180617e-05\n",
            "Train loss: 0.7269536852836609\n",
            "\n",
            "Time (s): 0.623767614364624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 448 / 499\n",
            "LR: 8.893178042387936e-05\n",
            "Train loss: 0.8872990608215332\n",
            "\n",
            "Time (s): 0.6282083988189697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 449 / 499\n",
            "LR: 8.893160036704624e-05\n",
            "Train loss: 0.44658178091049194\n",
            "\n",
            "Time (s): 0.6291482448577881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 450 / 499\n",
            "LR: 8.893142031130676e-05\n",
            "Train loss: 0.5648133754730225\n",
            "\n",
            "Time (s): 0.6240191459655762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 451 / 499\n",
            "LR: 8.893124025666095e-05\n",
            "Train loss: 0.8049979209899902\n",
            "\n",
            "Time (s): 0.6236562728881836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 452 / 499\n",
            "LR: 8.893106020310874e-05\n",
            "Train loss: 0.6522994637489319\n",
            "\n",
            "Time (s): 0.6275670528411865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 453 / 499\n",
            "LR: 8.893088015065019e-05\n",
            "Train loss: 0.7258560061454773\n",
            "\n",
            "Time (s): 0.6286251544952393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 454 / 499\n",
            "LR: 8.893070009928524e-05\n",
            "Train loss: 1.453187346458435\n",
            "\n",
            "Time (s): 0.6291060447692871\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 455 / 499\n",
            "LR: 8.893052004901388e-05\n",
            "Train loss: 1.0993095636367798\n",
            "\n",
            "Time (s): 0.6237499713897705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 456 / 499\n",
            "LR: 8.893033999983612e-05\n",
            "Train loss: 1.18434476852417\n",
            "\n",
            "Time (s): 0.6243515014648438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 457 / 499\n",
            "LR: 8.893015995175195e-05\n",
            "Train loss: 0.8220105171203613\n",
            "\n",
            "Time (s): 0.6288492679595947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 458 / 499\n",
            "LR: 8.892997990476134e-05\n",
            "Train loss: 1.1233752965927124\n",
            "\n",
            "Time (s): 0.6234300136566162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 459 / 499\n",
            "LR: 8.89297998588643e-05\n",
            "Train loss: 0.832153856754303\n",
            "\n",
            "Time (s): 0.6240870952606201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 460 / 499\n",
            "LR: 8.89296198140608e-05\n",
            "Train loss: 0.4033919870853424\n",
            "\n",
            "Time (s): 0.6274397373199463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 461 / 499\n",
            "LR: 8.892943977035085e-05\n",
            "Train loss: 0.5624662041664124\n",
            "\n",
            "Time (s): 0.628272294998169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 462 / 499\n",
            "LR: 8.892925972773441e-05\n",
            "Train loss: 1.0379854440689087\n",
            "\n",
            "Time (s): 0.6289680004119873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 463 / 499\n",
            "LR: 8.892907968621149e-05\n",
            "Train loss: 0.2649036645889282\n",
            "\n",
            "Time (s): 0.6242055892944336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 464 / 499\n",
            "LR: 8.892889964578208e-05\n",
            "Train loss: 0.961746871471405\n",
            "\n",
            "Time (s): 0.6243033409118652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 465 / 499\n",
            "LR: 8.892871960644615e-05\n",
            "Train loss: 0.6042961478233337\n",
            "\n",
            "Time (s): 0.6293151378631592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 466 / 499\n",
            "LR: 8.89285395682037e-05\n",
            "Train loss: 0.33209505677223206\n",
            "\n",
            "Time (s): 0.6263933181762695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 467 / 499\n",
            "LR: 8.892835953105473e-05\n",
            "Train loss: 0.52117919921875\n",
            "\n",
            "Time (s): 0.6281185150146484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 468 / 499\n",
            "LR: 8.892817949499921e-05\n",
            "Train loss: 0.8085787296295166\n",
            "\n",
            "Time (s): 0.6261904239654541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 469 / 499\n",
            "LR: 8.892799946003715e-05\n",
            "Train loss: 0.9618326425552368\n",
            "\n",
            "Time (s): 0.6237990856170654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 470 / 499\n",
            "LR: 8.892781942616853e-05\n",
            "Train loss: 0.7067238092422485\n",
            "\n",
            "Time (s): 0.6288895606994629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 471 / 499\n",
            "LR: 8.892763939339332e-05\n",
            "Train loss: 0.568289577960968\n",
            "\n",
            "Time (s): 0.6242763996124268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 472 / 499\n",
            "LR: 8.892745936171152e-05\n",
            "Train loss: 0.7763404846191406\n",
            "\n",
            "Time (s): 0.62860107421875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 473 / 499\n",
            "LR: 8.892727933112316e-05\n",
            "Train loss: 0.4473859369754791\n",
            "\n",
            "Time (s): 0.6289982795715332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 474 / 499\n",
            "LR: 8.892709930162814e-05\n",
            "Train loss: 1.3430073261260986\n",
            "\n",
            "Time (s): 0.6274776458740234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 475 / 499\n",
            "LR: 8.892691927322653e-05\n",
            "Train loss: 0.5365451574325562\n",
            "\n",
            "Time (s): 0.6250813007354736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 476 / 499\n",
            "LR: 8.89267392459183e-05\n",
            "Train loss: 0.8388445973396301\n",
            "\n",
            "Time (s): 0.628040075302124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 477 / 499\n",
            "LR: 8.892655921970342e-05\n",
            "Train loss: 1.0977741479873657\n",
            "\n",
            "Time (s): 0.6235780715942383\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 478 / 499\n",
            "LR: 8.89263791945819e-05\n",
            "Train loss: 0.9821233749389648\n",
            "\n",
            "Time (s): 0.6280479431152344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 479 / 499\n",
            "LR: 8.89261991705537e-05\n",
            "Train loss: 1.1372897624969482\n",
            "\n",
            "Time (s): 0.6285696029663086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 480 / 499\n",
            "LR: 8.892601914761884e-05\n",
            "Train loss: 1.2035712003707886\n",
            "\n",
            "Time (s): 0.6292397975921631\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 481 / 499\n",
            "LR: 8.892583912577729e-05\n",
            "Train loss: 1.0024263858795166\n",
            "\n",
            "Time (s): 0.6269500255584717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 482 / 499\n",
            "LR: 8.892565910502904e-05\n",
            "Train loss: 0.7564234137535095\n",
            "\n",
            "Time (s): 0.6287360191345215\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 483 / 499\n",
            "LR: 8.892547908537408e-05\n",
            "Train loss: 1.0698809623718262\n",
            "\n",
            "Time (s): 0.6295771598815918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 484 / 499\n",
            "LR: 8.892529906681242e-05\n",
            "Train loss: 1.2148329019546509\n",
            "\n",
            "Time (s): 0.6284899711608887\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 485 / 499\n",
            "LR: 8.892511904934401e-05\n",
            "Train loss: 0.883599579334259\n",
            "\n",
            "Time (s): 0.6238393783569336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 486 / 499\n",
            "LR: 8.892493903296886e-05\n",
            "Train loss: 0.8906082510948181\n",
            "\n",
            "Time (s): 0.6279091835021973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 487 / 499\n",
            "LR: 8.892475901768698e-05\n",
            "Train loss: 0.24709056317806244\n",
            "\n",
            "Time (s): 0.6281871795654297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 488 / 499\n",
            "LR: 8.892457900349832e-05\n",
            "Train loss: 0.43221431970596313\n",
            "\n",
            "Time (s): 0.6235957145690918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 489 / 499\n",
            "LR: 8.892439899040288e-05\n",
            "Train loss: 1.3593600988388062\n",
            "\n",
            "Time (s): 0.6239378452301025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 490 / 499\n",
            "LR: 8.892421897840067e-05\n",
            "Train loss: 0.5932260751724243\n",
            "\n",
            "Time (s): 0.6282863616943359\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 491 / 499\n",
            "LR: 8.892403896749167e-05\n",
            "Train loss: 0.7642649412155151\n",
            "\n",
            "Time (s): 0.624251127243042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 492 / 499\n",
            "LR: 8.892385895767586e-05\n",
            "Train loss: 0.6127632856369019\n",
            "\n",
            "Time (s): 0.6286802291870117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 493 / 499\n",
            "LR: 8.892367894895323e-05\n",
            "Train loss: 0.7324447631835938\n",
            "\n",
            "Time (s): 0.6242680549621582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 494 / 499\n",
            "LR: 8.892349894132378e-05\n",
            "Train loss: 0.5437315106391907\n",
            "\n",
            "Time (s): 0.6239333152770996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 495 / 499\n",
            "LR: 8.892331893478746e-05\n",
            "Train loss: 0.39485421776771545\n",
            "\n",
            "Time (s): 0.6276721954345703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 496 / 499\n",
            "LR: 8.892313892934432e-05\n",
            "Train loss: 0.9125259518623352\n",
            "\n",
            "Time (s): 0.627694845199585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 497 / 499\n",
            "LR: 8.892295892499431e-05\n",
            "Train loss: 0.4883502721786499\n",
            "\n",
            "Time (s): 0.6260476112365723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 498 / 499\n",
            "LR: 8.892277892173743e-05\n",
            "Train loss: 1.47031831741333\n",
            "\n",
            "Time (s): 0.6289033889770508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 495  Batch 499 / 499\n",
            "LR: 8.892259891957366e-05\n",
            "Train loss: 2.132293701171875\n",
            "\n",
            "Time (s): 0.05069875717163086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 495\n",
            "Avg train loss: 0.7050277403217996\n",
            "Avg train acc: 0.7914939913338793\n",
            "Avg eval loss: 0.8990144186160144\n",
            "Avg eval acc: 0.7528695814749774\n",
            "=========================\n",
            "\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 1 / 499\n",
            "LR: 8.8922418918503e-05\n",
            "Train loss: 1.1094512939453125\n",
            "\n",
            "Time (s): 0.6294727325439453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 2 / 499\n",
            "LR: 8.892223891852543e-05\n",
            "Train loss: 1.0131534337997437\n",
            "\n",
            "Time (s): 0.6264603137969971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 3 / 499\n",
            "LR: 8.892205891964094e-05\n",
            "Train loss: 0.6440118551254272\n",
            "\n",
            "Time (s): 0.6288342475891113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 4 / 499\n",
            "LR: 8.892187892184954e-05\n",
            "Train loss: 0.38676851987838745\n",
            "\n",
            "Time (s): 0.6278836727142334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 5 / 499\n",
            "LR: 8.892169892515116e-05\n",
            "Train loss: 0.8991538286209106\n",
            "\n",
            "Time (s): 0.6279902458190918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 6 / 499\n",
            "LR: 8.892151892954587e-05\n",
            "Train loss: 0.367083340883255\n",
            "\n",
            "Time (s): 0.6299135684967041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 7 / 499\n",
            "LR: 8.892133893503362e-05\n",
            "Train loss: 0.4834294319152832\n",
            "\n",
            "Time (s): 0.6289093494415283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 8 / 499\n",
            "LR: 8.892115894161438e-05\n",
            "Train loss: 0.8157501220703125\n",
            "\n",
            "Time (s): 0.6275532245635986\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 9 / 499\n",
            "LR: 8.892097894928815e-05\n",
            "Train loss: 0.5761762261390686\n",
            "\n",
            "Time (s): 0.6288669109344482\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 10 / 499\n",
            "LR: 8.892079895805493e-05\n",
            "Train loss: 0.8902847766876221\n",
            "\n",
            "Time (s): 0.6291518211364746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 11 / 499\n",
            "LR: 8.89206189679147e-05\n",
            "Train loss: 0.8150052428245544\n",
            "\n",
            "Time (s): 0.627918004989624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 12 / 499\n",
            "LR: 8.892043897886748e-05\n",
            "Train loss: 0.9204169511795044\n",
            "\n",
            "Time (s): 0.6285085678100586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 13 / 499\n",
            "LR: 8.892025899091321e-05\n",
            "Train loss: 0.6079835891723633\n",
            "\n",
            "Time (s): 0.6289453506469727\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 14 / 499\n",
            "LR: 8.892007900405191e-05\n",
            "Train loss: 0.7888811826705933\n",
            "\n",
            "Time (s): 0.6236796379089355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 15 / 499\n",
            "LR: 8.891989901828357e-05\n",
            "Train loss: 0.5619102716445923\n",
            "\n",
            "Time (s): 0.6285445690155029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 16 / 499\n",
            "LR: 8.891971903360815e-05\n",
            "Train loss: 0.5572022199630737\n",
            "\n",
            "Time (s): 0.6296982765197754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 17 / 499\n",
            "LR: 8.891953905002567e-05\n",
            "Train loss: 0.4669097065925598\n",
            "\n",
            "Time (s): 0.6243064403533936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 18 / 499\n",
            "LR: 8.891935906753609e-05\n",
            "Train loss: 0.5638986229896545\n",
            "\n",
            "Time (s): 0.6280035972595215\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 19 / 499\n",
            "LR: 8.891917908613943e-05\n",
            "Train loss: 1.5656838417053223\n",
            "\n",
            "Time (s): 0.6285178661346436\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 20 / 499\n",
            "LR: 8.891899910583565e-05\n",
            "Train loss: 1.0182284116744995\n",
            "\n",
            "Time (s): 0.6237833499908447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 21 / 499\n",
            "LR: 8.891881912662478e-05\n",
            "Train loss: 1.3409066200256348\n",
            "\n",
            "Time (s): 0.6276810169219971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 22 / 499\n",
            "LR: 8.891863914850676e-05\n",
            "Train loss: 0.8313805460929871\n",
            "\n",
            "Time (s): 0.6271660327911377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 23 / 499\n",
            "LR: 8.891845917148162e-05\n",
            "Train loss: 0.9193203449249268\n",
            "\n",
            "Time (s): 0.6286396980285645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 24 / 499\n",
            "LR: 8.891827919554932e-05\n",
            "Train loss: 0.9155759811401367\n",
            "\n",
            "Time (s): 0.6243181228637695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 25 / 499\n",
            "LR: 8.891809922070987e-05\n",
            "Train loss: 0.6961728930473328\n",
            "\n",
            "Time (s): 0.6283769607543945\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 26 / 499\n",
            "LR: 8.891791924696323e-05\n",
            "Train loss: 0.6514150500297546\n",
            "\n",
            "Time (s): 0.6251237392425537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 27 / 499\n",
            "LR: 8.891773927430942e-05\n",
            "Train loss: 0.5927736759185791\n",
            "\n",
            "Time (s): 0.6292440891265869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 28 / 499\n",
            "LR: 8.89175593027484e-05\n",
            "Train loss: 1.1459450721740723\n",
            "\n",
            "Time (s): 0.628028392791748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 29 / 499\n",
            "LR: 8.89173793322802e-05\n",
            "Train loss: 0.9822419881820679\n",
            "\n",
            "Time (s): 0.6284117698669434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 30 / 499\n",
            "LR: 8.891719936290477e-05\n",
            "Train loss: 0.7170635461807251\n",
            "\n",
            "Time (s): 0.625586748123169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 31 / 499\n",
            "LR: 8.891701939462213e-05\n",
            "Train loss: 1.5594780445098877\n",
            "\n",
            "Time (s): 0.6238193511962891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 32 / 499\n",
            "LR: 8.891683942743224e-05\n",
            "Train loss: 0.8911166191101074\n",
            "\n",
            "Time (s): 0.6237130165100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 33 / 499\n",
            "LR: 8.891665946133508e-05\n",
            "Train loss: 1.4824374914169312\n",
            "\n",
            "Time (s): 0.6242303848266602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 34 / 499\n",
            "LR: 8.891647949633069e-05\n",
            "Train loss: 0.8472127914428711\n",
            "\n",
            "Time (s): 0.6286134719848633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 35 / 499\n",
            "LR: 8.891629953241902e-05\n",
            "Train loss: 0.5790480375289917\n",
            "\n",
            "Time (s): 0.6277780532836914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 36 / 499\n",
            "LR: 8.891611956960007e-05\n",
            "Train loss: 0.6625364422798157\n",
            "\n",
            "Time (s): 0.6278970241546631\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 37 / 499\n",
            "LR: 8.891593960787382e-05\n",
            "Train loss: 0.582421600818634\n",
            "\n",
            "Time (s): 0.6254868507385254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 38 / 499\n",
            "LR: 8.891575964724026e-05\n",
            "Train loss: 0.7680156230926514\n",
            "\n",
            "Time (s): 0.6270897388458252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 39 / 499\n",
            "LR: 8.89155796876994e-05\n",
            "Train loss: 0.687192440032959\n",
            "\n",
            "Time (s): 0.6247851848602295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 40 / 499\n",
            "LR: 8.891539972925122e-05\n",
            "Train loss: 1.1288048028945923\n",
            "\n",
            "Time (s): 0.6240761280059814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 41 / 499\n",
            "LR: 8.891521977189568e-05\n",
            "Train loss: 0.5964148640632629\n",
            "\n",
            "Time (s): 0.6283907890319824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 42 / 499\n",
            "LR: 8.89150398156328e-05\n",
            "Train loss: 0.8616563677787781\n",
            "\n",
            "Time (s): 0.6236753463745117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 43 / 499\n",
            "LR: 8.891485986046256e-05\n",
            "Train loss: 0.8723852038383484\n",
            "\n",
            "Time (s): 0.6236212253570557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 44 / 499\n",
            "LR: 8.891467990638496e-05\n",
            "Train loss: 0.6598518490791321\n",
            "\n",
            "Time (s): 0.6235735416412354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 45 / 499\n",
            "LR: 8.891449995339998e-05\n",
            "Train loss: 0.860377848148346\n",
            "\n",
            "Time (s): 0.628748893737793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 46 / 499\n",
            "LR: 8.89143200015076e-05\n",
            "Train loss: 0.5860761404037476\n",
            "\n",
            "Time (s): 0.6229791641235352\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 47 / 499\n",
            "LR: 8.89141400507078e-05\n",
            "Train loss: 0.4593203663825989\n",
            "\n",
            "Time (s): 0.622866153717041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 48 / 499\n",
            "LR: 8.89139601010006e-05\n",
            "Train loss: 0.48783451318740845\n",
            "\n",
            "Time (s): 0.6281716823577881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 49 / 499\n",
            "LR: 8.891378015238598e-05\n",
            "Train loss: 1.5132747888565063\n",
            "\n",
            "Time (s): 0.6227757930755615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 50 / 499\n",
            "LR: 8.891360020486391e-05\n",
            "Train loss: 0.6573161482810974\n",
            "\n",
            "Time (s): 0.6284217834472656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 51 / 499\n",
            "LR: 8.891342025843441e-05\n",
            "Train loss: 1.174045205116272\n",
            "\n",
            "Time (s): 0.6277778148651123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 52 / 499\n",
            "LR: 8.891324031309743e-05\n",
            "Train loss: 0.6278668642044067\n",
            "\n",
            "Time (s): 0.627915620803833\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 53 / 499\n",
            "LR: 8.8913060368853e-05\n",
            "Train loss: 0.9268837571144104\n",
            "\n",
            "Time (s): 0.6278805732727051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 54 / 499\n",
            "LR: 8.891288042570107e-05\n",
            "Train loss: 0.708730936050415\n",
            "\n",
            "Time (s): 0.6273078918457031\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 55 / 499\n",
            "LR: 8.891270048364166e-05\n",
            "Train loss: 0.732812762260437\n",
            "\n",
            "Time (s): 0.6271710395812988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 56 / 499\n",
            "LR: 8.891252054267475e-05\n",
            "Train loss: 1.1313215494155884\n",
            "\n",
            "Time (s): 0.6278378963470459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 57 / 499\n",
            "LR: 8.891234060280034e-05\n",
            "Train loss: 1.1283894777297974\n",
            "\n",
            "Time (s): 0.622870922088623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 58 / 499\n",
            "LR: 8.891216066401836e-05\n",
            "Train loss: 1.0183991193771362\n",
            "\n",
            "Time (s): 0.6233034133911133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 59 / 499\n",
            "LR: 8.891198072632887e-05\n",
            "Train loss: 0.6632789373397827\n",
            "\n",
            "Time (s): 0.6282501220703125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 60 / 499\n",
            "LR: 8.891180078973184e-05\n",
            "Train loss: 0.2885802388191223\n",
            "\n",
            "Time (s): 0.6274724006652832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 61 / 499\n",
            "LR: 8.891162085422723e-05\n",
            "Train loss: 0.7556454539299011\n",
            "\n",
            "Time (s): 0.6281797885894775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 62 / 499\n",
            "LR: 8.891144091981508e-05\n",
            "Train loss: 0.961410641670227\n",
            "\n",
            "Time (s): 0.6286461353302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 63 / 499\n",
            "LR: 8.891126098649533e-05\n",
            "Train loss: 1.2180331945419312\n",
            "\n",
            "Time (s): 0.6232290267944336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 64 / 499\n",
            "LR: 8.8911081054268e-05\n",
            "Train loss: 1.339975118637085\n",
            "\n",
            "Time (s): 0.6283423900604248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 65 / 499\n",
            "LR: 8.891090112313305e-05\n",
            "Train loss: 0.7181785702705383\n",
            "\n",
            "Time (s): 0.6232089996337891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 66 / 499\n",
            "LR: 8.891072119309049e-05\n",
            "Train loss: 0.968609094619751\n",
            "\n",
            "Time (s): 0.6280496120452881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 67 / 499\n",
            "LR: 8.891054126414032e-05\n",
            "Train loss: 0.5318603515625\n",
            "\n",
            "Time (s): 0.6232640743255615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 68 / 499\n",
            "LR: 8.891036133628248e-05\n",
            "Train loss: 1.0682042837142944\n",
            "\n",
            "Time (s): 0.6234476566314697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 69 / 499\n",
            "LR: 8.891018140951703e-05\n",
            "Train loss: 0.9776986241340637\n",
            "\n",
            "Time (s): 0.6275515556335449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 70 / 499\n",
            "LR: 8.891000148384392e-05\n",
            "Train loss: 0.34833958745002747\n",
            "\n",
            "Time (s): 0.6231567859649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 71 / 499\n",
            "LR: 8.890982155926312e-05\n",
            "Train loss: 0.4674738943576813\n",
            "\n",
            "Time (s): 0.6270716190338135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 72 / 499\n",
            "LR: 8.890964163577465e-05\n",
            "Train loss: 0.8212717175483704\n",
            "\n",
            "Time (s): 0.6267337799072266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 73 / 499\n",
            "LR: 8.89094617133785e-05\n",
            "Train loss: 0.5887061953544617\n",
            "\n",
            "Time (s): 0.6233842372894287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 74 / 499\n",
            "LR: 8.890928179207463e-05\n",
            "Train loss: 0.3311297297477722\n",
            "\n",
            "Time (s): 0.6275501251220703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 75 / 499\n",
            "LR: 8.890910187186306e-05\n",
            "Train loss: 0.7035195231437683\n",
            "\n",
            "Time (s): 0.6229565143585205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 76 / 499\n",
            "LR: 8.890892195274376e-05\n",
            "Train loss: 0.4355623126029968\n",
            "\n",
            "Time (s): 0.6275656223297119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 77 / 499\n",
            "LR: 8.890874203471674e-05\n",
            "Train loss: 0.47549185156822205\n",
            "\n",
            "Time (s): 0.6254863739013672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 78 / 499\n",
            "LR: 8.890856211778194e-05\n",
            "Train loss: 0.3757880628108978\n",
            "\n",
            "Time (s): 0.6228163242340088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 79 / 499\n",
            "LR: 8.890838220193939e-05\n",
            "Train loss: 0.462660014629364\n",
            "\n",
            "Time (s): 0.6274280548095703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 80 / 499\n",
            "LR: 8.890820228718908e-05\n",
            "Train loss: 1.1817882061004639\n",
            "\n",
            "Time (s): 0.6232032775878906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 81 / 499\n",
            "LR: 8.890802237353099e-05\n",
            "Train loss: 0.7489144206047058\n",
            "\n",
            "Time (s): 0.6227991580963135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 82 / 499\n",
            "LR: 8.890784246096512e-05\n",
            "Train loss: 0.8096345663070679\n",
            "\n",
            "Time (s): 0.6280984878540039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 83 / 499\n",
            "LR: 8.890766254949145e-05\n",
            "Train loss: 1.7481976747512817\n",
            "\n",
            "Time (s): 0.6230549812316895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 84 / 499\n",
            "LR: 8.890748263910996e-05\n",
            "Train loss: 0.5842443704605103\n",
            "\n",
            "Time (s): 0.6264104843139648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 85 / 499\n",
            "LR: 8.890730272982064e-05\n",
            "Train loss: 1.0531024932861328\n",
            "\n",
            "Time (s): 0.6282274723052979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 86 / 499\n",
            "LR: 8.890712282162348e-05\n",
            "Train loss: 1.15796959400177\n",
            "\n",
            "Time (s): 0.6229197978973389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 87 / 499\n",
            "LR: 8.89069429145185e-05\n",
            "Train loss: 1.3545984029769897\n",
            "\n",
            "Time (s): 0.6231982707977295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 88 / 499\n",
            "LR: 8.890676300850564e-05\n",
            "Train loss: 0.45903804898262024\n",
            "\n",
            "Time (s): 0.6232120990753174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 89 / 499\n",
            "LR: 8.890658310358493e-05\n",
            "Train loss: 0.6763198375701904\n",
            "\n",
            "Time (s): 0.6272714138031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 90 / 499\n",
            "LR: 8.890640319975633e-05\n",
            "Train loss: 1.0265439748764038\n",
            "\n",
            "Time (s): 0.6234793663024902\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 91 / 499\n",
            "LR: 8.890622329701982e-05\n",
            "Train loss: 0.4957979917526245\n",
            "\n",
            "Time (s): 0.6234416961669922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 92 / 499\n",
            "LR: 8.890604339537545e-05\n",
            "Train loss: 1.2178363800048828\n",
            "\n",
            "Time (s): 0.6272773742675781\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 93 / 499\n",
            "LR: 8.890586349482313e-05\n",
            "Train loss: 0.4129531681537628\n",
            "\n",
            "Time (s): 0.626903772354126\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 94 / 499\n",
            "LR: 8.890568359536292e-05\n",
            "Train loss: 0.7896957993507385\n",
            "\n",
            "Time (s): 0.6275472640991211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 95 / 499\n",
            "LR: 8.890550369699476e-05\n",
            "Train loss: 0.7400349974632263\n",
            "\n",
            "Time (s): 0.6274540424346924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 96 / 499\n",
            "LR: 8.890532379971865e-05\n",
            "Train loss: 0.7763949632644653\n",
            "\n",
            "Time (s): 0.6273601055145264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 97 / 499\n",
            "LR: 8.890514390353459e-05\n",
            "Train loss: 0.619023323059082\n",
            "\n",
            "Time (s): 0.6231136322021484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 98 / 499\n",
            "LR: 8.890496400844255e-05\n",
            "Train loss: 0.9103294610977173\n",
            "\n",
            "Time (s): 0.6287844181060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 99 / 499\n",
            "LR: 8.890478411444257e-05\n",
            "Train loss: 0.5395151972770691\n",
            "\n",
            "Time (s): 0.6270542144775391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 100 / 499\n",
            "LR: 8.890460422153454e-05\n",
            "Train loss: 1.345430612564087\n",
            "\n",
            "Time (s): 0.6269130706787109\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 101 / 499\n",
            "LR: 8.890442432971855e-05\n",
            "Train loss: 1.4390459060668945\n",
            "\n",
            "Time (s): 0.6282980442047119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 102 / 499\n",
            "LR: 8.890424443899455e-05\n",
            "Train loss: 0.5095750093460083\n",
            "\n",
            "Time (s): 0.627934455871582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 103 / 499\n",
            "LR: 8.890406454936252e-05\n",
            "Train loss: 1.2999863624572754\n",
            "\n",
            "Time (s): 0.628065824508667\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 104 / 499\n",
            "LR: 8.890388466082246e-05\n",
            "Train loss: 1.1581196784973145\n",
            "\n",
            "Time (s): 0.6278860569000244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 105 / 499\n",
            "LR: 8.890370477337434e-05\n",
            "Train loss: 0.41815707087516785\n",
            "\n",
            "Time (s): 0.6232116222381592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 106 / 499\n",
            "LR: 8.890352488701818e-05\n",
            "Train loss: 0.6285008788108826\n",
            "\n",
            "Time (s): 0.6272447109222412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 107 / 499\n",
            "LR: 8.890334500175394e-05\n",
            "Train loss: 1.1969256401062012\n",
            "\n",
            "Time (s): 0.6231274604797363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 108 / 499\n",
            "LR: 8.890316511758165e-05\n",
            "Train loss: 0.5033130645751953\n",
            "\n",
            "Time (s): 0.6281342506408691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 109 / 499\n",
            "LR: 8.890298523450124e-05\n",
            "Train loss: 1.0077006816864014\n",
            "\n",
            "Time (s): 0.623333215713501\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 110 / 499\n",
            "LR: 8.890280535251274e-05\n",
            "Train loss: 0.3341553211212158\n",
            "\n",
            "Time (s): 0.6278476715087891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 111 / 499\n",
            "LR: 8.890262547161615e-05\n",
            "Train loss: 0.8636460304260254\n",
            "\n",
            "Time (s): 0.6278207302093506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 112 / 499\n",
            "LR: 8.89024455918114e-05\n",
            "Train loss: 0.45161378383636475\n",
            "\n",
            "Time (s): 0.627748966217041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 113 / 499\n",
            "LR: 8.890226571309853e-05\n",
            "Train loss: 1.0273853540420532\n",
            "\n",
            "Time (s): 0.6232664585113525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 114 / 499\n",
            "LR: 8.890208583547753e-05\n",
            "Train loss: 0.7149825692176819\n",
            "\n",
            "Time (s): 0.6230685710906982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 115 / 499\n",
            "LR: 8.890190595894837e-05\n",
            "Train loss: 0.506320595741272\n",
            "\n",
            "Time (s): 0.6279487609863281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 116 / 499\n",
            "LR: 8.890172608351105e-05\n",
            "Train loss: 0.4739435017108917\n",
            "\n",
            "Time (s): 0.6231896877288818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 117 / 499\n",
            "LR: 8.890154620916554e-05\n",
            "Train loss: 1.2947434186935425\n",
            "\n",
            "Time (s): 0.6275997161865234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 118 / 499\n",
            "LR: 8.890136633591182e-05\n",
            "Train loss: 1.1620583534240723\n",
            "\n",
            "Time (s): 0.623755931854248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 119 / 499\n",
            "LR: 8.890118646374994e-05\n",
            "Train loss: 0.3677752912044525\n",
            "\n",
            "Time (s): 0.6278784275054932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 120 / 499\n",
            "LR: 8.890100659267983e-05\n",
            "Train loss: 1.6077431440353394\n",
            "\n",
            "Time (s): 0.6272592544555664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 121 / 499\n",
            "LR: 8.89008267227015e-05\n",
            "Train loss: 1.392212986946106\n",
            "\n",
            "Time (s): 0.6269364356994629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 122 / 499\n",
            "LR: 8.890064685381494e-05\n",
            "Train loss: 0.7492666244506836\n",
            "\n",
            "Time (s): 0.6271655559539795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 123 / 499\n",
            "LR: 8.890046698602014e-05\n",
            "Train loss: 0.7367255687713623\n",
            "\n",
            "Time (s): 0.6297159194946289\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 124 / 499\n",
            "LR: 8.89002871193171e-05\n",
            "Train loss: 0.8592270612716675\n",
            "\n",
            "Time (s): 0.6313230991363525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 125 / 499\n",
            "LR: 8.890010725370576e-05\n",
            "Train loss: 0.42243075370788574\n",
            "\n",
            "Time (s): 0.6294436454772949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 126 / 499\n",
            "LR: 8.889992738918617e-05\n",
            "Train loss: 0.5610010027885437\n",
            "\n",
            "Time (s): 0.6286618709564209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 127 / 499\n",
            "LR: 8.889974752575827e-05\n",
            "Train loss: 0.8086020946502686\n",
            "\n",
            "Time (s): 0.6297507286071777\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 128 / 499\n",
            "LR: 8.889956766342209e-05\n",
            "Train loss: 0.5400485992431641\n",
            "\n",
            "Time (s): 0.6277313232421875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 129 / 499\n",
            "LR: 8.88993878021776e-05\n",
            "Train loss: 0.37487155199050903\n",
            "\n",
            "Time (s): 0.6281049251556396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 130 / 499\n",
            "LR: 8.88992079420248e-05\n",
            "Train loss: 0.6196795701980591\n",
            "\n",
            "Time (s): 0.6286773681640625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 131 / 499\n",
            "LR: 8.889902808296364e-05\n",
            "Train loss: 0.48806560039520264\n",
            "\n",
            "Time (s): 0.6281125545501709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 132 / 499\n",
            "LR: 8.889884822499414e-05\n",
            "Train loss: 1.2251079082489014\n",
            "\n",
            "Time (s): 0.6283199787139893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 133 / 499\n",
            "LR: 8.889866836811629e-05\n",
            "Train loss: 1.0183225870132446\n",
            "\n",
            "Time (s): 0.6281907558441162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 134 / 499\n",
            "LR: 8.88984885123301e-05\n",
            "Train loss: 1.4097625017166138\n",
            "\n",
            "Time (s): 0.6281464099884033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 135 / 499\n",
            "LR: 8.88983086576355e-05\n",
            "Train loss: 1.002944827079773\n",
            "\n",
            "Time (s): 0.6290304660797119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 136 / 499\n",
            "LR: 8.889812880403253e-05\n",
            "Train loss: 1.4616987705230713\n",
            "\n",
            "Time (s): 0.6292927265167236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 137 / 499\n",
            "LR: 8.889794895152116e-05\n",
            "Train loss: 0.5588962435722351\n",
            "\n",
            "Time (s): 0.6242814064025879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 138 / 499\n",
            "LR: 8.889776910010138e-05\n",
            "Train loss: 0.9420031309127808\n",
            "\n",
            "Time (s): 0.6276957988739014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 139 / 499\n",
            "LR: 8.889758924977319e-05\n",
            "Train loss: 0.6425192356109619\n",
            "\n",
            "Time (s): 0.6238718032836914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 140 / 499\n",
            "LR: 8.889740940053654e-05\n",
            "Train loss: 1.6285696029663086\n",
            "\n",
            "Time (s): 0.6237971782684326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 141 / 499\n",
            "LR: 8.889722955239147e-05\n",
            "Train loss: 0.8350738883018494\n",
            "\n",
            "Time (s): 0.6284921169281006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 142 / 499\n",
            "LR: 8.889704970533794e-05\n",
            "Train loss: 1.184838056564331\n",
            "\n",
            "Time (s): 0.6297183036804199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 143 / 499\n",
            "LR: 8.889686985937596e-05\n",
            "Train loss: 0.9253092408180237\n",
            "\n",
            "Time (s): 0.6279385089874268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 144 / 499\n",
            "LR: 8.889669001450549e-05\n",
            "Train loss: 0.7560425400733948\n",
            "\n",
            "Time (s): 0.6290867328643799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 145 / 499\n",
            "LR: 8.889651017072654e-05\n",
            "Train loss: 1.038981318473816\n",
            "\n",
            "Time (s): 0.6238644123077393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 146 / 499\n",
            "LR: 8.889633032803908e-05\n",
            "Train loss: 0.9692338705062866\n",
            "\n",
            "Time (s): 0.6240336894989014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 147 / 499\n",
            "LR: 8.889615048644313e-05\n",
            "Train loss: 1.1848119497299194\n",
            "\n",
            "Time (s): 0.6239054203033447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 148 / 499\n",
            "LR: 8.889597064593866e-05\n",
            "Train loss: 0.9700994491577148\n",
            "\n",
            "Time (s): 0.626657247543335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 149 / 499\n",
            "LR: 8.889579080652563e-05\n",
            "Train loss: 0.7739138007164001\n",
            "\n",
            "Time (s): 0.628709077835083\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 150 / 499\n",
            "LR: 8.889561096820408e-05\n",
            "Train loss: 0.5303817987442017\n",
            "\n",
            "Time (s): 0.6304810047149658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 151 / 499\n",
            "LR: 8.889543113097399e-05\n",
            "Train loss: 0.6403806209564209\n",
            "\n",
            "Time (s): 0.6257500648498535\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 152 / 499\n",
            "LR: 8.889525129483533e-05\n",
            "Train loss: 0.6233465075492859\n",
            "\n",
            "Time (s): 0.6241550445556641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 153 / 499\n",
            "LR: 8.889507145978807e-05\n",
            "Train loss: 0.7878949046134949\n",
            "\n",
            "Time (s): 0.6289379596710205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 154 / 499\n",
            "LR: 8.889489162583226e-05\n",
            "Train loss: 0.5702342391014099\n",
            "\n",
            "Time (s): 0.6234066486358643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 155 / 499\n",
            "LR: 8.889471179296782e-05\n",
            "Train loss: 0.42027032375335693\n",
            "\n",
            "Time (s): 0.6286196708679199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 156 / 499\n",
            "LR: 8.88945319611948e-05\n",
            "Train loss: 0.7245991230010986\n",
            "\n",
            "Time (s): 0.6292872428894043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 157 / 499\n",
            "LR: 8.889435213051315e-05\n",
            "Train loss: 0.8909615278244019\n",
            "\n",
            "Time (s): 0.6240279674530029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 158 / 499\n",
            "LR: 8.889417230092287e-05\n",
            "Train loss: 0.9197232127189636\n",
            "\n",
            "Time (s): 0.6274604797363281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 159 / 499\n",
            "LR: 8.889399247242392e-05\n",
            "Train loss: 0.7522364258766174\n",
            "\n",
            "Time (s): 0.6237368583679199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 160 / 499\n",
            "LR: 8.889381264501636e-05\n",
            "Train loss: 0.8604863882064819\n",
            "\n",
            "Time (s): 0.6235685348510742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 161 / 499\n",
            "LR: 8.889363281870013e-05\n",
            "Train loss: 0.7299161553382874\n",
            "\n",
            "Time (s): 0.6268389225006104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 162 / 499\n",
            "LR: 8.889345299347523e-05\n",
            "Train loss: 0.6722244024276733\n",
            "\n",
            "Time (s): 0.6276078224182129\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 163 / 499\n",
            "LR: 8.889327316934163e-05\n",
            "Train loss: 0.7227867841720581\n",
            "\n",
            "Time (s): 0.6239087581634521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 164 / 499\n",
            "LR: 8.889309334629934e-05\n",
            "Train loss: 0.3376573622226715\n",
            "\n",
            "Time (s): 0.6282327175140381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 165 / 499\n",
            "LR: 8.889291352434833e-05\n",
            "Train loss: 0.8380891680717468\n",
            "\n",
            "Time (s): 0.6242482662200928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 166 / 499\n",
            "LR: 8.88927337034886e-05\n",
            "Train loss: 0.8089723587036133\n",
            "\n",
            "Time (s): 0.6288988590240479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 167 / 499\n",
            "LR: 8.889255388372017e-05\n",
            "Train loss: 1.2404091358184814\n",
            "\n",
            "Time (s): 0.6233808994293213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 168 / 499\n",
            "LR: 8.889237406504298e-05\n",
            "Train loss: 0.3564245402812958\n",
            "\n",
            "Time (s): 0.6281826496124268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 169 / 499\n",
            "LR: 8.889219424745704e-05\n",
            "Train loss: 0.5504832863807678\n",
            "\n",
            "Time (s): 0.6309926509857178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 170 / 499\n",
            "LR: 8.889201443096233e-05\n",
            "Train loss: 0.8278607130050659\n",
            "\n",
            "Time (s): 0.6290915012359619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 171 / 499\n",
            "LR: 8.889183461555886e-05\n",
            "Train loss: 0.7743418216705322\n",
            "\n",
            "Time (s): 0.6384248733520508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 172 / 499\n",
            "LR: 8.889165480124659e-05\n",
            "Train loss: 0.6672158241271973\n",
            "\n",
            "Time (s): 0.6333675384521484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 173 / 499\n",
            "LR: 8.889147498802556e-05\n",
            "Train loss: 0.8448605537414551\n",
            "\n",
            "Time (s): 0.6318490505218506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 174 / 499\n",
            "LR: 8.889129517589569e-05\n",
            "Train loss: 0.4147665500640869\n",
            "\n",
            "Time (s): 0.6296608448028564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 175 / 499\n",
            "LR: 8.889111536485699e-05\n",
            "Train loss: 0.923241913318634\n",
            "\n",
            "Time (s): 0.6283996105194092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 176 / 499\n",
            "LR: 8.88909355549095e-05\n",
            "Train loss: 0.7967302203178406\n",
            "\n",
            "Time (s): 0.6283602714538574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 177 / 499\n",
            "LR: 8.889075574605314e-05\n",
            "Train loss: 0.9125369787216187\n",
            "\n",
            "Time (s): 0.6291255950927734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 178 / 499\n",
            "LR: 8.889057593828794e-05\n",
            "Train loss: 0.6708424091339111\n",
            "\n",
            "Time (s): 0.6286821365356445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 179 / 499\n",
            "LR: 8.889039613161389e-05\n",
            "Train loss: 0.7028563022613525\n",
            "\n",
            "Time (s): 0.6281085014343262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 180 / 499\n",
            "LR: 8.889021632603095e-05\n",
            "Train loss: 0.646942138671875\n",
            "\n",
            "Time (s): 0.6284708976745605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 181 / 499\n",
            "LR: 8.889003652153913e-05\n",
            "Train loss: 1.6760578155517578\n",
            "\n",
            "Time (s): 0.6287064552307129\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 182 / 499\n",
            "LR: 8.888985671813842e-05\n",
            "Train loss: 1.0094289779663086\n",
            "\n",
            "Time (s): 0.6283481121063232\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 183 / 499\n",
            "LR: 8.88896769158288e-05\n",
            "Train loss: 0.6889051795005798\n",
            "\n",
            "Time (s): 0.6261632442474365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 184 / 499\n",
            "LR: 8.888949711461027e-05\n",
            "Train loss: 0.8225961923599243\n",
            "\n",
            "Time (s): 0.6282927989959717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 185 / 499\n",
            "LR: 8.88893173144828e-05\n",
            "Train loss: 0.43793871998786926\n",
            "\n",
            "Time (s): 0.6282956600189209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 186 / 499\n",
            "LR: 8.888913751544641e-05\n",
            "Train loss: 1.1195951700210571\n",
            "\n",
            "Time (s): 0.6282021999359131\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 187 / 499\n",
            "LR: 8.888895771750107e-05\n",
            "Train loss: 1.0657018423080444\n",
            "\n",
            "Time (s): 0.6283092498779297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 188 / 499\n",
            "LR: 8.888877792064676e-05\n",
            "Train loss: 0.2932462990283966\n",
            "\n",
            "Time (s): 0.6283648014068604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 189 / 499\n",
            "LR: 8.888859812488345e-05\n",
            "Train loss: 1.359786033630371\n",
            "\n",
            "Time (s): 0.6283948421478271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 190 / 499\n",
            "LR: 8.888841833021119e-05\n",
            "Train loss: 1.6041672229766846\n",
            "\n",
            "Time (s): 0.6277694702148438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 191 / 499\n",
            "LR: 8.888823853662994e-05\n",
            "Train loss: 0.6406177878379822\n",
            "\n",
            "Time (s): 0.6256799697875977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 192 / 499\n",
            "LR: 8.888805874413966e-05\n",
            "Train loss: 0.9326068758964539\n",
            "\n",
            "Time (s): 0.627701997756958\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 193 / 499\n",
            "LR: 8.888787895274039e-05\n",
            "Train loss: 0.6853114366531372\n",
            "\n",
            "Time (s): 0.6288409233093262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 194 / 499\n",
            "LR: 8.888769916243208e-05\n",
            "Train loss: 0.6451831459999084\n",
            "\n",
            "Time (s): 0.6284539699554443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 195 / 499\n",
            "LR: 8.888751937321471e-05\n",
            "Train loss: 0.7081464529037476\n",
            "\n",
            "Time (s): 0.6282014846801758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 196 / 499\n",
            "LR: 8.888733958508833e-05\n",
            "Train loss: 0.6605589985847473\n",
            "\n",
            "Time (s): 0.6280131340026855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 197 / 499\n",
            "LR: 8.888715979805286e-05\n",
            "Train loss: 1.0635616779327393\n",
            "\n",
            "Time (s): 0.628767728805542\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 198 / 499\n",
            "LR: 8.888698001210833e-05\n",
            "Train loss: 0.3513968884944916\n",
            "\n",
            "Time (s): 0.6282830238342285\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 199 / 499\n",
            "LR: 8.888680022725473e-05\n",
            "Train loss: 1.3170275688171387\n",
            "\n",
            "Time (s): 0.6287016868591309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 200 / 499\n",
            "LR: 8.888662044349204e-05\n",
            "Train loss: 0.7308176755905151\n",
            "\n",
            "Time (s): 0.6290473937988281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 201 / 499\n",
            "LR: 8.888644066082021e-05\n",
            "Train loss: 1.3572955131530762\n",
            "\n",
            "Time (s): 0.6293151378631592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 202 / 499\n",
            "LR: 8.888626087923929e-05\n",
            "Train loss: 1.0247478485107422\n",
            "\n",
            "Time (s): 0.6292896270751953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 203 / 499\n",
            "LR: 8.888608109874922e-05\n",
            "Train loss: 0.5247971415519714\n",
            "\n",
            "Time (s): 0.6287801265716553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 204 / 499\n",
            "LR: 8.888590131935003e-05\n",
            "Train loss: 0.28702643513679504\n",
            "\n",
            "Time (s): 0.628082275390625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 205 / 499\n",
            "LR: 8.88857215410417e-05\n",
            "Train loss: 0.8030989766120911\n",
            "\n",
            "Time (s): 0.6291332244873047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 206 / 499\n",
            "LR: 8.88855417638242e-05\n",
            "Train loss: 0.5686390995979309\n",
            "\n",
            "Time (s): 0.6291959285736084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 207 / 499\n",
            "LR: 8.888536198769755e-05\n",
            "Train loss: 0.44237661361694336\n",
            "\n",
            "Time (s): 0.6297991275787354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 208 / 499\n",
            "LR: 8.88851822126617e-05\n",
            "Train loss: 0.6302908658981323\n",
            "\n",
            "Time (s): 0.6281697750091553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 209 / 499\n",
            "LR: 8.888500243871666e-05\n",
            "Train loss: 0.5223211050033569\n",
            "\n",
            "Time (s): 0.6288282871246338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 210 / 499\n",
            "LR: 8.888482266586239e-05\n",
            "Train loss: 1.2754921913146973\n",
            "\n",
            "Time (s): 0.6276211738586426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 211 / 499\n",
            "LR: 8.888464289409894e-05\n",
            "Train loss: 0.5932367444038391\n",
            "\n",
            "Time (s): 0.6236028671264648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 212 / 499\n",
            "LR: 8.888446312342624e-05\n",
            "Train loss: 1.2732315063476562\n",
            "\n",
            "Time (s): 0.6288442611694336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 213 / 499\n",
            "LR: 8.888428335384433e-05\n",
            "Train loss: 0.9034083485603333\n",
            "\n",
            "Time (s): 0.6336662769317627\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 214 / 499\n",
            "LR: 8.888410358535316e-05\n",
            "Train loss: 1.2707324028015137\n",
            "\n",
            "Time (s): 0.6279358863830566\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 215 / 499\n",
            "LR: 8.888392381795273e-05\n",
            "Train loss: 0.864457368850708\n",
            "\n",
            "Time (s): 0.6273658275604248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 216 / 499\n",
            "LR: 8.888374405164302e-05\n",
            "Train loss: 0.7350652813911438\n",
            "\n",
            "Time (s): 0.6243484020233154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 217 / 499\n",
            "LR: 8.888356428642403e-05\n",
            "Train loss: 0.923322319984436\n",
            "\n",
            "Time (s): 0.6286361217498779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 218 / 499\n",
            "LR: 8.888338452229577e-05\n",
            "Train loss: 0.7670510411262512\n",
            "\n",
            "Time (s): 0.6282334327697754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 219 / 499\n",
            "LR: 8.88832047592582e-05\n",
            "Train loss: 0.8408594131469727\n",
            "\n",
            "Time (s): 0.6281797885894775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 220 / 499\n",
            "LR: 8.88830249973113e-05\n",
            "Train loss: 0.7447572946548462\n",
            "\n",
            "Time (s): 0.6283001899719238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 221 / 499\n",
            "LR: 8.888284523645507e-05\n",
            "Train loss: 0.7386350631713867\n",
            "\n",
            "Time (s): 0.6270816326141357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 222 / 499\n",
            "LR: 8.888266547668954e-05\n",
            "Train loss: 0.7782572507858276\n",
            "\n",
            "Time (s): 0.6280717849731445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 223 / 499\n",
            "LR: 8.888248571801463e-05\n",
            "Train loss: 0.8907742500305176\n",
            "\n",
            "Time (s): 0.627615213394165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 224 / 499\n",
            "LR: 8.888230596043038e-05\n",
            "Train loss: 0.7667129039764404\n",
            "\n",
            "Time (s): 0.62375807762146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 225 / 499\n",
            "LR: 8.888212620393675e-05\n",
            "Train loss: 1.3714632987976074\n",
            "\n",
            "Time (s): 0.6288955211639404\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 226 / 499\n",
            "LR: 8.888194644853374e-05\n",
            "Train loss: 0.8707191944122314\n",
            "\n",
            "Time (s): 0.6276776790618896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 227 / 499\n",
            "LR: 8.888176669422134e-05\n",
            "Train loss: 1.2236297130584717\n",
            "\n",
            "Time (s): 0.6287801265716553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 228 / 499\n",
            "LR: 8.888158694099954e-05\n",
            "Train loss: 0.9061678051948547\n",
            "\n",
            "Time (s): 0.6295599937438965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 229 / 499\n",
            "LR: 8.888140718886832e-05\n",
            "Train loss: 0.41310641169548035\n",
            "\n",
            "Time (s): 0.6285269260406494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 230 / 499\n",
            "LR: 8.888122743782768e-05\n",
            "Train loss: 0.9342034459114075\n",
            "\n",
            "Time (s): 0.62420654296875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 231 / 499\n",
            "LR: 8.888104768787762e-05\n",
            "Train loss: 1.1704435348510742\n",
            "\n",
            "Time (s): 0.6287131309509277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 232 / 499\n",
            "LR: 8.888086793901809e-05\n",
            "Train loss: 0.8391987681388855\n",
            "\n",
            "Time (s): 0.6274654865264893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 233 / 499\n",
            "LR: 8.888068819124912e-05\n",
            "Train loss: 0.6476224660873413\n",
            "\n",
            "Time (s): 0.6259059906005859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 234 / 499\n",
            "LR: 8.888050844457068e-05\n",
            "Train loss: 1.1786878108978271\n",
            "\n",
            "Time (s): 0.6237106323242188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 235 / 499\n",
            "LR: 8.888032869898276e-05\n",
            "Train loss: 0.9624155759811401\n",
            "\n",
            "Time (s): 0.6233868598937988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 236 / 499\n",
            "LR: 8.888014895448533e-05\n",
            "Train loss: 1.0317730903625488\n",
            "\n",
            "Time (s): 0.6244161128997803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 237 / 499\n",
            "LR: 8.88799692110784e-05\n",
            "Train loss: 1.0927479267120361\n",
            "\n",
            "Time (s): 0.6278767585754395\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 238 / 499\n",
            "LR: 8.887978946876198e-05\n",
            "Train loss: 1.1619138717651367\n",
            "\n",
            "Time (s): 0.6281898021697998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 239 / 499\n",
            "LR: 8.887960972753603e-05\n",
            "Train loss: 1.801702618598938\n",
            "\n",
            "Time (s): 0.6290678977966309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 240 / 499\n",
            "LR: 8.887942998740053e-05\n",
            "Train loss: 1.047627329826355\n",
            "\n",
            "Time (s): 0.625434160232544\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 241 / 499\n",
            "LR: 8.88792502483555e-05\n",
            "Train loss: 0.3362186849117279\n",
            "\n",
            "Time (s): 0.6247768402099609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 242 / 499\n",
            "LR: 8.887907051040092e-05\n",
            "Train loss: 0.7374961972236633\n",
            "\n",
            "Time (s): 0.6240897178649902\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 243 / 499\n",
            "LR: 8.887889077353676e-05\n",
            "Train loss: 0.6742252707481384\n",
            "\n",
            "Time (s): 0.6279103755950928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 244 / 499\n",
            "LR: 8.887871103776302e-05\n",
            "Train loss: 1.4095516204833984\n",
            "\n",
            "Time (s): 0.628345251083374\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 245 / 499\n",
            "LR: 8.88785313030797e-05\n",
            "Train loss: 0.5185118913650513\n",
            "\n",
            "Time (s): 0.6287055015563965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 246 / 499\n",
            "LR: 8.887835156948676e-05\n",
            "Train loss: 0.984997570514679\n",
            "\n",
            "Time (s): 0.623837947845459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 247 / 499\n",
            "LR: 8.887817183698423e-05\n",
            "Train loss: 1.1935358047485352\n",
            "\n",
            "Time (s): 0.6244306564331055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 248 / 499\n",
            "LR: 8.887799210557206e-05\n",
            "Train loss: 0.5544871687889099\n",
            "\n",
            "Time (s): 0.6245748996734619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 249 / 499\n",
            "LR: 8.887781237525026e-05\n",
            "Train loss: 1.0858945846557617\n",
            "\n",
            "Time (s): 0.6280450820922852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 250 / 499\n",
            "LR: 8.887763264601882e-05\n",
            "Train loss: 1.3762826919555664\n",
            "\n",
            "Time (s): 0.6285474300384521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 251 / 499\n",
            "LR: 8.887745291787773e-05\n",
            "Train loss: 0.8434378504753113\n",
            "\n",
            "Time (s): 0.6289951801300049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 252 / 499\n",
            "LR: 8.887727319082696e-05\n",
            "Train loss: 0.6875282526016235\n",
            "\n",
            "Time (s): 0.6235878467559814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 253 / 499\n",
            "LR: 8.887709346486653e-05\n",
            "Train loss: 1.2372496128082275\n",
            "\n",
            "Time (s): 0.629551887512207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 254 / 499\n",
            "LR: 8.887691373999638e-05\n",
            "Train loss: 0.6953283548355103\n",
            "\n",
            "Time (s): 0.6241934299468994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 255 / 499\n",
            "LR: 8.887673401621658e-05\n",
            "Train loss: 0.826576828956604\n",
            "\n",
            "Time (s): 0.6279861927032471\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 256 / 499\n",
            "LR: 8.887655429352703e-05\n",
            "Train loss: 0.6560112237930298\n",
            "\n",
            "Time (s): 0.6322364807128906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 257 / 499\n",
            "LR: 8.887637457192775e-05\n",
            "Train loss: 1.051340103149414\n",
            "\n",
            "Time (s): 0.6280777454376221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 258 / 499\n",
            "LR: 8.887619485141875e-05\n",
            "Train loss: 0.7502764463424683\n",
            "\n",
            "Time (s): 0.6321837902069092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 259 / 499\n",
            "LR: 8.887601513200002e-05\n",
            "Train loss: 0.6426832675933838\n",
            "\n",
            "Time (s): 0.6280834674835205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 260 / 499\n",
            "LR: 8.887583541367153e-05\n",
            "Train loss: 0.6714417934417725\n",
            "\n",
            "Time (s): 0.6315031051635742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 261 / 499\n",
            "LR: 8.887565569643326e-05\n",
            "Train loss: 0.8676810264587402\n",
            "\n",
            "Time (s): 0.6245663166046143\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 262 / 499\n",
            "LR: 8.887547598028522e-05\n",
            "Train loss: 1.1110509634017944\n",
            "\n",
            "Time (s): 0.6280181407928467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 263 / 499\n",
            "LR: 8.887529626522739e-05\n",
            "Train loss: 0.977834165096283\n",
            "\n",
            "Time (s): 0.6287646293640137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 264 / 499\n",
            "LR: 8.887511655125976e-05\n",
            "Train loss: 0.5699812769889832\n",
            "\n",
            "Time (s): 0.630474328994751\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 265 / 499\n",
            "LR: 8.887493683838233e-05\n",
            "Train loss: 0.2929764688014984\n",
            "\n",
            "Time (s): 0.6247665882110596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 266 / 499\n",
            "LR: 8.887475712659506e-05\n",
            "Train loss: 0.6485567688941956\n",
            "\n",
            "Time (s): 0.6282446384429932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 267 / 499\n",
            "LR: 8.887457741589798e-05\n",
            "Train loss: 1.1592282056808472\n",
            "\n",
            "Time (s): 0.6244907379150391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 268 / 499\n",
            "LR: 8.887439770629103e-05\n",
            "Train loss: 0.8904902338981628\n",
            "\n",
            "Time (s): 0.6242630481719971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 269 / 499\n",
            "LR: 8.887421799777425e-05\n",
            "Train loss: 1.2451807260513306\n",
            "\n",
            "Time (s): 0.6244640350341797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 270 / 499\n",
            "LR: 8.88740382903476e-05\n",
            "Train loss: 0.6711825132369995\n",
            "\n",
            "Time (s): 0.6244328022003174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 271 / 499\n",
            "LR: 8.887385858401106e-05\n",
            "Train loss: 0.4865918755531311\n",
            "\n",
            "Time (s): 0.6239285469055176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 272 / 499\n",
            "LR: 8.887367887876465e-05\n",
            "Train loss: 0.3455515503883362\n",
            "\n",
            "Time (s): 0.6286242008209229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 273 / 499\n",
            "LR: 8.887349917460833e-05\n",
            "Train loss: 0.5681730508804321\n",
            "\n",
            "Time (s): 0.6243515014648438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 274 / 499\n",
            "LR: 8.88733194715421e-05\n",
            "Train loss: 0.39301347732543945\n",
            "\n",
            "Time (s): 0.6307685375213623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 275 / 499\n",
            "LR: 8.887313976956597e-05\n",
            "Train loss: 1.0675938129425049\n",
            "\n",
            "Time (s): 0.6282579898834229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 276 / 499\n",
            "LR: 8.88729600686799e-05\n",
            "Train loss: 1.0716619491577148\n",
            "\n",
            "Time (s): 0.6294071674346924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 277 / 499\n",
            "LR: 8.887278036888386e-05\n",
            "Train loss: 0.6787258982658386\n",
            "\n",
            "Time (s): 0.6288318634033203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 278 / 499\n",
            "LR: 8.887260067017788e-05\n",
            "Train loss: 0.8217780590057373\n",
            "\n",
            "Time (s): 0.631220817565918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 279 / 499\n",
            "LR: 8.887242097256196e-05\n",
            "Train loss: 1.005637288093567\n",
            "\n",
            "Time (s): 0.6290910243988037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 280 / 499\n",
            "LR: 8.887224127603606e-05\n",
            "Train loss: 0.6589094996452332\n",
            "\n",
            "Time (s): 0.6290867328643799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 281 / 499\n",
            "LR: 8.887206158060014e-05\n",
            "Train loss: 0.951835572719574\n",
            "\n",
            "Time (s): 0.6299192905426025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 282 / 499\n",
            "LR: 8.887188188625425e-05\n",
            "Train loss: 0.2914198935031891\n",
            "\n",
            "Time (s): 0.6293761730194092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 283 / 499\n",
            "LR: 8.887170219299835e-05\n",
            "Train loss: 0.908909022808075\n",
            "\n",
            "Time (s): 0.6296005249023438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 284 / 499\n",
            "LR: 8.887152250083242e-05\n",
            "Train loss: 0.6817125082015991\n",
            "\n",
            "Time (s): 0.6295433044433594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 285 / 499\n",
            "LR: 8.887134280975646e-05\n",
            "Train loss: 1.0113660097122192\n",
            "\n",
            "Time (s): 0.6320488452911377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 286 / 499\n",
            "LR: 8.887116311977047e-05\n",
            "Train loss: 0.5023177266120911\n",
            "\n",
            "Time (s): 0.6300656795501709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 287 / 499\n",
            "LR: 8.887098343087441e-05\n",
            "Train loss: 0.9220643043518066\n",
            "\n",
            "Time (s): 0.6285915374755859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 288 / 499\n",
            "LR: 8.88708037430683e-05\n",
            "Train loss: 0.8477377891540527\n",
            "\n",
            "Time (s): 0.62919020652771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 289 / 499\n",
            "LR: 8.88706240563521e-05\n",
            "Train loss: 0.9099512100219727\n",
            "\n",
            "Time (s): 0.6291384696960449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 290 / 499\n",
            "LR: 8.887044437072583e-05\n",
            "Train loss: 0.782246470451355\n",
            "\n",
            "Time (s): 0.6294758319854736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 291 / 499\n",
            "LR: 8.887026468618945e-05\n",
            "Train loss: 0.6906638145446777\n",
            "\n",
            "Time (s): 0.6289207935333252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 292 / 499\n",
            "LR: 8.887008500274297e-05\n",
            "Train loss: 0.3270612955093384\n",
            "\n",
            "Time (s): 0.6297094821929932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 293 / 499\n",
            "LR: 8.886990532038639e-05\n",
            "Train loss: 0.4430301785469055\n",
            "\n",
            "Time (s): 0.629946231842041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 294 / 499\n",
            "LR: 8.886972563911965e-05\n",
            "Train loss: 0.8006571531295776\n",
            "\n",
            "Time (s): 0.629004955291748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 295 / 499\n",
            "LR: 8.886954595894279e-05\n",
            "Train loss: 0.5043742656707764\n",
            "\n",
            "Time (s): 0.6298830509185791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 296 / 499\n",
            "LR: 8.886936627985576e-05\n",
            "Train loss: 0.55571049451828\n",
            "\n",
            "Time (s): 0.629432201385498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 297 / 499\n",
            "LR: 8.886918660185859e-05\n",
            "Train loss: 1.0071872472763062\n",
            "\n",
            "Time (s): 0.629418134689331\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 298 / 499\n",
            "LR: 8.886900692495123e-05\n",
            "Train loss: 0.7294179797172546\n",
            "\n",
            "Time (s): 0.6300067901611328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 299 / 499\n",
            "LR: 8.886882724913369e-05\n",
            "Train loss: 0.9429106712341309\n",
            "\n",
            "Time (s): 0.629807710647583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 300 / 499\n",
            "LR: 8.886864757440594e-05\n",
            "Train loss: 1.0635138750076294\n",
            "\n",
            "Time (s): 0.629075288772583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 301 / 499\n",
            "LR: 8.886846790076801e-05\n",
            "Train loss: 0.6863688826560974\n",
            "\n",
            "Time (s): 0.6282711029052734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 302 / 499\n",
            "LR: 8.886828822821985e-05\n",
            "Train loss: 0.35285741090774536\n",
            "\n",
            "Time (s): 0.6291563510894775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 303 / 499\n",
            "LR: 8.886810855676144e-05\n",
            "Train loss: 0.8419610261917114\n",
            "\n",
            "Time (s): 0.6327056884765625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 304 / 499\n",
            "LR: 8.886792888639281e-05\n",
            "Train loss: 0.2813783288002014\n",
            "\n",
            "Time (s): 0.629539966583252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 305 / 499\n",
            "LR: 8.886774921711391e-05\n",
            "Train loss: 1.053175926208496\n",
            "\n",
            "Time (s): 0.6302535533905029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 306 / 499\n",
            "LR: 8.886756954892479e-05\n",
            "Train loss: 1.3808282613754272\n",
            "\n",
            "Time (s): 0.6303462982177734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 307 / 499\n",
            "LR: 8.886738988182537e-05\n",
            "Train loss: 0.8844355940818787\n",
            "\n",
            "Time (s): 0.6293437480926514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 308 / 499\n",
            "LR: 8.886721021581566e-05\n",
            "Train loss: 0.5797773003578186\n",
            "\n",
            "Time (s): 0.6292040348052979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 309 / 499\n",
            "LR: 8.886703055089568e-05\n",
            "Train loss: 0.7443485856056213\n",
            "\n",
            "Time (s): 0.6284170150756836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 310 / 499\n",
            "LR: 8.886685088706537e-05\n",
            "Train loss: 0.5927472114562988\n",
            "\n",
            "Time (s): 0.6239356994628906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 311 / 499\n",
            "LR: 8.886667122432474e-05\n",
            "Train loss: 0.909736692905426\n",
            "\n",
            "Time (s): 0.629371166229248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 312 / 499\n",
            "LR: 8.886649156267378e-05\n",
            "Train loss: 0.8293032646179199\n",
            "\n",
            "Time (s): 0.6286234855651855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 313 / 499\n",
            "LR: 8.886631190211251e-05\n",
            "Train loss: 0.45015639066696167\n",
            "\n",
            "Time (s): 0.6302237510681152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 314 / 499\n",
            "LR: 8.886613224264086e-05\n",
            "Train loss: 0.7299672961235046\n",
            "\n",
            "Time (s): 0.6296453475952148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 315 / 499\n",
            "LR: 8.886595258425887e-05\n",
            "Train loss: 1.312200665473938\n",
            "\n",
            "Time (s): 0.6242721080780029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 316 / 499\n",
            "LR: 8.886577292696649e-05\n",
            "Train loss: 0.5942519903182983\n",
            "\n",
            "Time (s): 0.6289019584655762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 317 / 499\n",
            "LR: 8.886559327076373e-05\n",
            "Train loss: 0.6719806790351868\n",
            "\n",
            "Time (s): 0.6264452934265137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 318 / 499\n",
            "LR: 8.886541361565058e-05\n",
            "Train loss: 0.9148509502410889\n",
            "\n",
            "Time (s): 0.6316545009613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 319 / 499\n",
            "LR: 8.886523396162703e-05\n",
            "Train loss: 1.248133659362793\n",
            "\n",
            "Time (s): 0.6336755752563477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 320 / 499\n",
            "LR: 8.886505430869306e-05\n",
            "Train loss: 0.9980044364929199\n",
            "\n",
            "Time (s): 0.6292300224304199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 321 / 499\n",
            "LR: 8.886487465684868e-05\n",
            "Train loss: 1.195205569267273\n",
            "\n",
            "Time (s): 0.6302251815795898\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 322 / 499\n",
            "LR: 8.886469500609384e-05\n",
            "Train loss: 1.5210683345794678\n",
            "\n",
            "Time (s): 0.6281046867370605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 323 / 499\n",
            "LR: 8.886451535642855e-05\n",
            "Train loss: 1.2756325006484985\n",
            "\n",
            "Time (s): 0.6293108463287354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 324 / 499\n",
            "LR: 8.88643357078528e-05\n",
            "Train loss: 1.0988531112670898\n",
            "\n",
            "Time (s): 0.6293559074401855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 325 / 499\n",
            "LR: 8.886415606036658e-05\n",
            "Train loss: 0.8191585540771484\n",
            "\n",
            "Time (s): 0.6248416900634766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 326 / 499\n",
            "LR: 8.886397641396989e-05\n",
            "Train loss: 0.5644485354423523\n",
            "\n",
            "Time (s): 0.629746675491333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 327 / 499\n",
            "LR: 8.886379676866272e-05\n",
            "Train loss: 1.302702784538269\n",
            "\n",
            "Time (s): 0.6281063556671143\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 328 / 499\n",
            "LR: 8.8863617124445e-05\n",
            "Train loss: 0.47698089480400085\n",
            "\n",
            "Time (s): 0.6293215751647949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 329 / 499\n",
            "LR: 8.88634374813168e-05\n",
            "Train loss: 1.1978768110275269\n",
            "\n",
            "Time (s): 0.6292154788970947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 330 / 499\n",
            "LR: 8.886325783927806e-05\n",
            "Train loss: 0.9720934629440308\n",
            "\n",
            "Time (s): 0.6289961338043213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 331 / 499\n",
            "LR: 8.886307819832879e-05\n",
            "Train loss: 0.46473854780197144\n",
            "\n",
            "Time (s): 0.6291472911834717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 332 / 499\n",
            "LR: 8.886289855846895e-05\n",
            "Train loss: 0.7900182604789734\n",
            "\n",
            "Time (s): 0.6292893886566162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 333 / 499\n",
            "LR: 8.886271891969857e-05\n",
            "Train loss: 0.7850916981697083\n",
            "\n",
            "Time (s): 0.6289200782775879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 334 / 499\n",
            "LR: 8.886253928201763e-05\n",
            "Train loss: 0.7552590370178223\n",
            "\n",
            "Time (s): 0.6284439563751221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 335 / 499\n",
            "LR: 8.88623596454261e-05\n",
            "Train loss: 0.38212814927101135\n",
            "\n",
            "Time (s): 0.6262331008911133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 336 / 499\n",
            "LR: 8.886218000992396e-05\n",
            "Train loss: 1.0697972774505615\n",
            "\n",
            "Time (s): 0.6244828701019287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 337 / 499\n",
            "LR: 8.886200037551122e-05\n",
            "Train loss: 1.0395146608352661\n",
            "\n",
            "Time (s): 0.62923264503479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 338 / 499\n",
            "LR: 8.886182074218788e-05\n",
            "Train loss: 0.7360725402832031\n",
            "\n",
            "Time (s): 0.629342794418335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 339 / 499\n",
            "LR: 8.88616411099539e-05\n",
            "Train loss: 0.6360438466072083\n",
            "\n",
            "Time (s): 0.6303901672363281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 340 / 499\n",
            "LR: 8.88614614788093e-05\n",
            "Train loss: 0.3451513946056366\n",
            "\n",
            "Time (s): 0.6293721199035645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 341 / 499\n",
            "LR: 8.886128184875407e-05\n",
            "Train loss: 0.8153919577598572\n",
            "\n",
            "Time (s): 0.6303806304931641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 342 / 499\n",
            "LR: 8.886110221978815e-05\n",
            "Train loss: 0.7279585003852844\n",
            "\n",
            "Time (s): 0.6293699741363525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 343 / 499\n",
            "LR: 8.886092259191157e-05\n",
            "Train loss: 0.7361593246459961\n",
            "\n",
            "Time (s): 0.6242048740386963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 344 / 499\n",
            "LR: 8.886074296512429e-05\n",
            "Train loss: 1.1735081672668457\n",
            "\n",
            "Time (s): 0.6283800601959229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 345 / 499\n",
            "LR: 8.886056333942634e-05\n",
            "Train loss: 0.9005275964736938\n",
            "\n",
            "Time (s): 0.6297919750213623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 346 / 499\n",
            "LR: 8.886038371481769e-05\n",
            "Train loss: 0.8156999349594116\n",
            "\n",
            "Time (s): 0.628061056137085\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 347 / 499\n",
            "LR: 8.88602040912983e-05\n",
            "Train loss: 0.9232547879219055\n",
            "\n",
            "Time (s): 0.6289997100830078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 348 / 499\n",
            "LR: 8.886002446886822e-05\n",
            "Train loss: 1.5607249736785889\n",
            "\n",
            "Time (s): 0.6281278133392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 349 / 499\n",
            "LR: 8.885984484752738e-05\n",
            "Train loss: 0.6511532068252563\n",
            "\n",
            "Time (s): 0.6292555332183838\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 350 / 499\n",
            "LR: 8.885966522727582e-05\n",
            "Train loss: 1.5591517686843872\n",
            "\n",
            "Time (s): 0.6296300888061523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 351 / 499\n",
            "LR: 8.885948560811348e-05\n",
            "Train loss: 1.2797151803970337\n",
            "\n",
            "Time (s): 0.6271982192993164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 352 / 499\n",
            "LR: 8.885930599004036e-05\n",
            "Train loss: 0.7786834239959717\n",
            "\n",
            "Time (s): 0.6311829090118408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 353 / 499\n",
            "LR: 8.88591263730565e-05\n",
            "Train loss: 0.7252045273780823\n",
            "\n",
            "Time (s): 0.6287238597869873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 354 / 499\n",
            "LR: 8.885894675716181e-05\n",
            "Train loss: 0.3790258765220642\n",
            "\n",
            "Time (s): 0.6255171298980713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 355 / 499\n",
            "LR: 8.885876714235635e-05\n",
            "Train loss: 0.6782218813896179\n",
            "\n",
            "Time (s): 0.6288118362426758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 356 / 499\n",
            "LR: 8.885858752864006e-05\n",
            "Train loss: 0.7633596062660217\n",
            "\n",
            "Time (s): 0.6287095546722412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 357 / 499\n",
            "LR: 8.885840791601293e-05\n",
            "Train loss: 0.36693865060806274\n",
            "\n",
            "Time (s): 0.6285057067871094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 358 / 499\n",
            "LR: 8.8858228304475e-05\n",
            "Train loss: 1.0977842807769775\n",
            "\n",
            "Time (s): 0.6324100494384766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 359 / 499\n",
            "LR: 8.885804869402621e-05\n",
            "Train loss: 0.5573776364326477\n",
            "\n",
            "Time (s): 0.6319172382354736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 360 / 499\n",
            "LR: 8.885786908466656e-05\n",
            "Train loss: 1.2338011264801025\n",
            "\n",
            "Time (s): 0.628143310546875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 361 / 499\n",
            "LR: 8.885768947639604e-05\n",
            "Train loss: 1.3085743188858032\n",
            "\n",
            "Time (s): 0.6287643909454346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 362 / 499\n",
            "LR: 8.885750986921465e-05\n",
            "Train loss: 0.741500735282898\n",
            "\n",
            "Time (s): 0.6290161609649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 363 / 499\n",
            "LR: 8.885733026312237e-05\n",
            "Train loss: 1.305389642715454\n",
            "\n",
            "Time (s): 0.6325907707214355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 364 / 499\n",
            "LR: 8.885715065811917e-05\n",
            "Train loss: 0.5277152061462402\n",
            "\n",
            "Time (s): 0.629889726638794\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 365 / 499\n",
            "LR: 8.88569710542051e-05\n",
            "Train loss: 0.46798405051231384\n",
            "\n",
            "Time (s): 0.629281759262085\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 366 / 499\n",
            "LR: 8.885679145138006e-05\n",
            "Train loss: 0.6962239146232605\n",
            "\n",
            "Time (s): 0.628913402557373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 367 / 499\n",
            "LR: 8.88566118496441e-05\n",
            "Train loss: 0.7537487149238586\n",
            "\n",
            "Time (s): 0.630993127822876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 368 / 499\n",
            "LR: 8.88564322489972e-05\n",
            "Train loss: 0.6508589386940002\n",
            "\n",
            "Time (s): 0.6272814273834229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 369 / 499\n",
            "LR: 8.885625264943936e-05\n",
            "Train loss: 0.945735514163971\n",
            "\n",
            "Time (s): 0.6309547424316406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 370 / 499\n",
            "LR: 8.885607305097054e-05\n",
            "Train loss: 0.7310261726379395\n",
            "\n",
            "Time (s): 0.630378007888794\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 371 / 499\n",
            "LR: 8.885589345359074e-05\n",
            "Train loss: 1.286163568496704\n",
            "\n",
            "Time (s): 0.6303102970123291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 372 / 499\n",
            "LR: 8.885571385729995e-05\n",
            "Train loss: 1.082368016242981\n",
            "\n",
            "Time (s): 0.629173755645752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 373 / 499\n",
            "LR: 8.885553426209817e-05\n",
            "Train loss: 0.9999364018440247\n",
            "\n",
            "Time (s): 0.6291933059692383\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 374 / 499\n",
            "LR: 8.885535466798539e-05\n",
            "Train loss: 1.191807508468628\n",
            "\n",
            "Time (s): 0.6301848888397217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 375 / 499\n",
            "LR: 8.885517507496156e-05\n",
            "Train loss: 0.6397572755813599\n",
            "\n",
            "Time (s): 0.6289968490600586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 376 / 499\n",
            "LR: 8.885499548302669e-05\n",
            "Train loss: 0.6833359599113464\n",
            "\n",
            "Time (s): 0.6289846897125244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 377 / 499\n",
            "LR: 8.885481589218082e-05\n",
            "Train loss: 0.38811561465263367\n",
            "\n",
            "Time (s): 0.629666805267334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 378 / 499\n",
            "LR: 8.885463630242386e-05\n",
            "Train loss: 1.0163346529006958\n",
            "\n",
            "Time (s): 0.6298246383666992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 379 / 499\n",
            "LR: 8.885445671375584e-05\n",
            "Train loss: 1.182377576828003\n",
            "\n",
            "Time (s): 0.6293394565582275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 380 / 499\n",
            "LR: 8.885427712617674e-05\n",
            "Train loss: 0.42096295952796936\n",
            "\n",
            "Time (s): 0.6293666362762451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 381 / 499\n",
            "LR: 8.885409753968655e-05\n",
            "Train loss: 1.322291374206543\n",
            "\n",
            "Time (s): 0.6297099590301514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 382 / 499\n",
            "LR: 8.885391795428528e-05\n",
            "Train loss: 0.6118848919868469\n",
            "\n",
            "Time (s): 0.6296322345733643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 383 / 499\n",
            "LR: 8.88537383699729e-05\n",
            "Train loss: 0.8528468012809753\n",
            "\n",
            "Time (s): 0.6300992965698242\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 384 / 499\n",
            "LR: 8.885355878674939e-05\n",
            "Train loss: 1.3564362525939941\n",
            "\n",
            "Time (s): 0.6294999122619629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 385 / 499\n",
            "LR: 8.885337920461474e-05\n",
            "Train loss: 0.7889470458030701\n",
            "\n",
            "Time (s): 0.6299958229064941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 386 / 499\n",
            "LR: 8.885319962356896e-05\n",
            "Train loss: 0.6581453084945679\n",
            "\n",
            "Time (s): 0.6298623085021973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 387 / 499\n",
            "LR: 8.885302004361202e-05\n",
            "Train loss: 0.6389458775520325\n",
            "\n",
            "Time (s): 0.6293458938598633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 388 / 499\n",
            "LR: 8.885284046474391e-05\n",
            "Train loss: 0.5628420114517212\n",
            "\n",
            "Time (s): 0.6298308372497559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 389 / 499\n",
            "LR: 8.885266088696466e-05\n",
            "Train loss: 0.44016844034194946\n",
            "\n",
            "Time (s): 0.6288151741027832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 390 / 499\n",
            "LR: 8.885248131027417e-05\n",
            "Train loss: 1.1082653999328613\n",
            "\n",
            "Time (s): 0.6309244632720947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 391 / 499\n",
            "LR: 8.885230173467251e-05\n",
            "Train loss: 0.36889296770095825\n",
            "\n",
            "Time (s): 0.6290464401245117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 392 / 499\n",
            "LR: 8.885212216015963e-05\n",
            "Train loss: 0.5402358770370483\n",
            "\n",
            "Time (s): 0.6307282447814941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 393 / 499\n",
            "LR: 8.885194258673555e-05\n",
            "Train loss: 1.2873352766036987\n",
            "\n",
            "Time (s): 0.6287214756011963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 394 / 499\n",
            "LR: 8.885176301440022e-05\n",
            "Train loss: 0.4917330741882324\n",
            "\n",
            "Time (s): 0.6294200420379639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 395 / 499\n",
            "LR: 8.885158344315366e-05\n",
            "Train loss: 1.0714975595474243\n",
            "\n",
            "Time (s): 0.6300837993621826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 396 / 499\n",
            "LR: 8.885140387299584e-05\n",
            "Train loss: 0.8318843245506287\n",
            "\n",
            "Time (s): 0.6286759376525879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 397 / 499\n",
            "LR: 8.885122430392676e-05\n",
            "Train loss: 0.5739191174507141\n",
            "\n",
            "Time (s): 0.6286265850067139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 398 / 499\n",
            "LR: 8.88510447359464e-05\n",
            "Train loss: 0.8760979771614075\n",
            "\n",
            "Time (s): 0.6308627128601074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 399 / 499\n",
            "LR: 8.885086516905476e-05\n",
            "Train loss: 1.0860111713409424\n",
            "\n",
            "Time (s): 0.630068302154541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 400 / 499\n",
            "LR: 8.885068560325184e-05\n",
            "Train loss: 1.0015298128128052\n",
            "\n",
            "Time (s): 0.6284995079040527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 401 / 499\n",
            "LR: 8.885050603853758e-05\n",
            "Train loss: 1.0186349153518677\n",
            "\n",
            "Time (s): 0.6289687156677246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 402 / 499\n",
            "LR: 8.885032647491202e-05\n",
            "Train loss: 1.0219107866287231\n",
            "\n",
            "Time (s): 0.6296463012695312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 403 / 499\n",
            "LR: 8.885014691237513e-05\n",
            "Train loss: 0.6963343024253845\n",
            "\n",
            "Time (s): 0.6280367374420166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 404 / 499\n",
            "LR: 8.884996735092689e-05\n",
            "Train loss: 1.1950747966766357\n",
            "\n",
            "Time (s): 0.6288168430328369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 405 / 499\n",
            "LR: 8.88497877905673e-05\n",
            "Train loss: 1.1801899671554565\n",
            "\n",
            "Time (s): 0.6304965019226074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 406 / 499\n",
            "LR: 8.884960823129633e-05\n",
            "Train loss: 0.8215752840042114\n",
            "\n",
            "Time (s): 0.6267821788787842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 407 / 499\n",
            "LR: 8.884942867311403e-05\n",
            "Train loss: 1.1262543201446533\n",
            "\n",
            "Time (s): 0.6309521198272705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 408 / 499\n",
            "LR: 8.884924911602031e-05\n",
            "Train loss: 0.3603205978870392\n",
            "\n",
            "Time (s): 0.6287131309509277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 409 / 499\n",
            "LR: 8.884906956001521e-05\n",
            "Train loss: 0.5258080959320068\n",
            "\n",
            "Time (s): 0.6324505805969238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 410 / 499\n",
            "LR: 8.884889000509869e-05\n",
            "Train loss: 0.18516957759857178\n",
            "\n",
            "Time (s): 0.6288132667541504\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 411 / 499\n",
            "LR: 8.884871045127076e-05\n",
            "Train loss: 0.9611537456512451\n",
            "\n",
            "Time (s): 0.6290333271026611\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 412 / 499\n",
            "LR: 8.884853089853141e-05\n",
            "Train loss: 0.6693317294120789\n",
            "\n",
            "Time (s): 0.6295723915100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 413 / 499\n",
            "LR: 8.88483513468806e-05\n",
            "Train loss: 0.6489678025245667\n",
            "\n",
            "Time (s): 0.6302411556243896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 414 / 499\n",
            "LR: 8.884817179631837e-05\n",
            "Train loss: 0.4430016279220581\n",
            "\n",
            "Time (s): 0.6297378540039062\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 415 / 499\n",
            "LR: 8.884799224684465e-05\n",
            "Train loss: 1.000028133392334\n",
            "\n",
            "Time (s): 0.6317346096038818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 416 / 499\n",
            "LR: 8.884781269845947e-05\n",
            "Train loss: 0.8370018005371094\n",
            "\n",
            "Time (s): 0.6295254230499268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 417 / 499\n",
            "LR: 8.88476331511628e-05\n",
            "Train loss: 0.6317288875579834\n",
            "\n",
            "Time (s): 0.6308302879333496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 418 / 499\n",
            "LR: 8.884745360495463e-05\n",
            "Train loss: 0.9295410513877869\n",
            "\n",
            "Time (s): 0.6296648979187012\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 419 / 499\n",
            "LR: 8.884727405983496e-05\n",
            "Train loss: 0.916728138923645\n",
            "\n",
            "Time (s): 0.6298873424530029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 420 / 499\n",
            "LR: 8.884709451580379e-05\n",
            "Train loss: 0.667419970035553\n",
            "\n",
            "Time (s): 0.6299927234649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 421 / 499\n",
            "LR: 8.884691497286108e-05\n",
            "Train loss: 1.0968793630599976\n",
            "\n",
            "Time (s): 0.6292660236358643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 422 / 499\n",
            "LR: 8.884673543100682e-05\n",
            "Train loss: 0.6860246658325195\n",
            "\n",
            "Time (s): 0.6294059753417969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 423 / 499\n",
            "LR: 8.884655589024102e-05\n",
            "Train loss: 0.9846951365470886\n",
            "\n",
            "Time (s): 0.6303434371948242\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 424 / 499\n",
            "LR: 8.884637635056365e-05\n",
            "Train loss: 0.8873488306999207\n",
            "\n",
            "Time (s): 0.6300256252288818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 425 / 499\n",
            "LR: 8.884619681197471e-05\n",
            "Train loss: 0.9044403433799744\n",
            "\n",
            "Time (s): 0.6255977153778076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 426 / 499\n",
            "LR: 8.88460172744742e-05\n",
            "Train loss: 0.3239331841468811\n",
            "\n",
            "Time (s): 0.6305363178253174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 427 / 499\n",
            "LR: 8.88458377380621e-05\n",
            "Train loss: 0.6399257779121399\n",
            "\n",
            "Time (s): 0.6287908554077148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 428 / 499\n",
            "LR: 8.884565820273839e-05\n",
            "Train loss: 0.567093014717102\n",
            "\n",
            "Time (s): 0.6291420459747314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 429 / 499\n",
            "LR: 8.884547866850304e-05\n",
            "Train loss: 0.736624002456665\n",
            "\n",
            "Time (s): 0.6286306381225586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 430 / 499\n",
            "LR: 8.884529913535609e-05\n",
            "Train loss: 0.6544579863548279\n",
            "\n",
            "Time (s): 0.6307940483093262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 431 / 499\n",
            "LR: 8.884511960329747e-05\n",
            "Train loss: 0.2488110065460205\n",
            "\n",
            "Time (s): 0.6284351348876953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 432 / 499\n",
            "LR: 8.884494007232724e-05\n",
            "Train loss: 0.33617064356803894\n",
            "\n",
            "Time (s): 0.6289083957672119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 433 / 499\n",
            "LR: 8.884476054244534e-05\n",
            "Train loss: 0.7842367887496948\n",
            "\n",
            "Time (s): 0.6290154457092285\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 434 / 499\n",
            "LR: 8.884458101365177e-05\n",
            "Train loss: 0.8368328213691711\n",
            "\n",
            "Time (s): 0.6294000148773193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 435 / 499\n",
            "LR: 8.88444014859465e-05\n",
            "Train loss: 0.9435321688652039\n",
            "\n",
            "Time (s): 0.6297905445098877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 436 / 499\n",
            "LR: 8.884422195932956e-05\n",
            "Train loss: 0.46040764451026917\n",
            "\n",
            "Time (s): 0.6291005611419678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 437 / 499\n",
            "LR: 8.88440424338009e-05\n",
            "Train loss: 0.33838126063346863\n",
            "\n",
            "Time (s): 0.6289587020874023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 438 / 499\n",
            "LR: 8.884386290936053e-05\n",
            "Train loss: 1.12875235080719\n",
            "\n",
            "Time (s): 0.6291968822479248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 439 / 499\n",
            "LR: 8.884368338600844e-05\n",
            "Train loss: 0.6181697845458984\n",
            "\n",
            "Time (s): 0.6285152435302734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 440 / 499\n",
            "LR: 8.884350386374461e-05\n",
            "Train loss: 0.5571858286857605\n",
            "\n",
            "Time (s): 0.6263296604156494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 441 / 499\n",
            "LR: 8.884332434256904e-05\n",
            "Train loss: 0.6996863484382629\n",
            "\n",
            "Time (s): 0.6242148876190186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 442 / 499\n",
            "LR: 8.88431448224817e-05\n",
            "Train loss: 0.8664645552635193\n",
            "\n",
            "Time (s): 0.6249034404754639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 443 / 499\n",
            "LR: 8.884296530348259e-05\n",
            "Train loss: 0.8628525137901306\n",
            "\n",
            "Time (s): 0.6304948329925537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 444 / 499\n",
            "LR: 8.88427857855717e-05\n",
            "Train loss: 0.8446916341781616\n",
            "\n",
            "Time (s): 0.625481367111206\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 445 / 499\n",
            "LR: 8.884260626874902e-05\n",
            "Train loss: 0.7444214224815369\n",
            "\n",
            "Time (s): 0.624589204788208\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 446 / 499\n",
            "LR: 8.884242675301455e-05\n",
            "Train loss: 0.6450868844985962\n",
            "\n",
            "Time (s): 0.6301784515380859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 447 / 499\n",
            "LR: 8.884224723836825e-05\n",
            "Train loss: 1.2798960208892822\n",
            "\n",
            "Time (s): 0.629260778427124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 448 / 499\n",
            "LR: 8.884206772481011e-05\n",
            "Train loss: 0.9885051250457764\n",
            "\n",
            "Time (s): 0.6248836517333984\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 449 / 499\n",
            "LR: 8.884188821234017e-05\n",
            "Train loss: 0.869958758354187\n",
            "\n",
            "Time (s): 0.6258213520050049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 450 / 499\n",
            "LR: 8.884170870095835e-05\n",
            "Train loss: 1.1828587055206299\n",
            "\n",
            "Time (s): 0.6305043697357178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 451 / 499\n",
            "LR: 8.88415291906647e-05\n",
            "Train loss: 1.1119358539581299\n",
            "\n",
            "Time (s): 0.6304380893707275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 452 / 499\n",
            "LR: 8.884134968145918e-05\n",
            "Train loss: 0.9132784008979797\n",
            "\n",
            "Time (s): 0.624330997467041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 453 / 499\n",
            "LR: 8.884117017334177e-05\n",
            "Train loss: 0.8457112908363342\n",
            "\n",
            "Time (s): 0.6293139457702637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 454 / 499\n",
            "LR: 8.884099066631246e-05\n",
            "Train loss: 1.0685083866119385\n",
            "\n",
            "Time (s): 0.6260709762573242\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 455 / 499\n",
            "LR: 8.884081116037128e-05\n",
            "Train loss: 0.4312221109867096\n",
            "\n",
            "Time (s): 0.6278915405273438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 456 / 499\n",
            "LR: 8.884063165551814e-05\n",
            "Train loss: 0.6426637172698975\n",
            "\n",
            "Time (s): 0.6286346912384033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 457 / 499\n",
            "LR: 8.884045215175311e-05\n",
            "Train loss: 0.8469817638397217\n",
            "\n",
            "Time (s): 0.6245262622833252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 458 / 499\n",
            "LR: 8.884027264907612e-05\n",
            "Train loss: 1.0327917337417603\n",
            "\n",
            "Time (s): 0.6273298263549805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 459 / 499\n",
            "LR: 8.884009314748722e-05\n",
            "Train loss: 0.7011799216270447\n",
            "\n",
            "Time (s): 0.6306290626525879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 460 / 499\n",
            "LR: 8.883991364698635e-05\n",
            "Train loss: 1.310875415802002\n",
            "\n",
            "Time (s): 0.6294903755187988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 461 / 499\n",
            "LR: 8.88397341475735e-05\n",
            "Train loss: 0.7731080055236816\n",
            "\n",
            "Time (s): 0.6248867511749268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 462 / 499\n",
            "LR: 8.883955464924868e-05\n",
            "Train loss: 0.7706342339515686\n",
            "\n",
            "Time (s): 0.6251177787780762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 463 / 499\n",
            "LR: 8.883937515201187e-05\n",
            "Train loss: 1.3529510498046875\n",
            "\n",
            "Time (s): 0.6264407634735107\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 464 / 499\n",
            "LR: 8.883919565586305e-05\n",
            "Train loss: 1.4060863256454468\n",
            "\n",
            "Time (s): 0.6298742294311523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 465 / 499\n",
            "LR: 8.883901616080224e-05\n",
            "Train loss: 0.9858906269073486\n",
            "\n",
            "Time (s): 0.629033088684082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 466 / 499\n",
            "LR: 8.88388366668294e-05\n",
            "Train loss: 0.7058168649673462\n",
            "\n",
            "Time (s): 0.6296091079711914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 467 / 499\n",
            "LR: 8.883865717394453e-05\n",
            "Train loss: 1.1820911169052124\n",
            "\n",
            "Time (s): 0.628544807434082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 468 / 499\n",
            "LR: 8.88384776821476e-05\n",
            "Train loss: 0.7122327089309692\n",
            "\n",
            "Time (s): 0.6255578994750977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 469 / 499\n",
            "LR: 8.883829819143862e-05\n",
            "Train loss: 0.9552054405212402\n",
            "\n",
            "Time (s): 0.6250734329223633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 470 / 499\n",
            "LR: 8.883811870181757e-05\n",
            "Train loss: 0.4206213355064392\n",
            "\n",
            "Time (s): 0.6242966651916504\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 471 / 499\n",
            "LR: 8.883793921328445e-05\n",
            "Train loss: 0.7471933960914612\n",
            "\n",
            "Time (s): 0.6308009624481201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 472 / 499\n",
            "LR: 8.883775972583924e-05\n",
            "Train loss: 0.7975884675979614\n",
            "\n",
            "Time (s): 0.6285552978515625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 473 / 499\n",
            "LR: 8.883758023948193e-05\n",
            "Train loss: 1.1785799264907837\n",
            "\n",
            "Time (s): 0.6257803440093994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 474 / 499\n",
            "LR: 8.883740075421249e-05\n",
            "Train loss: 0.7958089113235474\n",
            "\n",
            "Time (s): 0.6298727989196777\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 475 / 499\n",
            "LR: 8.883722127003096e-05\n",
            "Train loss: 0.5705493688583374\n",
            "\n",
            "Time (s): 0.6297607421875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 476 / 499\n",
            "LR: 8.883704178693729e-05\n",
            "Train loss: 0.8520640730857849\n",
            "\n",
            "Time (s): 0.6291139125823975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 477 / 499\n",
            "LR: 8.883686230493147e-05\n",
            "Train loss: 1.066176414489746\n",
            "\n",
            "Time (s): 0.6295807361602783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 478 / 499\n",
            "LR: 8.88366828240135e-05\n",
            "Train loss: 0.9193195104598999\n",
            "\n",
            "Time (s): 0.6255695819854736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 479 / 499\n",
            "LR: 8.883650334418335e-05\n",
            "Train loss: 0.6413470506668091\n",
            "\n",
            "Time (s): 0.6288161277770996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 480 / 499\n",
            "LR: 8.883632386544104e-05\n",
            "Train loss: 0.35337308049201965\n",
            "\n",
            "Time (s): 0.6248171329498291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 481 / 499\n",
            "LR: 8.883614438778655e-05\n",
            "Train loss: 0.9776952862739563\n",
            "\n",
            "Time (s): 0.6242325305938721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 482 / 499\n",
            "LR: 8.883596491121984e-05\n",
            "Train loss: 1.2648745775222778\n",
            "\n",
            "Time (s): 0.6244962215423584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 483 / 499\n",
            "LR: 8.883578543574093e-05\n",
            "Train loss: 0.6821101903915405\n",
            "\n",
            "Time (s): 0.6293106079101562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 484 / 499\n",
            "LR: 8.88356059613498e-05\n",
            "Train loss: 0.8296434283256531\n",
            "\n",
            "Time (s): 0.6287105083465576\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 485 / 499\n",
            "LR: 8.883542648804644e-05\n",
            "Train loss: 1.2962026596069336\n",
            "\n",
            "Time (s): 0.6289010047912598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 486 / 499\n",
            "LR: 8.883524701583084e-05\n",
            "Train loss: 1.2290682792663574\n",
            "\n",
            "Time (s): 0.6292033195495605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 487 / 499\n",
            "LR: 8.883506754470297e-05\n",
            "Train loss: 0.632352352142334\n",
            "\n",
            "Time (s): 0.6260159015655518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 488 / 499\n",
            "LR: 8.883488807466285e-05\n",
            "Train loss: 0.31502649188041687\n",
            "\n",
            "Time (s): 0.627685546875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 489 / 499\n",
            "LR: 8.883470860571047e-05\n",
            "Train loss: 0.9415298104286194\n",
            "\n",
            "Time (s): 0.6301846504211426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 490 / 499\n",
            "LR: 8.883452913784577e-05\n",
            "Train loss: 0.9121239185333252\n",
            "\n",
            "Time (s): 0.6247663497924805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 491 / 499\n",
            "LR: 8.883434967106879e-05\n",
            "Train loss: 0.7259165048599243\n",
            "\n",
            "Time (s): 0.6289525032043457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 492 / 499\n",
            "LR: 8.883417020537949e-05\n",
            "Train loss: 0.9381181001663208\n",
            "\n",
            "Time (s): 0.628986120223999\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 493 / 499\n",
            "LR: 8.883399074077788e-05\n",
            "Train loss: 1.272481918334961\n",
            "\n",
            "Time (s): 0.6267390251159668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 494 / 499\n",
            "LR: 8.883381127726395e-05\n",
            "Train loss: 0.5760090947151184\n",
            "\n",
            "Time (s): 0.6311435699462891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 495 / 499\n",
            "LR: 8.883363181483767e-05\n",
            "Train loss: 1.158414363861084\n",
            "\n",
            "Time (s): 0.6248164176940918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 496 / 499\n",
            "LR: 8.883345235349904e-05\n",
            "Train loss: 1.3992185592651367\n",
            "\n",
            "Time (s): 0.6250050067901611\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 497 / 499\n",
            "LR: 8.883327289324805e-05\n",
            "Train loss: 0.9741195440292358\n",
            "\n",
            "Time (s): 0.6273353099822998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 498 / 499\n",
            "LR: 8.883309343408468e-05\n",
            "Train loss: 0.6160473227500916\n",
            "\n",
            "Time (s): 0.6284818649291992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 496  Batch 499 / 499\n",
            "LR: 8.883291397600891e-05\n",
            "Train loss: 0.2741086184978485\n",
            "\n",
            "Time (s): 0.054029226303100586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 496\n",
            "Avg train loss: 0.7015064304660938\n",
            "Avg train acc: 0.7920489382887174\n",
            "Avg eval loss: 0.9310732396209941\n",
            "Avg eval acc: 0.7460646418964162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 497\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 1 / 499\n",
            "LR: 8.883273451902077e-05\n",
            "Train loss: 0.9477550983428955\n",
            "\n",
            "Time (s): 0.6397767066955566\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 2 / 499\n",
            "LR: 8.883255506312022e-05\n",
            "Train loss: 0.5995286703109741\n",
            "\n",
            "Time (s): 0.6361246109008789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 3 / 499\n",
            "LR: 8.883237560830723e-05\n",
            "Train loss: 0.5392432808876038\n",
            "\n",
            "Time (s): 0.6373631954193115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 4 / 499\n",
            "LR: 8.883219615458183e-05\n",
            "Train loss: 1.2731560468673706\n",
            "\n",
            "Time (s): 0.6300632953643799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 5 / 499\n",
            "LR: 8.883201670194399e-05\n",
            "Train loss: 1.3694355487823486\n",
            "\n",
            "Time (s): 0.6251692771911621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 6 / 499\n",
            "LR: 8.883183725039369e-05\n",
            "Train loss: 0.8030422925949097\n",
            "\n",
            "Time (s): 0.6302568912506104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 7 / 499\n",
            "LR: 8.883165779993093e-05\n",
            "Train loss: 0.6582207083702087\n",
            "\n",
            "Time (s): 0.630467414855957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 8 / 499\n",
            "LR: 8.88314783505557e-05\n",
            "Train loss: 0.8319669365882874\n",
            "\n",
            "Time (s): 0.6290373802185059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 9 / 499\n",
            "LR: 8.883129890226797e-05\n",
            "Train loss: 1.2326788902282715\n",
            "\n",
            "Time (s): 0.6299357414245605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 10 / 499\n",
            "LR: 8.883111945506776e-05\n",
            "Train loss: 0.7736688852310181\n",
            "\n",
            "Time (s): 0.6275954246520996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 11 / 499\n",
            "LR: 8.883094000895505e-05\n",
            "Train loss: 0.39777591824531555\n",
            "\n",
            "Time (s): 0.6290450096130371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 12 / 499\n",
            "LR: 8.883076056392982e-05\n",
            "Train loss: 0.9162079691886902\n",
            "\n",
            "Time (s): 0.62892746925354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 13 / 499\n",
            "LR: 8.883058111999207e-05\n",
            "Train loss: 0.7461040616035461\n",
            "\n",
            "Time (s): 0.6311933994293213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 14 / 499\n",
            "LR: 8.883040167714175e-05\n",
            "Train loss: 1.0374436378479004\n",
            "\n",
            "Time (s): 0.6296255588531494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 15 / 499\n",
            "LR: 8.88302222353789e-05\n",
            "Train loss: 0.49117311835289\n",
            "\n",
            "Time (s): 0.6281993389129639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 16 / 499\n",
            "LR: 8.88300427947035e-05\n",
            "Train loss: 0.5212893486022949\n",
            "\n",
            "Time (s): 0.631190299987793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 17 / 499\n",
            "LR: 8.882986335511551e-05\n",
            "Train loss: 1.357901930809021\n",
            "\n",
            "Time (s): 0.6297829151153564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 18 / 499\n",
            "LR: 8.882968391661495e-05\n",
            "Train loss: 0.596024215221405\n",
            "\n",
            "Time (s): 0.6297702789306641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 19 / 499\n",
            "LR: 8.88295044792018e-05\n",
            "Train loss: 1.0631790161132812\n",
            "\n",
            "Time (s): 0.6297202110290527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 20 / 499\n",
            "LR: 8.882932504287602e-05\n",
            "Train loss: 0.5780377984046936\n",
            "\n",
            "Time (s): 0.6297767162322998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 21 / 499\n",
            "LR: 8.882914560763763e-05\n",
            "Train loss: 0.8763644099235535\n",
            "\n",
            "Time (s): 0.629810094833374\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 22 / 499\n",
            "LR: 8.882896617348663e-05\n",
            "Train loss: 0.887660801410675\n",
            "\n",
            "Time (s): 0.6302762031555176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 23 / 499\n",
            "LR: 8.882878674042298e-05\n",
            "Train loss: 1.1593338251113892\n",
            "\n",
            "Time (s): 0.6295170783996582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 24 / 499\n",
            "LR: 8.882860730844669e-05\n",
            "Train loss: 0.793693482875824\n",
            "\n",
            "Time (s): 0.6300749778747559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 25 / 499\n",
            "LR: 8.882842787755775e-05\n",
            "Train loss: 1.3947746753692627\n",
            "\n",
            "Time (s): 0.629833459854126\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 26 / 499\n",
            "LR: 8.882824844775611e-05\n",
            "Train loss: 0.6104205846786499\n",
            "\n",
            "Time (s): 0.629779577255249\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 27 / 499\n",
            "LR: 8.882806901904181e-05\n",
            "Train loss: 0.5813862085342407\n",
            "\n",
            "Time (s): 0.6293332576751709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 28 / 499\n",
            "LR: 8.88278895914148e-05\n",
            "Train loss: 1.076135277748108\n",
            "\n",
            "Time (s): 0.6316134929656982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 29 / 499\n",
            "LR: 8.882771016487509e-05\n",
            "Train loss: 1.3580601215362549\n",
            "\n",
            "Time (s): 0.6257467269897461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 30 / 499\n",
            "LR: 8.882753073942267e-05\n",
            "Train loss: 1.1654974222183228\n",
            "\n",
            "Time (s): 0.6297609806060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 31 / 499\n",
            "LR: 8.882735131505754e-05\n",
            "Train loss: 1.4380110502243042\n",
            "\n",
            "Time (s): 0.6279432773590088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 32 / 499\n",
            "LR: 8.882717189177967e-05\n",
            "Train loss: 0.769340455532074\n",
            "\n",
            "Time (s): 0.6282684803009033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 33 / 499\n",
            "LR: 8.882699246958902e-05\n",
            "Train loss: 1.3255605697631836\n",
            "\n",
            "Time (s): 0.6296999454498291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 34 / 499\n",
            "LR: 8.882681304848564e-05\n",
            "Train loss: 1.0268007516860962\n",
            "\n",
            "Time (s): 0.6288912296295166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 35 / 499\n",
            "LR: 8.882663362846948e-05\n",
            "Train loss: 1.1679730415344238\n",
            "\n",
            "Time (s): 0.6298019886016846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 36 / 499\n",
            "LR: 8.882645420954055e-05\n",
            "Train loss: 0.8634961843490601\n",
            "\n",
            "Time (s): 0.6287755966186523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 37 / 499\n",
            "LR: 8.882627479169883e-05\n",
            "Train loss: 0.7269067168235779\n",
            "\n",
            "Time (s): 0.6260473728179932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 38 / 499\n",
            "LR: 8.882609537494429e-05\n",
            "Train loss: 0.5854123830795288\n",
            "\n",
            "Time (s): 0.6304116249084473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 39 / 499\n",
            "LR: 8.882591595927695e-05\n",
            "Train loss: 1.2220903635025024\n",
            "\n",
            "Time (s): 0.6295871734619141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 40 / 499\n",
            "LR: 8.882573654469678e-05\n",
            "Train loss: 0.97781902551651\n",
            "\n",
            "Time (s): 0.6303958892822266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 41 / 499\n",
            "LR: 8.882555713120376e-05\n",
            "Train loss: 0.5941998362541199\n",
            "\n",
            "Time (s): 0.6291944980621338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 42 / 499\n",
            "LR: 8.882537771879792e-05\n",
            "Train loss: 0.7721878290176392\n",
            "\n",
            "Time (s): 0.6291234493255615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 43 / 499\n",
            "LR: 8.882519830747922e-05\n",
            "Train loss: 0.5156735181808472\n",
            "\n",
            "Time (s): 0.6283853054046631\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 44 / 499\n",
            "LR: 8.882501889724764e-05\n",
            "Train loss: 0.7159075140953064\n",
            "\n",
            "Time (s): 0.6286687850952148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 45 / 499\n",
            "LR: 8.882483948810318e-05\n",
            "Train loss: 1.1034977436065674\n",
            "\n",
            "Time (s): 0.6261467933654785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 46 / 499\n",
            "LR: 8.882466008004584e-05\n",
            "Train loss: 0.4617147147655487\n",
            "\n",
            "Time (s): 0.6290779113769531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 47 / 499\n",
            "LR: 8.882448067307559e-05\n",
            "Train loss: 0.9863715171813965\n",
            "\n",
            "Time (s): 0.6288423538208008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 48 / 499\n",
            "LR: 8.882430126719243e-05\n",
            "Train loss: 0.8040709495544434\n",
            "\n",
            "Time (s): 0.6286661624908447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 49 / 499\n",
            "LR: 8.882412186239634e-05\n",
            "Train loss: 1.0687170028686523\n",
            "\n",
            "Time (s): 0.6284434795379639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 50 / 499\n",
            "LR: 8.882394245868733e-05\n",
            "Train loss: 0.7768842577934265\n",
            "\n",
            "Time (s): 0.6286125183105469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 51 / 499\n",
            "LR: 8.882376305606537e-05\n",
            "Train loss: 0.5085781216621399\n",
            "\n",
            "Time (s): 0.6293840408325195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 52 / 499\n",
            "LR: 8.882358365453045e-05\n",
            "Train loss: 1.173948049545288\n",
            "\n",
            "Time (s): 0.6296632289886475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 53 / 499\n",
            "LR: 8.882340425408257e-05\n",
            "Train loss: 0.5459418296813965\n",
            "\n",
            "Time (s): 0.626863956451416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 54 / 499\n",
            "LR: 8.882322485472169e-05\n",
            "Train loss: 1.0714826583862305\n",
            "\n",
            "Time (s): 0.6291873455047607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 55 / 499\n",
            "LR: 8.882304545644785e-05\n",
            "Train loss: 0.6781809329986572\n",
            "\n",
            "Time (s): 0.6298880577087402\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 56 / 499\n",
            "LR: 8.882286605926099e-05\n",
            "Train loss: 0.38835689425468445\n",
            "\n",
            "Time (s): 0.6295742988586426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 57 / 499\n",
            "LR: 8.882268666316112e-05\n",
            "Train loss: 0.49302420020103455\n",
            "\n",
            "Time (s): 0.6335952281951904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 58 / 499\n",
            "LR: 8.882250726814825e-05\n",
            "Train loss: 1.0170252323150635\n",
            "\n",
            "Time (s): 0.6284961700439453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 59 / 499\n",
            "LR: 8.882232787422232e-05\n",
            "Train loss: 0.4659367799758911\n",
            "\n",
            "Time (s): 0.6251165866851807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 60 / 499\n",
            "LR: 8.882214848138334e-05\n",
            "Train loss: 0.7624233961105347\n",
            "\n",
            "Time (s): 0.6282958984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 61 / 499\n",
            "LR: 8.882196908963132e-05\n",
            "Train loss: 1.0705642700195312\n",
            "\n",
            "Time (s): 0.6284160614013672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 62 / 499\n",
            "LR: 8.882178969896625e-05\n",
            "Train loss: 0.32921239733695984\n",
            "\n",
            "Time (s): 0.6253163814544678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 63 / 499\n",
            "LR: 8.882161030938808e-05\n",
            "Train loss: 0.7216696739196777\n",
            "\n",
            "Time (s): 0.6283466815948486\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 64 / 499\n",
            "LR: 8.882143092089683e-05\n",
            "Train loss: 0.8803002834320068\n",
            "\n",
            "Time (s): 0.6269714832305908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 65 / 499\n",
            "LR: 8.882125153349248e-05\n",
            "Train loss: 0.2897184193134308\n",
            "\n",
            "Time (s): 0.6242775917053223\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 66 / 499\n",
            "LR: 8.882107214717502e-05\n",
            "Train loss: 0.835205078125\n",
            "\n",
            "Time (s): 0.6288762092590332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 67 / 499\n",
            "LR: 8.882089276194444e-05\n",
            "Train loss: 1.0760958194732666\n",
            "\n",
            "Time (s): 0.6244266033172607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 68 / 499\n",
            "LR: 8.882071337780074e-05\n",
            "Train loss: 1.1291310787200928\n",
            "\n",
            "Time (s): 0.6244447231292725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 69 / 499\n",
            "LR: 8.882053399474388e-05\n",
            "Train loss: 1.0737946033477783\n",
            "\n",
            "Time (s): 0.6288261413574219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 70 / 499\n",
            "LR: 8.882035461277387e-05\n",
            "Train loss: 0.5648345947265625\n",
            "\n",
            "Time (s): 0.6289098262786865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 71 / 499\n",
            "LR: 8.882017523189069e-05\n",
            "Train loss: 0.9758806824684143\n",
            "\n",
            "Time (s): 0.6245951652526855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 72 / 499\n",
            "LR: 8.881999585209434e-05\n",
            "Train loss: 0.7690878510475159\n",
            "\n",
            "Time (s): 0.6245174407958984\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 73 / 499\n",
            "LR: 8.881981647338481e-05\n",
            "Train loss: 0.3903653025627136\n",
            "\n",
            "Time (s): 0.6277196407318115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 74 / 499\n",
            "LR: 8.881963709576207e-05\n",
            "Train loss: 1.2507978677749634\n",
            "\n",
            "Time (s): 0.6285223960876465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 75 / 499\n",
            "LR: 8.881945771922613e-05\n",
            "Train loss: 1.1237314939498901\n",
            "\n",
            "Time (s): 0.6246113777160645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 76 / 499\n",
            "LR: 8.881927834377696e-05\n",
            "Train loss: 0.5714682936668396\n",
            "\n",
            "Time (s): 0.6291418075561523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 77 / 499\n",
            "LR: 8.881909896941458e-05\n",
            "Train loss: 0.5655306577682495\n",
            "\n",
            "Time (s): 0.6297445297241211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 78 / 499\n",
            "LR: 8.881891959613895e-05\n",
            "Train loss: 0.6765066385269165\n",
            "\n",
            "Time (s): 0.6245267391204834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 79 / 499\n",
            "LR: 8.881874022395006e-05\n",
            "Train loss: 1.0641485452651978\n",
            "\n",
            "Time (s): 0.6246597766876221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 80 / 499\n",
            "LR: 8.88185608528479e-05\n",
            "Train loss: 0.8748369216918945\n",
            "\n",
            "Time (s): 0.6245896816253662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 81 / 499\n",
            "LR: 8.881838148283248e-05\n",
            "Train loss: 0.5817163586616516\n",
            "\n",
            "Time (s): 0.624603271484375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 82 / 499\n",
            "LR: 8.881820211390378e-05\n",
            "Train loss: 0.4680485725402832\n",
            "\n",
            "Time (s): 0.6280944347381592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 83 / 499\n",
            "LR: 8.881802274606176e-05\n",
            "Train loss: 1.0717272758483887\n",
            "\n",
            "Time (s): 0.6252896785736084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 84 / 499\n",
            "LR: 8.881784337930644e-05\n",
            "Train loss: 0.5378411412239075\n",
            "\n",
            "Time (s): 0.6294770240783691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 85 / 499\n",
            "LR: 8.881766401363782e-05\n",
            "Train loss: 0.3435557186603546\n",
            "\n",
            "Time (s): 0.6294341087341309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 86 / 499\n",
            "LR: 8.881748464905586e-05\n",
            "Train loss: 0.5051536560058594\n",
            "\n",
            "Time (s): 0.626420259475708\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 87 / 499\n",
            "LR: 8.881730528556054e-05\n",
            "Train loss: 0.9794104695320129\n",
            "\n",
            "Time (s): 0.6254589557647705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 88 / 499\n",
            "LR: 8.881712592315191e-05\n",
            "Train loss: 1.0943551063537598\n",
            "\n",
            "Time (s): 0.6247682571411133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 89 / 499\n",
            "LR: 8.881694656182989e-05\n",
            "Train loss: 0.4332343339920044\n",
            "\n",
            "Time (s): 0.6291646957397461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 90 / 499\n",
            "LR: 8.88167672015945e-05\n",
            "Train loss: 0.664580225944519\n",
            "\n",
            "Time (s): 0.6294825077056885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 91 / 499\n",
            "LR: 8.881658784244573e-05\n",
            "Train loss: 0.33350783586502075\n",
            "\n",
            "Time (s): 0.6247167587280273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 92 / 499\n",
            "LR: 8.881640848438355e-05\n",
            "Train loss: 0.5221912264823914\n",
            "\n",
            "Time (s): 0.6281752586364746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 93 / 499\n",
            "LR: 8.881622912740798e-05\n",
            "Train loss: 0.4435320496559143\n",
            "\n",
            "Time (s): 0.6299788951873779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 94 / 499\n",
            "LR: 8.881604977151899e-05\n",
            "Train loss: 0.6596583127975464\n",
            "\n",
            "Time (s): 0.6296844482421875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 95 / 499\n",
            "LR: 8.881587041671655e-05\n",
            "Train loss: 1.0102455615997314\n",
            "\n",
            "Time (s): 0.6288020610809326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 96 / 499\n",
            "LR: 8.881569106300071e-05\n",
            "Train loss: 1.338550090789795\n",
            "\n",
            "Time (s): 0.6247398853302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 97 / 499\n",
            "LR: 8.881551171037139e-05\n",
            "Train loss: 0.5344551801681519\n",
            "\n",
            "Time (s): 0.6246135234832764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 98 / 499\n",
            "LR: 8.881533235882862e-05\n",
            "Train loss: 1.3554861545562744\n",
            "\n",
            "Time (s): 0.6241867542266846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 99 / 499\n",
            "LR: 8.881515300837238e-05\n",
            "Train loss: 1.1002826690673828\n",
            "\n",
            "Time (s): 0.6304061412811279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 100 / 499\n",
            "LR: 8.881497365900266e-05\n",
            "Train loss: 0.8753937482833862\n",
            "\n",
            "Time (s): 0.6239948272705078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 101 / 499\n",
            "LR: 8.881479431071943e-05\n",
            "Train loss: 0.32655125856399536\n",
            "\n",
            "Time (s): 0.6282863616943359\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 102 / 499\n",
            "LR: 8.881461496352271e-05\n",
            "Train loss: 0.8010427355766296\n",
            "\n",
            "Time (s): 0.6285383701324463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 103 / 499\n",
            "LR: 8.881443561741246e-05\n",
            "Train loss: 0.5542776584625244\n",
            "\n",
            "Time (s): 0.6258339881896973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 104 / 499\n",
            "LR: 8.881425627238871e-05\n",
            "Train loss: 0.679554283618927\n",
            "\n",
            "Time (s): 0.6277182102203369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 105 / 499\n",
            "LR: 8.88140769284514e-05\n",
            "Train loss: 1.1635164022445679\n",
            "\n",
            "Time (s): 0.6291213035583496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 106 / 499\n",
            "LR: 8.881389758560054e-05\n",
            "Train loss: 0.824023962020874\n",
            "\n",
            "Time (s): 0.6286704540252686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 107 / 499\n",
            "LR: 8.881371824383614e-05\n",
            "Train loss: 0.9877831339836121\n",
            "\n",
            "Time (s): 0.6249322891235352\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 108 / 499\n",
            "LR: 8.881353890315813e-05\n",
            "Train loss: 0.43669795989990234\n",
            "\n",
            "Time (s): 0.6310787200927734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 109 / 499\n",
            "LR: 8.881335956356658e-05\n",
            "Train loss: 0.9423086047172546\n",
            "\n",
            "Time (s): 0.6285364627838135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 110 / 499\n",
            "LR: 8.881318022506143e-05\n",
            "Train loss: 0.7047858834266663\n",
            "\n",
            "Time (s): 0.6356453895568848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 111 / 499\n",
            "LR: 8.881300088764265e-05\n",
            "Train loss: 0.6332089900970459\n",
            "\n",
            "Time (s): 0.6291613578796387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 112 / 499\n",
            "LR: 8.881282155131027e-05\n",
            "Train loss: 0.703106164932251\n",
            "\n",
            "Time (s): 0.6295604705810547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 113 / 499\n",
            "LR: 8.881264221606427e-05\n",
            "Train loss: 0.7455323338508606\n",
            "\n",
            "Time (s): 0.6247169971466064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 114 / 499\n",
            "LR: 8.881246288190464e-05\n",
            "Train loss: 1.0361700057983398\n",
            "\n",
            "Time (s): 0.6286835670471191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 115 / 499\n",
            "LR: 8.881228354883136e-05\n",
            "Train loss: 0.34209704399108887\n",
            "\n",
            "Time (s): 0.624690055847168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 116 / 499\n",
            "LR: 8.88121042168444e-05\n",
            "Train loss: 1.0722432136535645\n",
            "\n",
            "Time (s): 0.6249973773956299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 117 / 499\n",
            "LR: 8.881192488594378e-05\n",
            "Train loss: 0.8748237490653992\n",
            "\n",
            "Time (s): 0.6330661773681641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 118 / 499\n",
            "LR: 8.881174555612949e-05\n",
            "Train loss: 1.043856143951416\n",
            "\n",
            "Time (s): 0.6298415660858154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 119 / 499\n",
            "LR: 8.88115662274015e-05\n",
            "Train loss: 1.0635730028152466\n",
            "\n",
            "Time (s): 0.6293699741363525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 120 / 499\n",
            "LR: 8.881138689975982e-05\n",
            "Train loss: 0.9321240782737732\n",
            "\n",
            "Time (s): 0.628258466720581\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 121 / 499\n",
            "LR: 8.881120757320441e-05\n",
            "Train loss: 0.6904711723327637\n",
            "\n",
            "Time (s): 0.6294653415679932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 122 / 499\n",
            "LR: 8.88110282477353e-05\n",
            "Train loss: 1.1787364482879639\n",
            "\n",
            "Time (s): 0.6283130645751953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 123 / 499\n",
            "LR: 8.881084892335243e-05\n",
            "Train loss: 0.7139055728912354\n",
            "\n",
            "Time (s): 0.6262857913970947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 124 / 499\n",
            "LR: 8.881066960005581e-05\n",
            "Train loss: 0.8127152919769287\n",
            "\n",
            "Time (s): 0.6288316249847412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 125 / 499\n",
            "LR: 8.881049027784546e-05\n",
            "Train loss: 1.3497748374938965\n",
            "\n",
            "Time (s): 0.6243724822998047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 126 / 499\n",
            "LR: 8.881031095672132e-05\n",
            "Train loss: 0.4513810873031616\n",
            "\n",
            "Time (s): 0.6290302276611328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 127 / 499\n",
            "LR: 8.88101316366834e-05\n",
            "Train loss: 1.244377613067627\n",
            "\n",
            "Time (s): 0.6274795532226562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 128 / 499\n",
            "LR: 8.88099523177317e-05\n",
            "Train loss: 1.225440502166748\n",
            "\n",
            "Time (s): 0.6267726421356201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 129 / 499\n",
            "LR: 8.88097729998662e-05\n",
            "Train loss: 0.811022937297821\n",
            "\n",
            "Time (s): 0.6273150444030762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 130 / 499\n",
            "LR: 8.880959368308689e-05\n",
            "Train loss: 0.4797583818435669\n",
            "\n",
            "Time (s): 0.624406099319458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 131 / 499\n",
            "LR: 8.880941436739373e-05\n",
            "Train loss: 0.4856076240539551\n",
            "\n",
            "Time (s): 0.6284797191619873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 132 / 499\n",
            "LR: 8.880923505278676e-05\n",
            "Train loss: 0.6922565698623657\n",
            "\n",
            "Time (s): 0.6269326210021973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 133 / 499\n",
            "LR: 8.880905573926596e-05\n",
            "Train loss: 0.28928491473197937\n",
            "\n",
            "Time (s): 0.629326581954956\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 134 / 499\n",
            "LR: 8.880887642683128e-05\n",
            "Train loss: 1.8061476945877075\n",
            "\n",
            "Time (s): 0.6298580169677734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 135 / 499\n",
            "LR: 8.880869711548275e-05\n",
            "Train loss: 0.7851070165634155\n",
            "\n",
            "Time (s): 0.6240811347961426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 136 / 499\n",
            "LR: 8.880851780522033e-05\n",
            "Train loss: 0.8386287093162537\n",
            "\n",
            "Time (s): 0.628917932510376\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 137 / 499\n",
            "LR: 8.880833849604401e-05\n",
            "Train loss: 0.6526742577552795\n",
            "\n",
            "Time (s): 0.6283838748931885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 138 / 499\n",
            "LR: 8.88081591879538e-05\n",
            "Train loss: 0.9587646722793579\n",
            "\n",
            "Time (s): 0.6237406730651855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 139 / 499\n",
            "LR: 8.880797988094969e-05\n",
            "Train loss: 0.6423549056053162\n",
            "\n",
            "Time (s): 0.6283118724822998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 140 / 499\n",
            "LR: 8.880780057503165e-05\n",
            "Train loss: 0.7581391930580139\n",
            "\n",
            "Time (s): 0.6263065338134766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 141 / 499\n",
            "LR: 8.880762127019967e-05\n",
            "Train loss: 0.4247795641422272\n",
            "\n",
            "Time (s): 0.6239993572235107\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 142 / 499\n",
            "LR: 8.880744196645376e-05\n",
            "Train loss: 0.8721008896827698\n",
            "\n",
            "Time (s): 0.6288151741027832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 143 / 499\n",
            "LR: 8.880726266379389e-05\n",
            "Train loss: 0.9726817011833191\n",
            "\n",
            "Time (s): 0.6239490509033203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 144 / 499\n",
            "LR: 8.880708336222006e-05\n",
            "Train loss: 0.7914413809776306\n",
            "\n",
            "Time (s): 0.6291418075561523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 145 / 499\n",
            "LR: 8.880690406173223e-05\n",
            "Train loss: 0.432597279548645\n",
            "\n",
            "Time (s): 0.6288120746612549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 146 / 499\n",
            "LR: 8.880672476233044e-05\n",
            "Train loss: 1.3485054969787598\n",
            "\n",
            "Time (s): 0.6283278465270996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 147 / 499\n",
            "LR: 8.880654546401464e-05\n",
            "Train loss: 1.5972894430160522\n",
            "\n",
            "Time (s): 0.6281442642211914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 148 / 499\n",
            "LR: 8.880636616678483e-05\n",
            "Train loss: 0.8035901784896851\n",
            "\n",
            "Time (s): 0.6320631504058838\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 149 / 499\n",
            "LR: 8.8806186870641e-05\n",
            "Train loss: 0.7368823289871216\n",
            "\n",
            "Time (s): 0.6318442821502686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 150 / 499\n",
            "LR: 8.880600757558315e-05\n",
            "Train loss: 1.137598991394043\n",
            "\n",
            "Time (s): 0.6294529438018799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 151 / 499\n",
            "LR: 8.880582828161124e-05\n",
            "Train loss: 0.8185100555419922\n",
            "\n",
            "Time (s): 0.6290771961212158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 152 / 499\n",
            "LR: 8.88056489887253e-05\n",
            "Train loss: 0.7181613445281982\n",
            "\n",
            "Time (s): 0.6292731761932373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 153 / 499\n",
            "LR: 8.880546969692528e-05\n",
            "Train loss: 0.34644827246665955\n",
            "\n",
            "Time (s): 0.6285004615783691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 154 / 499\n",
            "LR: 8.880529040621118e-05\n",
            "Train loss: 0.7016046047210693\n",
            "\n",
            "Time (s): 0.6283280849456787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 155 / 499\n",
            "LR: 8.880511111658299e-05\n",
            "Train loss: 0.5064688920974731\n",
            "\n",
            "Time (s): 0.6295223236083984\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 156 / 499\n",
            "LR: 8.880493182804071e-05\n",
            "Train loss: 0.9354588389396667\n",
            "\n",
            "Time (s): 0.6244046688079834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 157 / 499\n",
            "LR: 8.880475254058433e-05\n",
            "Train loss: 0.4037928581237793\n",
            "\n",
            "Time (s): 0.6303858757019043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 158 / 499\n",
            "LR: 8.880457325421383e-05\n",
            "Train loss: 0.5356142520904541\n",
            "\n",
            "Time (s): 0.6300382614135742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 159 / 499\n",
            "LR: 8.880439396892919e-05\n",
            "Train loss: 0.3877241313457489\n",
            "\n",
            "Time (s): 0.629880428314209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 160 / 499\n",
            "LR: 8.880421468473043e-05\n",
            "Train loss: 0.6719756722450256\n",
            "\n",
            "Time (s): 0.6295270919799805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 161 / 499\n",
            "LR: 8.88040354016175e-05\n",
            "Train loss: 0.7750268578529358\n",
            "\n",
            "Time (s): 0.6287405490875244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 162 / 499\n",
            "LR: 8.880385611959039e-05\n",
            "Train loss: 0.8305741548538208\n",
            "\n",
            "Time (s): 0.6287388801574707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 163 / 499\n",
            "LR: 8.880367683864913e-05\n",
            "Train loss: 0.7954546809196472\n",
            "\n",
            "Time (s): 0.6292905807495117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 164 / 499\n",
            "LR: 8.88034975587937e-05\n",
            "Train loss: 0.9522788524627686\n",
            "\n",
            "Time (s): 0.6250109672546387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 165 / 499\n",
            "LR: 8.880331828002405e-05\n",
            "Train loss: 0.7508316040039062\n",
            "\n",
            "Time (s): 0.6296536922454834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 166 / 499\n",
            "LR: 8.880313900234018e-05\n",
            "Train loss: 0.41432514786720276\n",
            "\n",
            "Time (s): 0.6285960674285889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 167 / 499\n",
            "LR: 8.880295972574214e-05\n",
            "Train loss: 0.46038705110549927\n",
            "\n",
            "Time (s): 0.6297121047973633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 168 / 499\n",
            "LR: 8.880278045022981e-05\n",
            "Train loss: 1.1114152669906616\n",
            "\n",
            "Time (s): 0.630378007888794\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 169 / 499\n",
            "LR: 8.880260117580329e-05\n",
            "Train loss: 0.8323470950126648\n",
            "\n",
            "Time (s): 0.630441427230835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 170 / 499\n",
            "LR: 8.88024219024625e-05\n",
            "Train loss: 0.5989893078804016\n",
            "\n",
            "Time (s): 0.6286704540252686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 171 / 499\n",
            "LR: 8.880224263020745e-05\n",
            "Train loss: 1.1329618692398071\n",
            "\n",
            "Time (s): 0.6298761367797852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 172 / 499\n",
            "LR: 8.880206335903813e-05\n",
            "Train loss: 0.720910906791687\n",
            "\n",
            "Time (s): 0.6244640350341797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 173 / 499\n",
            "LR: 8.880188408895453e-05\n",
            "Train loss: 0.8258458971977234\n",
            "\n",
            "Time (s): 0.6286897659301758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 174 / 499\n",
            "LR: 8.880170481995662e-05\n",
            "Train loss: 0.4826277792453766\n",
            "\n",
            "Time (s): 0.6285970211029053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 175 / 499\n",
            "LR: 8.880152555204441e-05\n",
            "Train loss: 0.7852353453636169\n",
            "\n",
            "Time (s): 0.6251943111419678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 176 / 499\n",
            "LR: 8.880134628521789e-05\n",
            "Train loss: 0.5412408709526062\n",
            "\n",
            "Time (s): 0.6241796016693115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 177 / 499\n",
            "LR: 8.880116701947703e-05\n",
            "Train loss: 1.2588847875595093\n",
            "\n",
            "Time (s): 0.630002498626709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 178 / 499\n",
            "LR: 8.880098775482187e-05\n",
            "Train loss: 0.40331482887268066\n",
            "\n",
            "Time (s): 0.6282472610473633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 179 / 499\n",
            "LR: 8.880080849125232e-05\n",
            "Train loss: 1.0556273460388184\n",
            "\n",
            "Time (s): 0.6293253898620605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 180 / 499\n",
            "LR: 8.880062922876843e-05\n",
            "Train loss: 1.0151816606521606\n",
            "\n",
            "Time (s): 0.6260488033294678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 181 / 499\n",
            "LR: 8.880044996737014e-05\n",
            "Train loss: 0.7053364515304565\n",
            "\n",
            "Time (s): 0.6285016536712646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 182 / 499\n",
            "LR: 8.88002707070575e-05\n",
            "Train loss: 1.8537942171096802\n",
            "\n",
            "Time (s): 0.6245429515838623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 183 / 499\n",
            "LR: 8.880009144783049e-05\n",
            "Train loss: 0.5599481463432312\n",
            "\n",
            "Time (s): 0.6301414966583252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 184 / 499\n",
            "LR: 8.879991218968902e-05\n",
            "Train loss: 0.9427300691604614\n",
            "\n",
            "Time (s): 0.6296381950378418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 185 / 499\n",
            "LR: 8.879973293263317e-05\n",
            "Train loss: 0.6276851892471313\n",
            "\n",
            "Time (s): 0.6273529529571533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 186 / 499\n",
            "LR: 8.879955367666287e-05\n",
            "Train loss: 0.8136774897575378\n",
            "\n",
            "Time (s): 0.627408504486084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 187 / 499\n",
            "LR: 8.879937442177816e-05\n",
            "Train loss: 1.1363375186920166\n",
            "\n",
            "Time (s): 0.6258821487426758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 188 / 499\n",
            "LR: 8.879919516797897e-05\n",
            "Train loss: 0.9087510704994202\n",
            "\n",
            "Time (s): 0.6296207904815674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 189 / 499\n",
            "LR: 8.879901591526535e-05\n",
            "Train loss: 1.1098781824111938\n",
            "\n",
            "Time (s): 0.6305618286132812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 190 / 499\n",
            "LR: 8.879883666363726e-05\n",
            "Train loss: 0.8290873169898987\n",
            "\n",
            "Time (s): 0.6294915676116943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 191 / 499\n",
            "LR: 8.879865741309466e-05\n",
            "Train loss: 0.5752153992652893\n",
            "\n",
            "Time (s): 0.6289117336273193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 192 / 499\n",
            "LR: 8.879847816363759e-05\n",
            "Train loss: 0.4929102659225464\n",
            "\n",
            "Time (s): 0.6297459602355957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 193 / 499\n",
            "LR: 8.879829891526602e-05\n",
            "Train loss: 0.6931840181350708\n",
            "\n",
            "Time (s): 0.6287932395935059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 194 / 499\n",
            "LR: 8.879811966797994e-05\n",
            "Train loss: 0.6311280727386475\n",
            "\n",
            "Time (s): 0.6282937526702881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 195 / 499\n",
            "LR: 8.879794042177932e-05\n",
            "Train loss: 1.3479650020599365\n",
            "\n",
            "Time (s): 0.6292107105255127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 196 / 499\n",
            "LR: 8.879776117666418e-05\n",
            "Train loss: 0.693568229675293\n",
            "\n",
            "Time (s): 0.624232292175293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 197 / 499\n",
            "LR: 8.879758193263448e-05\n",
            "Train loss: 1.2429940700531006\n",
            "\n",
            "Time (s): 0.6284153461456299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 198 / 499\n",
            "LR: 8.879740268969024e-05\n",
            "Train loss: 0.7417022585868835\n",
            "\n",
            "Time (s): 0.6289718151092529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 199 / 499\n",
            "LR: 8.87972234478314e-05\n",
            "Train loss: 1.1081808805465698\n",
            "\n",
            "Time (s): 0.6292893886566162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 200 / 499\n",
            "LR: 8.879704420705801e-05\n",
            "Train loss: 0.9589407444000244\n",
            "\n",
            "Time (s): 0.6300818920135498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 201 / 499\n",
            "LR: 8.879686496737002e-05\n",
            "Train loss: 0.9328766465187073\n",
            "\n",
            "Time (s): 0.6285183429718018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 202 / 499\n",
            "LR: 8.879668572876742e-05\n",
            "Train loss: 0.4672221541404724\n",
            "\n",
            "Time (s): 0.6277048587799072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 203 / 499\n",
            "LR: 8.879650649125023e-05\n",
            "Train loss: 1.2085015773773193\n",
            "\n",
            "Time (s): 0.6291489601135254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 204 / 499\n",
            "LR: 8.87963272548184e-05\n",
            "Train loss: 0.7649714946746826\n",
            "\n",
            "Time (s): 0.6250934600830078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 205 / 499\n",
            "LR: 8.879614801947193e-05\n",
            "Train loss: 0.8312948942184448\n",
            "\n",
            "Time (s): 0.6244943141937256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 206 / 499\n",
            "LR: 8.879596878521083e-05\n",
            "Train loss: 0.8763208985328674\n",
            "\n",
            "Time (s): 0.6241872310638428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 207 / 499\n",
            "LR: 8.879578955203506e-05\n",
            "Train loss: 0.7090064287185669\n",
            "\n",
            "Time (s): 0.6299862861633301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 208 / 499\n",
            "LR: 8.879561031994464e-05\n",
            "Train loss: 0.8869099020957947\n",
            "\n",
            "Time (s): 0.6262760162353516\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 209 / 499\n",
            "LR: 8.879543108893955e-05\n",
            "Train loss: 0.9952300190925598\n",
            "\n",
            "Time (s): 0.629645824432373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 210 / 499\n",
            "LR: 8.879525185901974e-05\n",
            "Train loss: 1.0212466716766357\n",
            "\n",
            "Time (s): 0.6263003349304199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 211 / 499\n",
            "LR: 8.879507263018525e-05\n",
            "Train loss: 0.9286669492721558\n",
            "\n",
            "Time (s): 0.6242485046386719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 212 / 499\n",
            "LR: 8.879489340243605e-05\n",
            "Train loss: 1.1695994138717651\n",
            "\n",
            "Time (s): 0.6287317276000977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 213 / 499\n",
            "LR: 8.879471417577213e-05\n",
            "Train loss: 0.7903563976287842\n",
            "\n",
            "Time (s): 0.6243364810943604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 214 / 499\n",
            "LR: 8.879453495019345e-05\n",
            "Train loss: 0.4375581741333008\n",
            "\n",
            "Time (s): 0.6242129802703857\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 215 / 499\n",
            "LR: 8.879435572570005e-05\n",
            "Train loss: 1.1010009050369263\n",
            "\n",
            "Time (s): 0.6293826103210449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 216 / 499\n",
            "LR: 8.87941765022919e-05\n",
            "Train loss: 0.60251784324646\n",
            "\n",
            "Time (s): 0.6298515796661377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 217 / 499\n",
            "LR: 8.879399727996898e-05\n",
            "Train loss: 0.8662721514701843\n",
            "\n",
            "Time (s): 0.6244430541992188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 218 / 499\n",
            "LR: 8.879381805873127e-05\n",
            "Train loss: 1.4386637210845947\n",
            "\n",
            "Time (s): 0.6286098957061768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 219 / 499\n",
            "LR: 8.879363883857879e-05\n",
            "Train loss: 0.3557678163051605\n",
            "\n",
            "Time (s): 0.6239151954650879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 220 / 499\n",
            "LR: 8.879345961951149e-05\n",
            "Train loss: 0.6448039412498474\n",
            "\n",
            "Time (s): 0.6281397342681885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 221 / 499\n",
            "LR: 8.879328040152942e-05\n",
            "Train loss: 1.1993235349655151\n",
            "\n",
            "Time (s): 0.6288659572601318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 222 / 499\n",
            "LR: 8.879310118463249e-05\n",
            "Train loss: 0.999147355556488\n",
            "\n",
            "Time (s): 0.6286745071411133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 223 / 499\n",
            "LR: 8.879292196882075e-05\n",
            "Train loss: 0.38077813386917114\n",
            "\n",
            "Time (s): 0.6251566410064697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 224 / 499\n",
            "LR: 8.879274275409416e-05\n",
            "Train loss: 0.8003122806549072\n",
            "\n",
            "Time (s): 0.6293947696685791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 225 / 499\n",
            "LR: 8.879256354045272e-05\n",
            "Train loss: 0.3950553834438324\n",
            "\n",
            "Time (s): 0.6247563362121582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 226 / 499\n",
            "LR: 8.879238432789641e-05\n",
            "Train loss: 1.5391714572906494\n",
            "\n",
            "Time (s): 0.6243054866790771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 227 / 499\n",
            "LR: 8.879220511642524e-05\n",
            "Train loss: 0.5107068419456482\n",
            "\n",
            "Time (s): 0.628913164138794\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 228 / 499\n",
            "LR: 8.879202590603917e-05\n",
            "Train loss: 0.7276148200035095\n",
            "\n",
            "Time (s): 0.6279008388519287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 229 / 499\n",
            "LR: 8.879184669673822e-05\n",
            "Train loss: 1.2227184772491455\n",
            "\n",
            "Time (s): 0.6244096755981445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 230 / 499\n",
            "LR: 8.879166748852234e-05\n",
            "Train loss: 0.9914308786392212\n",
            "\n",
            "Time (s): 0.6253113746643066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 231 / 499\n",
            "LR: 8.879148828139154e-05\n",
            "Train loss: 0.2879936099052429\n",
            "\n",
            "Time (s): 0.6287248134613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 232 / 499\n",
            "LR: 8.879130907534583e-05\n",
            "Train loss: 0.40305694937705994\n",
            "\n",
            "Time (s): 0.6287229061126709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 233 / 499\n",
            "LR: 8.879112987038517e-05\n",
            "Train loss: 0.8069164156913757\n",
            "\n",
            "Time (s): 0.6264233589172363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 234 / 499\n",
            "LR: 8.879095066650955e-05\n",
            "Train loss: 1.365303874015808\n",
            "\n",
            "Time (s): 0.6246640682220459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 235 / 499\n",
            "LR: 8.879077146371898e-05\n",
            "Train loss: 1.510885238647461\n",
            "\n",
            "Time (s): 0.6286458969116211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 236 / 499\n",
            "LR: 8.879059226201343e-05\n",
            "Train loss: 0.498429536819458\n",
            "\n",
            "Time (s): 0.629615068435669\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 237 / 499\n",
            "LR: 8.87904130613929e-05\n",
            "Train loss: 1.665794014930725\n",
            "\n",
            "Time (s): 0.628502368927002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 238 / 499\n",
            "LR: 8.879023386185738e-05\n",
            "Train loss: 1.2196353673934937\n",
            "\n",
            "Time (s): 0.6246862411499023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 239 / 499\n",
            "LR: 8.879005466340685e-05\n",
            "Train loss: 1.3271470069885254\n",
            "\n",
            "Time (s): 0.6286866664886475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 240 / 499\n",
            "LR: 8.87898754660413e-05\n",
            "Train loss: 1.3103523254394531\n",
            "\n",
            "Time (s): 0.6300299167633057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 241 / 499\n",
            "LR: 8.878969626976071e-05\n",
            "Train loss: 0.4961099326610565\n",
            "\n",
            "Time (s): 0.6282360553741455\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 242 / 499\n",
            "LR: 8.87895170745651e-05\n",
            "Train loss: 0.49558278918266296\n",
            "\n",
            "Time (s): 0.628302812576294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 243 / 499\n",
            "LR: 8.878933788045443e-05\n",
            "Train loss: 0.7652865648269653\n",
            "\n",
            "Time (s): 0.6288995742797852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 244 / 499\n",
            "LR: 8.87891586874287e-05\n",
            "Train loss: 1.094736099243164\n",
            "\n",
            "Time (s): 0.6301634311676025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 245 / 499\n",
            "LR: 8.87889794954879e-05\n",
            "Train loss: 0.46943461894989014\n",
            "\n",
            "Time (s): 0.624579906463623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 246 / 499\n",
            "LR: 8.878880030463202e-05\n",
            "Train loss: 0.6977044939994812\n",
            "\n",
            "Time (s): 0.6249535083770752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 247 / 499\n",
            "LR: 8.878862111486103e-05\n",
            "Train loss: 0.8707398772239685\n",
            "\n",
            "Time (s): 0.6291472911834717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 248 / 499\n",
            "LR: 8.878844192617495e-05\n",
            "Train loss: 0.6981602907180786\n",
            "\n",
            "Time (s): 0.6290640830993652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 249 / 499\n",
            "LR: 8.878826273857374e-05\n",
            "Train loss: 0.9079758524894714\n",
            "\n",
            "Time (s): 0.6268742084503174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 250 / 499\n",
            "LR: 8.878808355205741e-05\n",
            "Train loss: 0.8575612306594849\n",
            "\n",
            "Time (s): 0.6278307437896729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 251 / 499\n",
            "LR: 8.878790436662597e-05\n",
            "Train loss: 1.1572966575622559\n",
            "\n",
            "Time (s): 0.6295068264007568\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 252 / 499\n",
            "LR: 8.878772518227934e-05\n",
            "Train loss: 1.223716139793396\n",
            "\n",
            "Time (s): 0.6243917942047119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 253 / 499\n",
            "LR: 8.878754599901757e-05\n",
            "Train loss: 1.108488917350769\n",
            "\n",
            "Time (s): 0.6245567798614502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 254 / 499\n",
            "LR: 8.878736681684063e-05\n",
            "Train loss: 0.6707399487495422\n",
            "\n",
            "Time (s): 0.6281614303588867\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 255 / 499\n",
            "LR: 8.87871876357485e-05\n",
            "Train loss: 0.9347798228263855\n",
            "\n",
            "Time (s): 0.6251668930053711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 256 / 499\n",
            "LR: 8.87870084557412e-05\n",
            "Train loss: 0.5049092173576355\n",
            "\n",
            "Time (s): 0.6290774345397949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 257 / 499\n",
            "LR: 8.878682927681867e-05\n",
            "Train loss: 0.47896355390548706\n",
            "\n",
            "Time (s): 0.6247375011444092\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 258 / 499\n",
            "LR: 8.878665009898091e-05\n",
            "Train loss: 0.8441780805587769\n",
            "\n",
            "Time (s): 0.6307740211486816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 259 / 499\n",
            "LR: 8.878647092222797e-05\n",
            "Train loss: 0.5622563362121582\n",
            "\n",
            "Time (s): 0.6245419979095459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 260 / 499\n",
            "LR: 8.878629174655977e-05\n",
            "Train loss: 0.5219817757606506\n",
            "\n",
            "Time (s): 0.6284806728363037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 261 / 499\n",
            "LR: 8.878611257197633e-05\n",
            "Train loss: 1.3206502199172974\n",
            "\n",
            "Time (s): 0.6267781257629395\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 262 / 499\n",
            "LR: 8.878593339847762e-05\n",
            "Train loss: 1.0386966466903687\n",
            "\n",
            "Time (s): 0.624427318572998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 263 / 499\n",
            "LR: 8.878575422606364e-05\n",
            "Train loss: 1.0643181800842285\n",
            "\n",
            "Time (s): 0.6299169063568115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 264 / 499\n",
            "LR: 8.878557505473439e-05\n",
            "Train loss: 1.2797726392745972\n",
            "\n",
            "Time (s): 0.6286067962646484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 265 / 499\n",
            "LR: 8.878539588448986e-05\n",
            "Train loss: 0.765376091003418\n",
            "\n",
            "Time (s): 0.628577709197998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 266 / 499\n",
            "LR: 8.878521671533003e-05\n",
            "Train loss: 0.31445300579071045\n",
            "\n",
            "Time (s): 0.6283862590789795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 267 / 499\n",
            "LR: 8.878503754725485e-05\n",
            "Train loss: 0.4809858500957489\n",
            "\n",
            "Time (s): 0.6287975311279297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 268 / 499\n",
            "LR: 8.878485838026438e-05\n",
            "Train loss: 1.1432321071624756\n",
            "\n",
            "Time (s): 0.6245288848876953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 269 / 499\n",
            "LR: 8.878467921435857e-05\n",
            "Train loss: 0.9515057802200317\n",
            "\n",
            "Time (s): 0.624347448348999\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 270 / 499\n",
            "LR: 8.878450004953739e-05\n",
            "Train loss: 0.4019167125225067\n",
            "\n",
            "Time (s): 0.6255722045898438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 271 / 499\n",
            "LR: 8.878432088580088e-05\n",
            "Train loss: 0.5138324499130249\n",
            "\n",
            "Time (s): 0.6288776397705078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 272 / 499\n",
            "LR: 8.8784141723149e-05\n",
            "Train loss: 0.5136206746101379\n",
            "\n",
            "Time (s): 0.6286289691925049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 273 / 499\n",
            "LR: 8.878396256158173e-05\n",
            "Train loss: 0.6722233295440674\n",
            "\n",
            "Time (s): 0.6292941570281982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 274 / 499\n",
            "LR: 8.878378340109907e-05\n",
            "Train loss: 1.2734005451202393\n",
            "\n",
            "Time (s): 0.6292271614074707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 275 / 499\n",
            "LR: 8.878360424170103e-05\n",
            "Train loss: 0.7129499912261963\n",
            "\n",
            "Time (s): 0.6286134719848633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 276 / 499\n",
            "LR: 8.878342508338756e-05\n",
            "Train loss: 0.2681519687175751\n",
            "\n",
            "Time (s): 0.6245059967041016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 277 / 499\n",
            "LR: 8.878324592615868e-05\n",
            "Train loss: 1.1486167907714844\n",
            "\n",
            "Time (s): 0.6314730644226074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 278 / 499\n",
            "LR: 8.878306677001434e-05\n",
            "Train loss: 0.8599172830581665\n",
            "\n",
            "Time (s): 0.6254394054412842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 279 / 499\n",
            "LR: 8.878288761495458e-05\n",
            "Train loss: 0.7946588397026062\n",
            "\n",
            "Time (s): 0.6303951740264893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 280 / 499\n",
            "LR: 8.878270846097938e-05\n",
            "Train loss: 1.4224821329116821\n",
            "\n",
            "Time (s): 0.6242024898529053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 281 / 499\n",
            "LR: 8.878252930808868e-05\n",
            "Train loss: 0.9388501644134521\n",
            "\n",
            "Time (s): 0.625434398651123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 282 / 499\n",
            "LR: 8.878235015628251e-05\n",
            "Train loss: 0.6093607544898987\n",
            "\n",
            "Time (s): 0.6286721229553223\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 283 / 499\n",
            "LR: 8.878217100556087e-05\n",
            "Train loss: 0.8233323097229004\n",
            "\n",
            "Time (s): 0.6266767978668213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 284 / 499\n",
            "LR: 8.878199185592372e-05\n",
            "Train loss: 0.7476578950881958\n",
            "\n",
            "Time (s): 0.6249420642852783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 285 / 499\n",
            "LR: 8.878181270737106e-05\n",
            "Train loss: 0.9159554839134216\n",
            "\n",
            "Time (s): 0.6290485858917236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 286 / 499\n",
            "LR: 8.878163355990287e-05\n",
            "Train loss: 0.678706169128418\n",
            "\n",
            "Time (s): 0.6297006607055664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 287 / 499\n",
            "LR: 8.878145441351914e-05\n",
            "Train loss: 0.7137792706489563\n",
            "\n",
            "Time (s): 0.6298284530639648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 288 / 499\n",
            "LR: 8.87812752682199e-05\n",
            "Train loss: 0.6473377346992493\n",
            "\n",
            "Time (s): 0.6264400482177734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 289 / 499\n",
            "LR: 8.87810961240051e-05\n",
            "Train loss: 0.7153921127319336\n",
            "\n",
            "Time (s): 0.6289889812469482\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 290 / 499\n",
            "LR: 8.878091698087472e-05\n",
            "Train loss: 0.7039211988449097\n",
            "\n",
            "Time (s): 0.6287248134613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 291 / 499\n",
            "LR: 8.878073783882877e-05\n",
            "Train loss: 1.2624996900558472\n",
            "\n",
            "Time (s): 0.6247577667236328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 292 / 499\n",
            "LR: 8.878055869786723e-05\n",
            "Train loss: 0.5058997869491577\n",
            "\n",
            "Time (s): 0.6284294128417969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 293 / 499\n",
            "LR: 8.87803795579901e-05\n",
            "Train loss: 0.9839500188827515\n",
            "\n",
            "Time (s): 0.6303989887237549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 294 / 499\n",
            "LR: 8.878020041919735e-05\n",
            "Train loss: 0.8826256990432739\n",
            "\n",
            "Time (s): 0.6306722164154053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 295 / 499\n",
            "LR: 8.878002128148901e-05\n",
            "Train loss: 0.5532276630401611\n",
            "\n",
            "Time (s): 0.6242246627807617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 296 / 499\n",
            "LR: 8.877984214486502e-05\n",
            "Train loss: 0.7772276401519775\n",
            "\n",
            "Time (s): 0.6281018257141113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 297 / 499\n",
            "LR: 8.877966300932536e-05\n",
            "Train loss: 0.8924713134765625\n",
            "\n",
            "Time (s): 0.6292963027954102\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 298 / 499\n",
            "LR: 8.87794838748701e-05\n",
            "Train loss: 1.2740954160690308\n",
            "\n",
            "Time (s): 0.6299862861633301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 299 / 499\n",
            "LR: 8.877930474149914e-05\n",
            "Train loss: 1.0051889419555664\n",
            "\n",
            "Time (s): 0.6251678466796875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 300 / 499\n",
            "LR: 8.877912560921252e-05\n",
            "Train loss: 1.3566534519195557\n",
            "\n",
            "Time (s): 0.6289963722229004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 301 / 499\n",
            "LR: 8.877894647801022e-05\n",
            "Train loss: 0.8886515498161316\n",
            "\n",
            "Time (s): 0.6262557506561279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 302 / 499\n",
            "LR: 8.877876734789221e-05\n",
            "Train loss: 1.070197582244873\n",
            "\n",
            "Time (s): 0.6297557353973389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 303 / 499\n",
            "LR: 8.877858821885852e-05\n",
            "Train loss: 1.7364237308502197\n",
            "\n",
            "Time (s): 0.6294870376586914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 304 / 499\n",
            "LR: 8.87784090909091e-05\n",
            "Train loss: 1.3390429019927979\n",
            "\n",
            "Time (s): 0.6243495941162109\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 305 / 499\n",
            "LR: 8.877822996404392e-05\n",
            "Train loss: 0.9194673895835876\n",
            "\n",
            "Time (s): 0.630241870880127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 306 / 499\n",
            "LR: 8.877805083826303e-05\n",
            "Train loss: 0.7687342762947083\n",
            "\n",
            "Time (s): 0.6300945281982422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 307 / 499\n",
            "LR: 8.87778717135664e-05\n",
            "Train loss: 0.8843092322349548\n",
            "\n",
            "Time (s): 0.6248128414154053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 308 / 499\n",
            "LR: 8.877769258995397e-05\n",
            "Train loss: 0.5825621485710144\n",
            "\n",
            "Time (s): 0.6293041706085205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 309 / 499\n",
            "LR: 8.877751346742578e-05\n",
            "Train loss: 1.1749171018600464\n",
            "\n",
            "Time (s): 0.6305208206176758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 310 / 499\n",
            "LR: 8.877733434598184e-05\n",
            "Train loss: 0.8118952512741089\n",
            "\n",
            "Time (s): 0.6245627403259277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 311 / 499\n",
            "LR: 8.877715522562208e-05\n",
            "Train loss: 0.7309247255325317\n",
            "\n",
            "Time (s): 0.6295437812805176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 312 / 499\n",
            "LR: 8.877697610634651e-05\n",
            "Train loss: 0.6760873794555664\n",
            "\n",
            "Time (s): 0.6293599605560303\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 313 / 499\n",
            "LR: 8.877679698815514e-05\n",
            "Train loss: 0.7783257961273193\n",
            "\n",
            "Time (s): 0.6303093433380127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 314 / 499\n",
            "LR: 8.877661787104794e-05\n",
            "Train loss: 0.7520614266395569\n",
            "\n",
            "Time (s): 0.6296703815460205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 315 / 499\n",
            "LR: 8.877643875502488e-05\n",
            "Train loss: 0.5463991165161133\n",
            "\n",
            "Time (s): 0.6293027400970459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 316 / 499\n",
            "LR: 8.877625964008601e-05\n",
            "Train loss: 0.9950507283210754\n",
            "\n",
            "Time (s): 0.6302700042724609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 317 / 499\n",
            "LR: 8.877608052623125e-05\n",
            "Train loss: 0.5714495182037354\n",
            "\n",
            "Time (s): 0.6296205520629883\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 318 / 499\n",
            "LR: 8.877590141346063e-05\n",
            "Train loss: 1.2598332166671753\n",
            "\n",
            "Time (s): 0.62461256980896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 319 / 499\n",
            "LR: 8.877572230177413e-05\n",
            "Train loss: 0.7072333693504333\n",
            "\n",
            "Time (s): 0.6292605400085449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 320 / 499\n",
            "LR: 8.877554319117173e-05\n",
            "Train loss: 0.9204517602920532\n",
            "\n",
            "Time (s): 0.6303071975708008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 321 / 499\n",
            "LR: 8.877536408165343e-05\n",
            "Train loss: 1.607601523399353\n",
            "\n",
            "Time (s): 0.6293435096740723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 322 / 499\n",
            "LR: 8.877518497321921e-05\n",
            "Train loss: 0.9745689630508423\n",
            "\n",
            "Time (s): 0.6293325424194336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 323 / 499\n",
            "LR: 8.877500586586906e-05\n",
            "Train loss: 1.3097987174987793\n",
            "\n",
            "Time (s): 0.6249783039093018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 324 / 499\n",
            "LR: 8.877482675960299e-05\n",
            "Train loss: 0.6354106068611145\n",
            "\n",
            "Time (s): 0.6284596920013428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 325 / 499\n",
            "LR: 8.877464765442095e-05\n",
            "Train loss: 0.7708103656768799\n",
            "\n",
            "Time (s): 0.6246795654296875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 326 / 499\n",
            "LR: 8.877446855032299e-05\n",
            "Train loss: 0.7220403552055359\n",
            "\n",
            "Time (s): 0.6297216415405273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 327 / 499\n",
            "LR: 8.877428944730903e-05\n",
            "Train loss: 1.082411527633667\n",
            "\n",
            "Time (s): 0.6242868900299072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 328 / 499\n",
            "LR: 8.877411034537909e-05\n",
            "Train loss: 1.0596606731414795\n",
            "\n",
            "Time (s): 0.6252954006195068\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 329 / 499\n",
            "LR: 8.877393124453317e-05\n",
            "Train loss: 0.7123317122459412\n",
            "\n",
            "Time (s): 0.629058837890625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 330 / 499\n",
            "LR: 8.877375214477124e-05\n",
            "Train loss: 1.0515685081481934\n",
            "\n",
            "Time (s): 0.6301681995391846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 331 / 499\n",
            "LR: 8.877357304609331e-05\n",
            "Train loss: 0.6306180357933044\n",
            "\n",
            "Time (s): 0.6292743682861328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 332 / 499\n",
            "LR: 8.877339394849934e-05\n",
            "Train loss: 0.8747655153274536\n",
            "\n",
            "Time (s): 0.6254465579986572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 333 / 499\n",
            "LR: 8.877321485198933e-05\n",
            "Train loss: 0.47104546427726746\n",
            "\n",
            "Time (s): 0.6298000812530518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 334 / 499\n",
            "LR: 8.87730357565633e-05\n",
            "Train loss: 0.8321993947029114\n",
            "\n",
            "Time (s): 0.6248807907104492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 335 / 499\n",
            "LR: 8.87728566622212e-05\n",
            "Train loss: 0.43527379631996155\n",
            "\n",
            "Time (s): 0.6246201992034912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 336 / 499\n",
            "LR: 8.877267756896304e-05\n",
            "Train loss: 1.0424597263336182\n",
            "\n",
            "Time (s): 0.6289482116699219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 337 / 499\n",
            "LR: 8.877249847678877e-05\n",
            "Train loss: 0.609332263469696\n",
            "\n",
            "Time (s): 0.6263852119445801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 338 / 499\n",
            "LR: 8.877231938569844e-05\n",
            "Train loss: 0.41412124037742615\n",
            "\n",
            "Time (s): 0.6298913955688477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 339 / 499\n",
            "LR: 8.8772140295692e-05\n",
            "Train loss: 1.0006071329116821\n",
            "\n",
            "Time (s): 0.6302018165588379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 340 / 499\n",
            "LR: 8.877196120676946e-05\n",
            "Train loss: 0.38627344369888306\n",
            "\n",
            "Time (s): 0.6285512447357178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 341 / 499\n",
            "LR: 8.877178211893078e-05\n",
            "Train loss: 1.1423606872558594\n",
            "\n",
            "Time (s): 0.6311490535736084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 342 / 499\n",
            "LR: 8.877160303217597e-05\n",
            "Train loss: 0.7305877208709717\n",
            "\n",
            "Time (s): 0.6250045299530029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 343 / 499\n",
            "LR: 8.877142394650504e-05\n",
            "Train loss: 0.9290613532066345\n",
            "\n",
            "Time (s): 0.6290314197540283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 344 / 499\n",
            "LR: 8.877124486191793e-05\n",
            "Train loss: 0.9439677000045776\n",
            "\n",
            "Time (s): 0.628413200378418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 345 / 499\n",
            "LR: 8.877106577841466e-05\n",
            "Train loss: 1.289476990699768\n",
            "\n",
            "Time (s): 0.6250710487365723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 346 / 499\n",
            "LR: 8.877088669599521e-05\n",
            "Train loss: 1.4313219785690308\n",
            "\n",
            "Time (s): 0.6310958862304688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 347 / 499\n",
            "LR: 8.877070761465958e-05\n",
            "Train loss: 1.6439332962036133\n",
            "\n",
            "Time (s): 0.625098466873169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 348 / 499\n",
            "LR: 8.877052853440775e-05\n",
            "Train loss: 0.8585565686225891\n",
            "\n",
            "Time (s): 0.6251254081726074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 349 / 499\n",
            "LR: 8.877034945523971e-05\n",
            "Train loss: 1.180328130722046\n",
            "\n",
            "Time (s): 0.6290662288665771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 350 / 499\n",
            "LR: 8.877017037715544e-05\n",
            "Train loss: 1.2321704626083374\n",
            "\n",
            "Time (s): 0.630516767501831\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 351 / 499\n",
            "LR: 8.876999130015495e-05\n",
            "Train loss: 0.8543803095817566\n",
            "\n",
            "Time (s): 0.6304328441619873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 352 / 499\n",
            "LR: 8.87698122242382e-05\n",
            "Train loss: 0.7922430634498596\n",
            "\n",
            "Time (s): 0.6288843154907227\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 353 / 499\n",
            "LR: 8.876963314940522e-05\n",
            "Train loss: 1.1583197116851807\n",
            "\n",
            "Time (s): 0.6302132606506348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 354 / 499\n",
            "LR: 8.876945407565596e-05\n",
            "Train loss: 0.5389933586120605\n",
            "\n",
            "Time (s): 0.6300692558288574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 355 / 499\n",
            "LR: 8.876927500299042e-05\n",
            "Train loss: 0.32330241799354553\n",
            "\n",
            "Time (s): 0.6287684440612793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 356 / 499\n",
            "LR: 8.876909593140861e-05\n",
            "Train loss: 0.7540794014930725\n",
            "\n",
            "Time (s): 0.6288747787475586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 357 / 499\n",
            "LR: 8.876891686091048e-05\n",
            "Train loss: 1.1305829286575317\n",
            "\n",
            "Time (s): 0.6305663585662842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 358 / 499\n",
            "LR: 8.876873779149607e-05\n",
            "Train loss: 0.42164894938468933\n",
            "\n",
            "Time (s): 0.6282498836517334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 359 / 499\n",
            "LR: 8.876855872316532e-05\n",
            "Train loss: 0.5235950350761414\n",
            "\n",
            "Time (s): 0.6263632774353027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 360 / 499\n",
            "LR: 8.876837965591825e-05\n",
            "Train loss: 0.47245872020721436\n",
            "\n",
            "Time (s): 0.6291635036468506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 361 / 499\n",
            "LR: 8.876820058975484e-05\n",
            "Train loss: 0.5183425545692444\n",
            "\n",
            "Time (s): 0.6254746913909912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 362 / 499\n",
            "LR: 8.876802152467508e-05\n",
            "Train loss: 0.7484942078590393\n",
            "\n",
            "Time (s): 0.6286680698394775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 363 / 499\n",
            "LR: 8.876784246067894e-05\n",
            "Train loss: 0.4226990044116974\n",
            "\n",
            "Time (s): 0.6262185573577881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 364 / 499\n",
            "LR: 8.876766339776645e-05\n",
            "Train loss: 0.7358448505401611\n",
            "\n",
            "Time (s): 0.6247103214263916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 365 / 499\n",
            "LR: 8.876748433593757e-05\n",
            "Train loss: 1.4626669883728027\n",
            "\n",
            "Time (s): 0.6246612071990967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 366 / 499\n",
            "LR: 8.876730527519228e-05\n",
            "Train loss: 1.0906407833099365\n",
            "\n",
            "Time (s): 0.6286022663116455\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 367 / 499\n",
            "LR: 8.876712621553058e-05\n",
            "Train loss: 0.7472405433654785\n",
            "\n",
            "Time (s): 0.6261982917785645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 368 / 499\n",
            "LR: 8.876694715695248e-05\n",
            "Train loss: 0.5296061038970947\n",
            "\n",
            "Time (s): 0.6295990943908691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 369 / 499\n",
            "LR: 8.876676809945795e-05\n",
            "Train loss: 1.073732614517212\n",
            "\n",
            "Time (s): 0.6245746612548828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 370 / 499\n",
            "LR: 8.876658904304696e-05\n",
            "Train loss: 0.9014342427253723\n",
            "\n",
            "Time (s): 0.6243455410003662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 371 / 499\n",
            "LR: 8.876640998771955e-05\n",
            "Train loss: 0.6659712791442871\n",
            "\n",
            "Time (s): 0.6296613216400146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 372 / 499\n",
            "LR: 8.876623093347565e-05\n",
            "Train loss: 1.46372652053833\n",
            "\n",
            "Time (s): 0.6251351833343506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 373 / 499\n",
            "LR: 8.87660518803153e-05\n",
            "Train loss: 0.7681182026863098\n",
            "\n",
            "Time (s): 0.6253056526184082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 374 / 499\n",
            "LR: 8.876587282823846e-05\n",
            "Train loss: 0.952043890953064\n",
            "\n",
            "Time (s): 0.6294572353363037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 375 / 499\n",
            "LR: 8.876569377724512e-05\n",
            "Train loss: 1.229175090789795\n",
            "\n",
            "Time (s): 0.6245882511138916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 376 / 499\n",
            "LR: 8.87655147273353e-05\n",
            "Train loss: 1.4179238080978394\n",
            "\n",
            "Time (s): 0.6318151950836182\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 377 / 499\n",
            "LR: 8.876533567850892e-05\n",
            "Train loss: 0.3044739067554474\n",
            "\n",
            "Time (s): 0.6296560764312744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 378 / 499\n",
            "LR: 8.876515663076604e-05\n",
            "Train loss: 1.2188870906829834\n",
            "\n",
            "Time (s): 0.6297845840454102\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 379 / 499\n",
            "LR: 8.876497758410663e-05\n",
            "Train loss: 0.5091142654418945\n",
            "\n",
            "Time (s): 0.6293179988861084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 380 / 499\n",
            "LR: 8.876479853853065e-05\n",
            "Train loss: 0.3844031095504761\n",
            "\n",
            "Time (s): 0.626101016998291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 381 / 499\n",
            "LR: 8.876461949403813e-05\n",
            "Train loss: 0.7134563326835632\n",
            "\n",
            "Time (s): 0.6299338340759277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 382 / 499\n",
            "LR: 8.876444045062903e-05\n",
            "Train loss: 1.265763521194458\n",
            "\n",
            "Time (s): 0.6252937316894531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 383 / 499\n",
            "LR: 8.876426140830333e-05\n",
            "Train loss: 1.0851669311523438\n",
            "\n",
            "Time (s): 0.6290717124938965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 384 / 499\n",
            "LR: 8.876408236706108e-05\n",
            "Train loss: 0.8479296565055847\n",
            "\n",
            "Time (s): 0.6252419948577881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 385 / 499\n",
            "LR: 8.876390332690219e-05\n",
            "Train loss: 0.6924668550491333\n",
            "\n",
            "Time (s): 0.6285996437072754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 386 / 499\n",
            "LR: 8.87637242878267e-05\n",
            "Train loss: 0.7289741635322571\n",
            "\n",
            "Time (s): 0.6256358623504639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 387 / 499\n",
            "LR: 8.876354524983461e-05\n",
            "Train loss: 0.8582761287689209\n",
            "\n",
            "Time (s): 0.6304082870483398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 388 / 499\n",
            "LR: 8.876336621292583e-05\n",
            "Train loss: 0.7733319401741028\n",
            "\n",
            "Time (s): 0.6245582103729248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 389 / 499\n",
            "LR: 8.876318717710043e-05\n",
            "Train loss: 0.5445652604103088\n",
            "\n",
            "Time (s): 0.6247613430023193\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 390 / 499\n",
            "LR: 8.876300814235839e-05\n",
            "Train loss: 1.0807214975357056\n",
            "\n",
            "Time (s): 0.6287350654602051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 391 / 499\n",
            "LR: 8.876282910869965e-05\n",
            "Train loss: 1.3882383108139038\n",
            "\n",
            "Time (s): 0.6264560222625732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 392 / 499\n",
            "LR: 8.876265007612427e-05\n",
            "Train loss: 0.5145182013511658\n",
            "\n",
            "Time (s): 0.6308038234710693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 393 / 499\n",
            "LR: 8.876247104463216e-05\n",
            "Train loss: 0.6446725130081177\n",
            "\n",
            "Time (s): 0.6303269863128662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 394 / 499\n",
            "LR: 8.876229201422336e-05\n",
            "Train loss: 0.8177545666694641\n",
            "\n",
            "Time (s): 0.6292300224304199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 395 / 499\n",
            "LR: 8.876211298489786e-05\n",
            "Train loss: 1.4807953834533691\n",
            "\n",
            "Time (s): 0.6299030780792236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 396 / 499\n",
            "LR: 8.876193395665564e-05\n",
            "Train loss: 0.9457921981811523\n",
            "\n",
            "Time (s): 0.6310675144195557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 397 / 499\n",
            "LR: 8.876175492949665e-05\n",
            "Train loss: 0.6563498973846436\n",
            "\n",
            "Time (s): 0.628852367401123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 398 / 499\n",
            "LR: 8.876157590342095e-05\n",
            "Train loss: 0.985565185546875\n",
            "\n",
            "Time (s): 0.6288845539093018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 399 / 499\n",
            "LR: 8.876139687842848e-05\n",
            "Train loss: 0.7155724763870239\n",
            "\n",
            "Time (s): 0.6291437149047852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 400 / 499\n",
            "LR: 8.876121785451923e-05\n",
            "Train loss: 0.8622763752937317\n",
            "\n",
            "Time (s): 0.6294815540313721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 401 / 499\n",
            "LR: 8.876103883169323e-05\n",
            "Train loss: 0.8465778231620789\n",
            "\n",
            "Time (s): 0.6287631988525391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 402 / 499\n",
            "LR: 8.876085980995042e-05\n",
            "Train loss: 0.36295634508132935\n",
            "\n",
            "Time (s): 0.6283953189849854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 403 / 499\n",
            "LR: 8.876068078929082e-05\n",
            "Train loss: 0.9960957169532776\n",
            "\n",
            "Time (s): 0.6291985511779785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 404 / 499\n",
            "LR: 8.87605017697144e-05\n",
            "Train loss: 0.8739694952964783\n",
            "\n",
            "Time (s): 0.6313488483428955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 405 / 499\n",
            "LR: 8.876032275122117e-05\n",
            "Train loss: 0.7073586583137512\n",
            "\n",
            "Time (s): 0.6304888725280762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 406 / 499\n",
            "LR: 8.87601437338111e-05\n",
            "Train loss: 0.42599043250083923\n",
            "\n",
            "Time (s): 0.6291632652282715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 407 / 499\n",
            "LR: 8.87599647174842e-05\n",
            "Train loss: 0.6300842761993408\n",
            "\n",
            "Time (s): 0.6285214424133301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 408 / 499\n",
            "LR: 8.875978570224042e-05\n",
            "Train loss: 0.3649649918079376\n",
            "\n",
            "Time (s): 0.6289405822753906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 409 / 499\n",
            "LR: 8.87596066880798e-05\n",
            "Train loss: 1.035020112991333\n",
            "\n",
            "Time (s): 0.6287569999694824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 410 / 499\n",
            "LR: 8.875942767500229e-05\n",
            "Train loss: 0.7542516589164734\n",
            "\n",
            "Time (s): 0.6293087005615234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 411 / 499\n",
            "LR: 8.875924866300788e-05\n",
            "Train loss: 0.5094007253646851\n",
            "\n",
            "Time (s): 0.6291160583496094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 412 / 499\n",
            "LR: 8.87590696520966e-05\n",
            "Train loss: 0.9023302793502808\n",
            "\n",
            "Time (s): 0.6289639472961426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 413 / 499\n",
            "LR: 8.875889064226838e-05\n",
            "Train loss: 0.5253279209136963\n",
            "\n",
            "Time (s): 0.6287641525268555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 414 / 499\n",
            "LR: 8.875871163352327e-05\n",
            "Train loss: 0.8372575044631958\n",
            "\n",
            "Time (s): 0.6293864250183105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 415 / 499\n",
            "LR: 8.875853262586121e-05\n",
            "Train loss: 0.6974892020225525\n",
            "\n",
            "Time (s): 0.6319596767425537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 416 / 499\n",
            "LR: 8.875835361928222e-05\n",
            "Train loss: 0.8000171184539795\n",
            "\n",
            "Time (s): 0.6311759948730469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 417 / 499\n",
            "LR: 8.875817461378626e-05\n",
            "Train loss: 0.6523463726043701\n",
            "\n",
            "Time (s): 0.6297328472137451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 418 / 499\n",
            "LR: 8.875799560937336e-05\n",
            "Train loss: 0.8686507344245911\n",
            "\n",
            "Time (s): 0.628695011138916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 419 / 499\n",
            "LR: 8.875781660604348e-05\n",
            "Train loss: 0.6730086207389832\n",
            "\n",
            "Time (s): 0.6297857761383057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 420 / 499\n",
            "LR: 8.87576376037966e-05\n",
            "Train loss: 0.7321767807006836\n",
            "\n",
            "Time (s): 0.6294515132904053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 421 / 499\n",
            "LR: 8.875745860263272e-05\n",
            "Train loss: 1.320480465888977\n",
            "\n",
            "Time (s): 0.6290628910064697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 422 / 499\n",
            "LR: 8.875727960255185e-05\n",
            "Train loss: 0.30850812792778015\n",
            "\n",
            "Time (s): 0.629542350769043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 423 / 499\n",
            "LR: 8.875710060355396e-05\n",
            "Train loss: 0.45932310819625854\n",
            "\n",
            "Time (s): 0.6296100616455078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 424 / 499\n",
            "LR: 8.875692160563904e-05\n",
            "Train loss: 1.0732834339141846\n",
            "\n",
            "Time (s): 0.6298160552978516\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 425 / 499\n",
            "LR: 8.875674260880708e-05\n",
            "Train loss: 0.4283389151096344\n",
            "\n",
            "Time (s): 0.6301865577697754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 426 / 499\n",
            "LR: 8.875656361305805e-05\n",
            "Train loss: 1.535909652709961\n",
            "\n",
            "Time (s): 0.631890058517456\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 427 / 499\n",
            "LR: 8.875638461839197e-05\n",
            "Train loss: 0.6899017691612244\n",
            "\n",
            "Time (s): 0.6288294792175293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 428 / 499\n",
            "LR: 8.875620562480884e-05\n",
            "Train loss: 0.7843438386917114\n",
            "\n",
            "Time (s): 0.6286005973815918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 429 / 499\n",
            "LR: 8.875602663230858e-05\n",
            "Train loss: 0.7517448663711548\n",
            "\n",
            "Time (s): 0.6298031806945801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 430 / 499\n",
            "LR: 8.875584764089125e-05\n",
            "Train loss: 0.9278608560562134\n",
            "\n",
            "Time (s): 0.6291542053222656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 431 / 499\n",
            "LR: 8.875566865055683e-05\n",
            "Train loss: 0.7979145646095276\n",
            "\n",
            "Time (s): 0.6290364265441895\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 432 / 499\n",
            "LR: 8.875548966130529e-05\n",
            "Train loss: 1.508472204208374\n",
            "\n",
            "Time (s): 0.6302578449249268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 433 / 499\n",
            "LR: 8.87553106731366e-05\n",
            "Train loss: 0.7556967735290527\n",
            "\n",
            "Time (s): 0.6297461986541748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 434 / 499\n",
            "LR: 8.875513168605079e-05\n",
            "Train loss: 0.8427742123603821\n",
            "\n",
            "Time (s): 0.6299045085906982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 435 / 499\n",
            "LR: 8.875495270004781e-05\n",
            "Train loss: 0.7383156418800354\n",
            "\n",
            "Time (s): 0.6297013759613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 436 / 499\n",
            "LR: 8.875477371512768e-05\n",
            "Train loss: 0.8169704079627991\n",
            "\n",
            "Time (s): 0.6288702487945557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 437 / 499\n",
            "LR: 8.875459473129039e-05\n",
            "Train loss: 0.7951690554618835\n",
            "\n",
            "Time (s): 0.6298942565917969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 438 / 499\n",
            "LR: 8.875441574853591e-05\n",
            "Train loss: 1.3602488040924072\n",
            "\n",
            "Time (s): 0.6295232772827148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 439 / 499\n",
            "LR: 8.875423676686424e-05\n",
            "Train loss: 1.4377409219741821\n",
            "\n",
            "Time (s): 0.6289386749267578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 440 / 499\n",
            "LR: 8.875405778627537e-05\n",
            "Train loss: 0.37391895055770874\n",
            "\n",
            "Time (s): 0.6288800239562988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 441 / 499\n",
            "LR: 8.875387880676927e-05\n",
            "Train loss: 0.9029994010925293\n",
            "\n",
            "Time (s): 0.6290252208709717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 442 / 499\n",
            "LR: 8.875369982834594e-05\n",
            "Train loss: 0.9460422992706299\n",
            "\n",
            "Time (s): 0.6305956840515137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 443 / 499\n",
            "LR: 8.875352085100539e-05\n",
            "Train loss: 0.8606592416763306\n",
            "\n",
            "Time (s): 0.6301355361938477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 444 / 499\n",
            "LR: 8.87533418747476e-05\n",
            "Train loss: 1.1810929775238037\n",
            "\n",
            "Time (s): 0.6312611103057861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 445 / 499\n",
            "LR: 8.875316289957253e-05\n",
            "Train loss: 0.6830586791038513\n",
            "\n",
            "Time (s): 0.6260101795196533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 446 / 499\n",
            "LR: 8.875298392548019e-05\n",
            "Train loss: 1.422016978263855\n",
            "\n",
            "Time (s): 0.6287202835083008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 447 / 499\n",
            "LR: 8.875280495247058e-05\n",
            "Train loss: 0.3221243619918823\n",
            "\n",
            "Time (s): 0.6290299892425537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 448 / 499\n",
            "LR: 8.875262598054369e-05\n",
            "Train loss: 0.38727471232414246\n",
            "\n",
            "Time (s): 0.6301071643829346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 449 / 499\n",
            "LR: 8.875244700969947e-05\n",
            "Train loss: 0.9800097942352295\n",
            "\n",
            "Time (s): 0.6254770755767822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 450 / 499\n",
            "LR: 8.875226803993795e-05\n",
            "Train loss: 0.822173535823822\n",
            "\n",
            "Time (s): 0.625133752822876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 451 / 499\n",
            "LR: 8.875208907125911e-05\n",
            "Train loss: 0.8378960490226746\n",
            "\n",
            "Time (s): 0.627532958984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 452 / 499\n",
            "LR: 8.875191010366294e-05\n",
            "Train loss: 0.5823096036911011\n",
            "\n",
            "Time (s): 0.6293790340423584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 453 / 499\n",
            "LR: 8.875173113714942e-05\n",
            "Train loss: 0.6082396507263184\n",
            "\n",
            "Time (s): 0.6240983009338379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 454 / 499\n",
            "LR: 8.875155217171854e-05\n",
            "Train loss: 0.7211450934410095\n",
            "\n",
            "Time (s): 0.6243188381195068\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 455 / 499\n",
            "LR: 8.875137320737029e-05\n",
            "Train loss: 0.8545093536376953\n",
            "\n",
            "Time (s): 0.6242432594299316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 456 / 499\n",
            "LR: 8.875119424410467e-05\n",
            "Train loss: 0.7307201027870178\n",
            "\n",
            "Time (s): 0.6297121047973633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 457 / 499\n",
            "LR: 8.875101528192166e-05\n",
            "Train loss: 1.2179814577102661\n",
            "\n",
            "Time (s): 0.6292235851287842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 458 / 499\n",
            "LR: 8.875083632082123e-05\n",
            "Train loss: 0.6197497844696045\n",
            "\n",
            "Time (s): 0.6250288486480713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 459 / 499\n",
            "LR: 8.875065736080341e-05\n",
            "Train loss: 0.45795610547065735\n",
            "\n",
            "Time (s): 0.6285204887390137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 460 / 499\n",
            "LR: 8.875047840186816e-05\n",
            "Train loss: 0.7019820809364319\n",
            "\n",
            "Time (s): 0.6300215721130371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 461 / 499\n",
            "LR: 8.875029944401547e-05\n",
            "Train loss: 0.6999344229698181\n",
            "\n",
            "Time (s): 0.624964714050293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 462 / 499\n",
            "LR: 8.875012048724536e-05\n",
            "Train loss: 1.2688871622085571\n",
            "\n",
            "Time (s): 0.6246535778045654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 463 / 499\n",
            "LR: 8.874994153155777e-05\n",
            "Train loss: 1.4692813158035278\n",
            "\n",
            "Time (s): 0.6291463375091553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 464 / 499\n",
            "LR: 8.874976257695272e-05\n",
            "Train loss: 0.9530810117721558\n",
            "\n",
            "Time (s): 0.6263668537139893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 465 / 499\n",
            "LR: 8.87495836234302e-05\n",
            "Train loss: 0.5247117280960083\n",
            "\n",
            "Time (s): 0.6291306018829346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 466 / 499\n",
            "LR: 8.874940467099017e-05\n",
            "Train loss: 0.5368093252182007\n",
            "\n",
            "Time (s): 0.6269333362579346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 467 / 499\n",
            "LR: 8.874922571963268e-05\n",
            "Train loss: 1.1787140369415283\n",
            "\n",
            "Time (s): 0.624518871307373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 468 / 499\n",
            "LR: 8.874904676935766e-05\n",
            "Train loss: 0.8544043898582458\n",
            "\n",
            "Time (s): 0.6297674179077148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 469 / 499\n",
            "LR: 8.874886782016512e-05\n",
            "Train loss: 0.914227306842804\n",
            "\n",
            "Time (s): 0.6284527778625488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 470 / 499\n",
            "LR: 8.874868887205503e-05\n",
            "Train loss: 0.5662935972213745\n",
            "\n",
            "Time (s): 0.6304974555969238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 471 / 499\n",
            "LR: 8.874850992502743e-05\n",
            "Train loss: 0.6075741052627563\n",
            "\n",
            "Time (s): 0.6293017864227295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 472 / 499\n",
            "LR: 8.874833097908225e-05\n",
            "Train loss: 0.7021024823188782\n",
            "\n",
            "Time (s): 0.6294028759002686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 473 / 499\n",
            "LR: 8.874815203421952e-05\n",
            "Train loss: 0.5025352239608765\n",
            "\n",
            "Time (s): 0.6330609321594238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 474 / 499\n",
            "LR: 8.874797309043922e-05\n",
            "Train loss: 1.0595543384552002\n",
            "\n",
            "Time (s): 0.6300361156463623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 475 / 499\n",
            "LR: 8.874779414774132e-05\n",
            "Train loss: 0.6824108362197876\n",
            "\n",
            "Time (s): 0.6286036968231201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 476 / 499\n",
            "LR: 8.874761520612584e-05\n",
            "Train loss: 0.9237809181213379\n",
            "\n",
            "Time (s): 0.6293787956237793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 477 / 499\n",
            "LR: 8.874743626559274e-05\n",
            "Train loss: 0.40280619263648987\n",
            "\n",
            "Time (s): 0.6285796165466309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 478 / 499\n",
            "LR: 8.874725732614203e-05\n",
            "Train loss: 0.6047866344451904\n",
            "\n",
            "Time (s): 0.6294081211090088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 479 / 499\n",
            "LR: 8.874707838777367e-05\n",
            "Train loss: 1.248451590538025\n",
            "\n",
            "Time (s): 0.6293108463287354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 480 / 499\n",
            "LR: 8.874689945048769e-05\n",
            "Train loss: 0.4353569447994232\n",
            "\n",
            "Time (s): 0.6295723915100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 481 / 499\n",
            "LR: 8.874672051428404e-05\n",
            "Train loss: 0.5854471921920776\n",
            "\n",
            "Time (s): 0.630363941192627\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 482 / 499\n",
            "LR: 8.874654157916275e-05\n",
            "Train loss: 1.1550719738006592\n",
            "\n",
            "Time (s): 0.6293990612030029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 483 / 499\n",
            "LR: 8.874636264512378e-05\n",
            "Train loss: 0.6017035841941833\n",
            "\n",
            "Time (s): 0.629981279373169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 484 / 499\n",
            "LR: 8.874618371216711e-05\n",
            "Train loss: 0.43164077401161194\n",
            "\n",
            "Time (s): 0.629544734954834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 485 / 499\n",
            "LR: 8.874600478029275e-05\n",
            "Train loss: 0.6520028114318848\n",
            "\n",
            "Time (s): 0.6283917427062988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 486 / 499\n",
            "LR: 8.874582584950069e-05\n",
            "Train loss: 0.39916953444480896\n",
            "\n",
            "Time (s): 0.6293621063232422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 487 / 499\n",
            "LR: 8.874564691979092e-05\n",
            "Train loss: 0.8049424290657043\n",
            "\n",
            "Time (s): 0.6306943893432617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 488 / 499\n",
            "LR: 8.87454679911634e-05\n",
            "Train loss: 1.3635988235473633\n",
            "\n",
            "Time (s): 0.6292672157287598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 489 / 499\n",
            "LR: 8.874528906361818e-05\n",
            "Train loss: 0.6421666145324707\n",
            "\n",
            "Time (s): 0.6303479671478271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 490 / 499\n",
            "LR: 8.874511013715518e-05\n",
            "Train loss: 0.5027440190315247\n",
            "\n",
            "Time (s): 0.6298258304595947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 491 / 499\n",
            "LR: 8.874493121177443e-05\n",
            "Train loss: 1.2663944959640503\n",
            "\n",
            "Time (s): 0.6298859119415283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 492 / 499\n",
            "LR: 8.87447522874759e-05\n",
            "Train loss: 0.6801241636276245\n",
            "\n",
            "Time (s): 0.6294870376586914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 493 / 499\n",
            "LR: 8.87445733642596e-05\n",
            "Train loss: 1.0072094202041626\n",
            "\n",
            "Time (s): 0.6299798488616943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 494 / 499\n",
            "LR: 8.874439444212549e-05\n",
            "Train loss: 0.6244521737098694\n",
            "\n",
            "Time (s): 0.6290731430053711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 495 / 499\n",
            "LR: 8.874421552107359e-05\n",
            "Train loss: 0.3383464217185974\n",
            "\n",
            "Time (s): 0.630124568939209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 496 / 499\n",
            "LR: 8.874403660110386e-05\n",
            "Train loss: 0.6649106740951538\n",
            "\n",
            "Time (s): 0.6296353340148926\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 497 / 499\n",
            "LR: 8.874385768221633e-05\n",
            "Train loss: 0.44248053431510925\n",
            "\n",
            "Time (s): 0.6297750473022461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 498 / 499\n",
            "LR: 8.874367876441093e-05\n",
            "Train loss: 0.4852246344089508\n",
            "\n",
            "Time (s): 0.629676103591919\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 497  Batch 499 / 499\n",
            "LR: 8.87434998476877e-05\n",
            "Train loss: 0.7062000036239624\n",
            "\n",
            "Time (s): 0.05088973045349121\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 497\n",
            "Avg train loss: 0.7014849978183697\n",
            "Avg train acc: 0.7920212106618709\n",
            "Avg eval loss: 0.8995397757081425\n",
            "Avg eval acc: 0.7534119276439443\n",
            "=========================\n",
            "\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 1 / 499\n",
            "LR: 8.87433209320466e-05\n",
            "Train loss: 0.76560378074646\n",
            "\n",
            "Time (s): 0.6338350772857666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 2 / 499\n",
            "LR: 8.874314201748765e-05\n",
            "Train loss: 1.190581202507019\n",
            "\n",
            "Time (s): 0.6328043937683105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 3 / 499\n",
            "LR: 8.874296310401083e-05\n",
            "Train loss: 0.48925191164016724\n",
            "\n",
            "Time (s): 0.6325798034667969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 4 / 499\n",
            "LR: 8.874278419161609e-05\n",
            "Train loss: 0.9901420474052429\n",
            "\n",
            "Time (s): 0.639054536819458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 5 / 499\n",
            "LR: 8.874260528030347e-05\n",
            "Train loss: 0.9219197034835815\n",
            "\n",
            "Time (s): 0.6292245388031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 6 / 499\n",
            "LR: 8.87424263700729e-05\n",
            "Train loss: 1.2215306758880615\n",
            "\n",
            "Time (s): 0.6301717758178711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 7 / 499\n",
            "LR: 8.874224746092443e-05\n",
            "Train loss: 1.2091922760009766\n",
            "\n",
            "Time (s): 0.6291730403900146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 8 / 499\n",
            "LR: 8.874206855285802e-05\n",
            "Train loss: 0.869335412979126\n",
            "\n",
            "Time (s): 0.6297600269317627\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 9 / 499\n",
            "LR: 8.874188964587368e-05\n",
            "Train loss: 0.5690827965736389\n",
            "\n",
            "Time (s): 0.6292445659637451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 10 / 499\n",
            "LR: 8.874171073997136e-05\n",
            "Train loss: 0.7724481821060181\n",
            "\n",
            "Time (s): 0.6243224143981934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 11 / 499\n",
            "LR: 8.87415318351511e-05\n",
            "Train loss: 0.5511081218719482\n",
            "\n",
            "Time (s): 0.6285641193389893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 12 / 499\n",
            "LR: 8.874135293141282e-05\n",
            "Train loss: 0.7451818585395813\n",
            "\n",
            "Time (s): 0.6271719932556152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 13 / 499\n",
            "LR: 8.874117402875658e-05\n",
            "Train loss: 0.9636012315750122\n",
            "\n",
            "Time (s): 0.6280450820922852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 14 / 499\n",
            "LR: 8.874099512718235e-05\n",
            "Train loss: 0.4756353199481964\n",
            "\n",
            "Time (s): 0.6285555362701416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 15 / 499\n",
            "LR: 8.874081622669007e-05\n",
            "Train loss: 0.6509513854980469\n",
            "\n",
            "Time (s): 0.6306302547454834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 16 / 499\n",
            "LR: 8.87406373272798e-05\n",
            "Train loss: 0.49105843901634216\n",
            "\n",
            "Time (s): 0.6291375160217285\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 17 / 499\n",
            "LR: 8.874045842895149e-05\n",
            "Train loss: 0.3577692210674286\n",
            "\n",
            "Time (s): 0.6241531372070312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 18 / 499\n",
            "LR: 8.874027953170515e-05\n",
            "Train loss: 0.4552810788154602\n",
            "\n",
            "Time (s): 0.6283440589904785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 19 / 499\n",
            "LR: 8.874010063554071e-05\n",
            "Train loss: 1.1470539569854736\n",
            "\n",
            "Time (s): 0.6259269714355469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 20 / 499\n",
            "LR: 8.873992174045824e-05\n",
            "Train loss: 1.0162227153778076\n",
            "\n",
            "Time (s): 0.6262459754943848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 21 / 499\n",
            "LR: 8.873974284645769e-05\n",
            "Train loss: 0.5499892830848694\n",
            "\n",
            "Time (s): 0.627877950668335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 22 / 499\n",
            "LR: 8.873956395353904e-05\n",
            "Train loss: 0.6504087448120117\n",
            "\n",
            "Time (s): 0.6300451755523682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 23 / 499\n",
            "LR: 8.873938506170231e-05\n",
            "Train loss: 0.7340779304504395\n",
            "\n",
            "Time (s): 0.6248271465301514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 24 / 499\n",
            "LR: 8.873920617094745e-05\n",
            "Train loss: 0.7412643432617188\n",
            "\n",
            "Time (s): 0.6269960403442383\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 25 / 499\n",
            "LR: 8.873902728127448e-05\n",
            "Train loss: 1.135667085647583\n",
            "\n",
            "Time (s): 0.6238384246826172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 26 / 499\n",
            "LR: 8.873884839268337e-05\n",
            "Train loss: 0.5366529226303101\n",
            "\n",
            "Time (s): 0.6352877616882324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 27 / 499\n",
            "LR: 8.873866950517414e-05\n",
            "Train loss: 0.6749865412712097\n",
            "\n",
            "Time (s): 0.6245875358581543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 28 / 499\n",
            "LR: 8.873849061874672e-05\n",
            "Train loss: 0.6494708061218262\n",
            "\n",
            "Time (s): 0.6309561729431152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 29 / 499\n",
            "LR: 8.873831173340117e-05\n",
            "Train loss: 0.8368061780929565\n",
            "\n",
            "Time (s): 0.6291906833648682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 30 / 499\n",
            "LR: 8.873813284913742e-05\n",
            "Train loss: 0.9923450946807861\n",
            "\n",
            "Time (s): 0.6245851516723633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 31 / 499\n",
            "LR: 8.87379539659555e-05\n",
            "Train loss: 0.89939945936203\n",
            "\n",
            "Time (s): 0.6240954399108887\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 32 / 499\n",
            "LR: 8.873777508385539e-05\n",
            "Train loss: 0.6726993918418884\n",
            "\n",
            "Time (s): 0.624272346496582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 33 / 499\n",
            "LR: 8.873759620283706e-05\n",
            "Train loss: 1.376363754272461\n",
            "\n",
            "Time (s): 0.6251022815704346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 34 / 499\n",
            "LR: 8.873741732290051e-05\n",
            "Train loss: 0.7690023183822632\n",
            "\n",
            "Time (s): 0.6283917427062988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 35 / 499\n",
            "LR: 8.873723844404573e-05\n",
            "Train loss: 1.0333267450332642\n",
            "\n",
            "Time (s): 0.6278064250946045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 36 / 499\n",
            "LR: 8.873705956627272e-05\n",
            "Train loss: 1.5559006929397583\n",
            "\n",
            "Time (s): 0.6282341480255127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 37 / 499\n",
            "LR: 8.873688068958145e-05\n",
            "Train loss: 0.45684611797332764\n",
            "\n",
            "Time (s): 0.629143476486206\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 38 / 499\n",
            "LR: 8.873670181397191e-05\n",
            "Train loss: 1.0032918453216553\n",
            "\n",
            "Time (s): 0.6266727447509766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 39 / 499\n",
            "LR: 8.87365229394441e-05\n",
            "Train loss: 0.3861997723579407\n",
            "\n",
            "Time (s): 0.6278340816497803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 40 / 499\n",
            "LR: 8.873634406599802e-05\n",
            "Train loss: 1.077917456626892\n",
            "\n",
            "Time (s): 0.6285309791564941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 41 / 499\n",
            "LR: 8.873616519363365e-05\n",
            "Train loss: 0.5903981328010559\n",
            "\n",
            "Time (s): 0.6268095970153809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 42 / 499\n",
            "LR: 8.873598632235094e-05\n",
            "Train loss: 0.6529557108879089\n",
            "\n",
            "Time (s): 0.6241927146911621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 43 / 499\n",
            "LR: 8.873580745214994e-05\n",
            "Train loss: 0.9671599864959717\n",
            "\n",
            "Time (s): 0.6295502185821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 44 / 499\n",
            "LR: 8.873562858303062e-05\n",
            "Train loss: 0.9621112942695618\n",
            "\n",
            "Time (s): 0.6292343139648438\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 45 / 499\n",
            "LR: 8.873544971499294e-05\n",
            "Train loss: 0.3901155889034271\n",
            "\n",
            "Time (s): 0.6287157535552979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 46 / 499\n",
            "LR: 8.873527084803691e-05\n",
            "Train loss: 0.7833369374275208\n",
            "\n",
            "Time (s): 0.6296684741973877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 47 / 499\n",
            "LR: 8.873509198216252e-05\n",
            "Train loss: 0.6936846375465393\n",
            "\n",
            "Time (s): 0.6281297206878662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 48 / 499\n",
            "LR: 8.873491311736978e-05\n",
            "Train loss: 1.5394319295883179\n",
            "\n",
            "Time (s): 0.6275038719177246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 49 / 499\n",
            "LR: 8.873473425365866e-05\n",
            "Train loss: 0.33752962946891785\n",
            "\n",
            "Time (s): 0.6239438056945801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 50 / 499\n",
            "LR: 8.873455539102911e-05\n",
            "Train loss: 0.6034700870513916\n",
            "\n",
            "Time (s): 0.6245825290679932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 51 / 499\n",
            "LR: 8.873437652948117e-05\n",
            "Train loss: 0.7601091265678406\n",
            "\n",
            "Time (s): 0.6247425079345703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 52 / 499\n",
            "LR: 8.873419766901484e-05\n",
            "Train loss: 0.8606743216514587\n",
            "\n",
            "Time (s): 0.6278724670410156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 53 / 499\n",
            "LR: 8.873401880963005e-05\n",
            "Train loss: 0.751175045967102\n",
            "\n",
            "Time (s): 0.6282258033752441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 54 / 499\n",
            "LR: 8.873383995132685e-05\n",
            "Train loss: 1.4304066896438599\n",
            "\n",
            "Time (s): 0.6279857158660889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 55 / 499\n",
            "LR: 8.87336610941052e-05\n",
            "Train loss: 0.9996559023857117\n",
            "\n",
            "Time (s): 0.6286187171936035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 56 / 499\n",
            "LR: 8.873348223796507e-05\n",
            "Train loss: 0.6538953185081482\n",
            "\n",
            "Time (s): 0.6284358501434326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 57 / 499\n",
            "LR: 8.873330338290649e-05\n",
            "Train loss: 0.5657920241355896\n",
            "\n",
            "Time (s): 0.6284985542297363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 58 / 499\n",
            "LR: 8.873312452892942e-05\n",
            "Train loss: 0.6999251842498779\n",
            "\n",
            "Time (s): 0.6261413097381592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 59 / 499\n",
            "LR: 8.873294567603386e-05\n",
            "Train loss: 0.8068445324897766\n",
            "\n",
            "Time (s): 0.628826379776001\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 60 / 499\n",
            "LR: 8.873276682421981e-05\n",
            "Train loss: 0.3306692838668823\n",
            "\n",
            "Time (s): 0.6298685073852539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 61 / 499\n",
            "LR: 8.873258797348724e-05\n",
            "Train loss: 0.37014999985694885\n",
            "\n",
            "Time (s): 0.6242444515228271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 62 / 499\n",
            "LR: 8.873240912383613e-05\n",
            "Train loss: 0.7683951258659363\n",
            "\n",
            "Time (s): 0.6243135929107666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 63 / 499\n",
            "LR: 8.873223027526651e-05\n",
            "Train loss: 0.4400937259197235\n",
            "\n",
            "Time (s): 0.6242616176605225\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 64 / 499\n",
            "LR: 8.873205142777833e-05\n",
            "Train loss: 0.6474687457084656\n",
            "\n",
            "Time (s): 0.6289610862731934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 65 / 499\n",
            "LR: 8.87318725813716e-05\n",
            "Train loss: 0.6053667068481445\n",
            "\n",
            "Time (s): 0.6288964748382568\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 66 / 499\n",
            "LR: 8.87316937360463e-05\n",
            "Train loss: 1.492324709892273\n",
            "\n",
            "Time (s): 0.6288261413574219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 67 / 499\n",
            "LR: 8.87315148918024e-05\n",
            "Train loss: 1.3462740182876587\n",
            "\n",
            "Time (s): 0.625934362411499\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 68 / 499\n",
            "LR: 8.873133604863994e-05\n",
            "Train loss: 0.8462073802947998\n",
            "\n",
            "Time (s): 0.628364086151123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 69 / 499\n",
            "LR: 8.873115720655889e-05\n",
            "Train loss: 1.2621852159500122\n",
            "\n",
            "Time (s): 0.631239652633667\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 70 / 499\n",
            "LR: 8.87309783655592e-05\n",
            "Train loss: 0.516233503818512\n",
            "\n",
            "Time (s): 0.6285037994384766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 71 / 499\n",
            "LR: 8.873079952564088e-05\n",
            "Train loss: 0.6391578912734985\n",
            "\n",
            "Time (s): 0.6289823055267334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 72 / 499\n",
            "LR: 8.873062068680395e-05\n",
            "Train loss: 1.4113553762435913\n",
            "\n",
            "Time (s): 0.6293394565582275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 73 / 499\n",
            "LR: 8.873044184904838e-05\n",
            "Train loss: 1.3236078023910522\n",
            "\n",
            "Time (s): 0.628493070602417\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 74 / 499\n",
            "LR: 8.873026301237414e-05\n",
            "Train loss: 0.7782784700393677\n",
            "\n",
            "Time (s): 0.6283707618713379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 75 / 499\n",
            "LR: 8.873008417678125e-05\n",
            "Train loss: 0.5152366757392883\n",
            "\n",
            "Time (s): 0.6290967464447021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 76 / 499\n",
            "LR: 8.872990534226967e-05\n",
            "Train loss: 0.831420361995697\n",
            "\n",
            "Time (s): 0.6278011798858643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 77 / 499\n",
            "LR: 8.872972650883941e-05\n",
            "Train loss: 1.0305062532424927\n",
            "\n",
            "Time (s): 0.6286501884460449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 78 / 499\n",
            "LR: 8.872954767649046e-05\n",
            "Train loss: 1.2126468420028687\n",
            "\n",
            "Time (s): 0.6298425197601318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 79 / 499\n",
            "LR: 8.872936884522278e-05\n",
            "Train loss: 0.8479917645454407\n",
            "\n",
            "Time (s): 0.6287181377410889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 80 / 499\n",
            "LR: 8.872919001503639e-05\n",
            "Train loss: 0.4544064998626709\n",
            "\n",
            "Time (s): 0.6288666725158691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 81 / 499\n",
            "LR: 8.872901118593127e-05\n",
            "Train loss: 0.7131133675575256\n",
            "\n",
            "Time (s): 0.6298573017120361\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 82 / 499\n",
            "LR: 8.872883235790742e-05\n",
            "Train loss: 0.45358777046203613\n",
            "\n",
            "Time (s): 0.6291921138763428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 83 / 499\n",
            "LR: 8.87286535309648e-05\n",
            "Train loss: 1.169809341430664\n",
            "\n",
            "Time (s): 0.6298010349273682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 84 / 499\n",
            "LR: 8.872847470510343e-05\n",
            "Train loss: 0.9964452981948853\n",
            "\n",
            "Time (s): 0.629035472869873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 85 / 499\n",
            "LR: 8.872829588032326e-05\n",
            "Train loss: 0.5771650075912476\n",
            "\n",
            "Time (s): 0.6282918453216553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 86 / 499\n",
            "LR: 8.872811705662432e-05\n",
            "Train loss: 0.47304481267929077\n",
            "\n",
            "Time (s): 0.627673864364624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 87 / 499\n",
            "LR: 8.872793823400658e-05\n",
            "Train loss: 1.2093273401260376\n",
            "\n",
            "Time (s): 0.6297192573547363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 88 / 499\n",
            "LR: 8.872775941247005e-05\n",
            "Train loss: 0.8584654331207275\n",
            "\n",
            "Time (s): 0.6299216747283936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 89 / 499\n",
            "LR: 8.872758059201468e-05\n",
            "Train loss: 1.0339380502700806\n",
            "\n",
            "Time (s): 0.629770040512085\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 90 / 499\n",
            "LR: 8.87274017726405e-05\n",
            "Train loss: 0.7286463975906372\n",
            "\n",
            "Time (s): 0.6298134326934814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 91 / 499\n",
            "LR: 8.872722295434745e-05\n",
            "Train loss: 0.46826595067977905\n",
            "\n",
            "Time (s): 0.6281185150146484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 92 / 499\n",
            "LR: 8.872704413713559e-05\n",
            "Train loss: 0.22588658332824707\n",
            "\n",
            "Time (s): 0.6288440227508545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 93 / 499\n",
            "LR: 8.872686532100484e-05\n",
            "Train loss: 0.5430734753608704\n",
            "\n",
            "Time (s): 0.6287438869476318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 94 / 499\n",
            "LR: 8.872668650595522e-05\n",
            "Train loss: 0.4490410387516022\n",
            "\n",
            "Time (s): 0.629361629486084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 95 / 499\n",
            "LR: 8.872650769198672e-05\n",
            "Train loss: 0.8321075439453125\n",
            "\n",
            "Time (s): 0.6289935111999512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 96 / 499\n",
            "LR: 8.872632887909933e-05\n",
            "Train loss: 1.1171454191207886\n",
            "\n",
            "Time (s): 0.6300146579742432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 97 / 499\n",
            "LR: 8.872615006729304e-05\n",
            "Train loss: 0.782045304775238\n",
            "\n",
            "Time (s): 0.6296393871307373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 98 / 499\n",
            "LR: 8.872597125656782e-05\n",
            "Train loss: 0.5001726150512695\n",
            "\n",
            "Time (s): 0.6297597885131836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 99 / 499\n",
            "LR: 8.872579244692369e-05\n",
            "Train loss: 0.5407207012176514\n",
            "\n",
            "Time (s): 0.6283423900604248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 100 / 499\n",
            "LR: 8.87256136383606e-05\n",
            "Train loss: 0.8581368923187256\n",
            "\n",
            "Time (s): 0.629342794418335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 101 / 499\n",
            "LR: 8.872543483087858e-05\n",
            "Train loss: 0.853134274482727\n",
            "\n",
            "Time (s): 0.6289424896240234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 102 / 499\n",
            "LR: 8.872525602447757e-05\n",
            "Train loss: 0.6265034675598145\n",
            "\n",
            "Time (s): 0.6292059421539307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 103 / 499\n",
            "LR: 8.872507721915761e-05\n",
            "Train loss: 1.0146514177322388\n",
            "\n",
            "Time (s): 0.629324197769165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 104 / 499\n",
            "LR: 8.872489841491869e-05\n",
            "Train loss: 0.6018010973930359\n",
            "\n",
            "Time (s): 0.6294147968292236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 105 / 499\n",
            "LR: 8.872471961176075e-05\n",
            "Train loss: 0.4302665889263153\n",
            "\n",
            "Time (s): 0.6298277378082275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 106 / 499\n",
            "LR: 8.872454080968382e-05\n",
            "Train loss: 0.6823225617408752\n",
            "\n",
            "Time (s): 0.630070686340332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 107 / 499\n",
            "LR: 8.872436200868786e-05\n",
            "Train loss: 0.46476423740386963\n",
            "\n",
            "Time (s): 0.6295416355133057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 108 / 499\n",
            "LR: 8.87241832087729e-05\n",
            "Train loss: 0.9578138589859009\n",
            "\n",
            "Time (s): 0.629549503326416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 109 / 499\n",
            "LR: 8.872400440993889e-05\n",
            "Train loss: 1.2516928911209106\n",
            "\n",
            "Time (s): 0.6295888423919678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 110 / 499\n",
            "LR: 8.872382561218582e-05\n",
            "Train loss: 0.9174813032150269\n",
            "\n",
            "Time (s): 0.6296591758728027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 111 / 499\n",
            "LR: 8.872364681551369e-05\n",
            "Train loss: 1.265549659729004\n",
            "\n",
            "Time (s): 0.6294353008270264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 112 / 499\n",
            "LR: 8.872346801992252e-05\n",
            "Train loss: 1.0220786333084106\n",
            "\n",
            "Time (s): 0.6290380954742432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 113 / 499\n",
            "LR: 8.872328922541225e-05\n",
            "Train loss: 0.6852912902832031\n",
            "\n",
            "Time (s): 0.628230094909668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 114 / 499\n",
            "LR: 8.872311043198289e-05\n",
            "Train loss: 1.052083969116211\n",
            "\n",
            "Time (s): 0.6286370754241943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 115 / 499\n",
            "LR: 8.872293163963444e-05\n",
            "Train loss: 0.28227096796035767\n",
            "\n",
            "Time (s): 0.6293644905090332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 116 / 499\n",
            "LR: 8.87227528483669e-05\n",
            "Train loss: 1.024138331413269\n",
            "\n",
            "Time (s): 0.6296589374542236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 117 / 499\n",
            "LR: 8.872257405818019e-05\n",
            "Train loss: 1.128607988357544\n",
            "\n",
            "Time (s): 0.6305294036865234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 118 / 499\n",
            "LR: 8.872239526907437e-05\n",
            "Train loss: 0.7371554374694824\n",
            "\n",
            "Time (s): 0.6282572746276855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 119 / 499\n",
            "LR: 8.872221648104938e-05\n",
            "Train loss: 0.35791078209877014\n",
            "\n",
            "Time (s): 0.6294937133789062\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 120 / 499\n",
            "LR: 8.872203769410528e-05\n",
            "Train loss: 0.3575983941555023\n",
            "\n",
            "Time (s): 0.627495288848877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 121 / 499\n",
            "LR: 8.872185890824198e-05\n",
            "Train loss: 1.1867709159851074\n",
            "\n",
            "Time (s): 0.6276695728302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 122 / 499\n",
            "LR: 8.872168012345951e-05\n",
            "Train loss: 0.93968665599823\n",
            "\n",
            "Time (s): 0.6288342475891113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 123 / 499\n",
            "LR: 8.872150133975784e-05\n",
            "Train loss: 0.9157513976097107\n",
            "\n",
            "Time (s): 0.6291534900665283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 124 / 499\n",
            "LR: 8.872132255713699e-05\n",
            "Train loss: 0.7399945855140686\n",
            "\n",
            "Time (s): 0.6294522285461426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 125 / 499\n",
            "LR: 8.872114377559692e-05\n",
            "Train loss: 0.47453972697257996\n",
            "\n",
            "Time (s): 0.628831148147583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 126 / 499\n",
            "LR: 8.872096499513764e-05\n",
            "Train loss: 1.0652049779891968\n",
            "\n",
            "Time (s): 0.6293067932128906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 127 / 499\n",
            "LR: 8.872078621575911e-05\n",
            "Train loss: 0.7248274087905884\n",
            "\n",
            "Time (s): 0.6284494400024414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 128 / 499\n",
            "LR: 8.872060743746135e-05\n",
            "Train loss: 1.128894567489624\n",
            "\n",
            "Time (s): 0.6293630599975586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 129 / 499\n",
            "LR: 8.872042866024432e-05\n",
            "Train loss: 0.7272380590438843\n",
            "\n",
            "Time (s): 0.6294450759887695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 130 / 499\n",
            "LR: 8.872024988410805e-05\n",
            "Train loss: 0.8277498483657837\n",
            "\n",
            "Time (s): 0.6294989585876465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 131 / 499\n",
            "LR: 8.872007110905249e-05\n",
            "Train loss: 0.6581418514251709\n",
            "\n",
            "Time (s): 0.628546953201294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 132 / 499\n",
            "LR: 8.871989233507763e-05\n",
            "Train loss: 0.9791693687438965\n",
            "\n",
            "Time (s): 0.6280691623687744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 133 / 499\n",
            "LR: 8.871971356218349e-05\n",
            "Train loss: 0.45230743288993835\n",
            "\n",
            "Time (s): 0.6288220882415771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 134 / 499\n",
            "LR: 8.871953479037006e-05\n",
            "Train loss: 0.7632538676261902\n",
            "\n",
            "Time (s): 0.6298308372497559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 135 / 499\n",
            "LR: 8.871935601963729e-05\n",
            "Train loss: 0.740822970867157\n",
            "\n",
            "Time (s): 0.6292028427124023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 136 / 499\n",
            "LR: 8.871917724998519e-05\n",
            "Train loss: 0.9886658191680908\n",
            "\n",
            "Time (s): 0.6293559074401855\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 137 / 499\n",
            "LR: 8.871899848141375e-05\n",
            "Train loss: 0.908557653427124\n",
            "\n",
            "Time (s): 0.6296329498291016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 138 / 499\n",
            "LR: 8.871881971392295e-05\n",
            "Train loss: 0.9110440015792847\n",
            "\n",
            "Time (s): 0.6295068264007568\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 139 / 499\n",
            "LR: 8.871864094751278e-05\n",
            "Train loss: 0.4801506996154785\n",
            "\n",
            "Time (s): 0.6286735534667969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 140 / 499\n",
            "LR: 8.871846218218326e-05\n",
            "Train loss: 0.9695437550544739\n",
            "\n",
            "Time (s): 0.6281721591949463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 141 / 499\n",
            "LR: 8.871828341793436e-05\n",
            "Train loss: 1.3151533603668213\n",
            "\n",
            "Time (s): 0.6290700435638428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 142 / 499\n",
            "LR: 8.871810465476604e-05\n",
            "Train loss: 0.8871200084686279\n",
            "\n",
            "Time (s): 0.629239559173584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 143 / 499\n",
            "LR: 8.871792589267833e-05\n",
            "Train loss: 0.9042616486549377\n",
            "\n",
            "Time (s): 0.6278979778289795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 144 / 499\n",
            "LR: 8.87177471316712e-05\n",
            "Train loss: 0.3467386066913605\n",
            "\n",
            "Time (s): 0.6238865852355957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 145 / 499\n",
            "LR: 8.871756837174465e-05\n",
            "Train loss: 0.581562876701355\n",
            "\n",
            "Time (s): 0.6279311180114746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 146 / 499\n",
            "LR: 8.871738961289864e-05\n",
            "Train loss: 0.8947885036468506\n",
            "\n",
            "Time (s): 0.6292884349822998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 147 / 499\n",
            "LR: 8.87172108551332e-05\n",
            "Train loss: 0.7871180772781372\n",
            "\n",
            "Time (s): 0.6287624835968018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 148 / 499\n",
            "LR: 8.871703209844829e-05\n",
            "Train loss: 0.6645261645317078\n",
            "\n",
            "Time (s): 0.6292018890380859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 149 / 499\n",
            "LR: 8.87168533428439e-05\n",
            "Train loss: 0.9548397064208984\n",
            "\n",
            "Time (s): 0.628420352935791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 150 / 499\n",
            "LR: 8.871667458832004e-05\n",
            "Train loss: 0.9342629909515381\n",
            "\n",
            "Time (s): 0.6285953521728516\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 151 / 499\n",
            "LR: 8.871649583487669e-05\n",
            "Train loss: 0.618281900882721\n",
            "\n",
            "Time (s): 0.6285572052001953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 152 / 499\n",
            "LR: 8.871631708251383e-05\n",
            "Train loss: 0.6378006935119629\n",
            "\n",
            "Time (s): 0.624591588973999\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 153 / 499\n",
            "LR: 8.871613833123145e-05\n",
            "Train loss: 0.5297693014144897\n",
            "\n",
            "Time (s): 0.6296653747558594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 154 / 499\n",
            "LR: 8.871595958102955e-05\n",
            "Train loss: 0.8688218593597412\n",
            "\n",
            "Time (s): 0.6281182765960693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 155 / 499\n",
            "LR: 8.871578083190812e-05\n",
            "Train loss: 0.5045050382614136\n",
            "\n",
            "Time (s): 0.6283786296844482\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 156 / 499\n",
            "LR: 8.871560208386713e-05\n",
            "Train loss: 0.9582169055938721\n",
            "\n",
            "Time (s): 0.6244006156921387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 157 / 499\n",
            "LR: 8.871542333690658e-05\n",
            "Train loss: 0.985561728477478\n",
            "\n",
            "Time (s): 0.6282575130462646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 158 / 499\n",
            "LR: 8.871524459102646e-05\n",
            "Train loss: 1.0659130811691284\n",
            "\n",
            "Time (s): 0.6288950443267822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 159 / 499\n",
            "LR: 8.871506584622678e-05\n",
            "Train loss: 0.4912164807319641\n",
            "\n",
            "Time (s): 0.6243512630462646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 160 / 499\n",
            "LR: 8.87148871025075e-05\n",
            "Train loss: 1.0108314752578735\n",
            "\n",
            "Time (s): 0.6281301975250244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 161 / 499\n",
            "LR: 8.87147083598686e-05\n",
            "Train loss: 0.4080548882484436\n",
            "\n",
            "Time (s): 0.6289887428283691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 162 / 499\n",
            "LR: 8.871452961831011e-05\n",
            "Train loss: 0.6743196249008179\n",
            "\n",
            "Time (s): 0.6333699226379395\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 163 / 499\n",
            "LR: 8.871435087783198e-05\n",
            "Train loss: 1.4619897603988647\n",
            "\n",
            "Time (s): 0.630699634552002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 164 / 499\n",
            "LR: 8.871417213843422e-05\n",
            "Train loss: 0.7945955395698547\n",
            "\n",
            "Time (s): 0.6242053508758545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 165 / 499\n",
            "LR: 8.871399340011681e-05\n",
            "Train loss: 1.1404446363449097\n",
            "\n",
            "Time (s): 0.6282804012298584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 166 / 499\n",
            "LR: 8.871381466287975e-05\n",
            "Train loss: 0.6259901523590088\n",
            "\n",
            "Time (s): 0.6291215419769287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 167 / 499\n",
            "LR: 8.871363592672301e-05\n",
            "Train loss: 1.3898296356201172\n",
            "\n",
            "Time (s): 0.6286532878875732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 168 / 499\n",
            "LR: 8.87134571916466e-05\n",
            "Train loss: 1.3914926052093506\n",
            "\n",
            "Time (s): 0.6245806217193604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 169 / 499\n",
            "LR: 8.871327845765051e-05\n",
            "Train loss: 0.5156922936439514\n",
            "\n",
            "Time (s): 0.628288745880127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 170 / 499\n",
            "LR: 8.871309972473471e-05\n",
            "Train loss: 0.9656256437301636\n",
            "\n",
            "Time (s): 0.626471996307373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 171 / 499\n",
            "LR: 8.87129209928992e-05\n",
            "Train loss: 1.2899316549301147\n",
            "\n",
            "Time (s): 0.6247706413269043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 172 / 499\n",
            "LR: 8.871274226214399e-05\n",
            "Train loss: 0.72562175989151\n",
            "\n",
            "Time (s): 0.627856969833374\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 173 / 499\n",
            "LR: 8.871256353246901e-05\n",
            "Train loss: 1.1026525497436523\n",
            "\n",
            "Time (s): 0.6242389678955078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 174 / 499\n",
            "LR: 8.87123848038743e-05\n",
            "Train loss: 1.0741872787475586\n",
            "\n",
            "Time (s): 0.6279864311218262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 175 / 499\n",
            "LR: 8.871220607635986e-05\n",
            "Train loss: 1.0681195259094238\n",
            "\n",
            "Time (s): 0.62978196144104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 176 / 499\n",
            "LR: 8.871202734992563e-05\n",
            "Train loss: 0.4065617322921753\n",
            "\n",
            "Time (s): 0.6282749176025391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 177 / 499\n",
            "LR: 8.871184862457161e-05\n",
            "Train loss: 0.29116129875183105\n",
            "\n",
            "Time (s): 0.6240036487579346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 178 / 499\n",
            "LR: 8.871166990029783e-05\n",
            "Train loss: 1.1178711652755737\n",
            "\n",
            "Time (s): 0.6280422210693359\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 179 / 499\n",
            "LR: 8.871149117710424e-05\n",
            "Train loss: 0.7153231501579285\n",
            "\n",
            "Time (s): 0.6269073486328125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 180 / 499\n",
            "LR: 8.871131245499085e-05\n",
            "Train loss: 1.216613531112671\n",
            "\n",
            "Time (s): 0.6280519962310791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 181 / 499\n",
            "LR: 8.871113373395764e-05\n",
            "Train loss: 0.3804383873939514\n",
            "\n",
            "Time (s): 0.6292445659637451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 182 / 499\n",
            "LR: 8.871095501400459e-05\n",
            "Train loss: 0.3380948603153229\n",
            "\n",
            "Time (s): 0.6292359828948975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 183 / 499\n",
            "LR: 8.87107762951317e-05\n",
            "Train loss: 0.9001546502113342\n",
            "\n",
            "Time (s): 0.6293833255767822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 184 / 499\n",
            "LR: 8.871059757733895e-05\n",
            "Train loss: 0.5102349519729614\n",
            "\n",
            "Time (s): 0.6292159557342529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 185 / 499\n",
            "LR: 8.871041886062634e-05\n",
            "Train loss: 0.8246066570281982\n",
            "\n",
            "Time (s): 0.6285438537597656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 186 / 499\n",
            "LR: 8.871024014499385e-05\n",
            "Train loss: 1.059817910194397\n",
            "\n",
            "Time (s): 0.627962589263916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 187 / 499\n",
            "LR: 8.87100614304415e-05\n",
            "Train loss: 1.301281213760376\n",
            "\n",
            "Time (s): 0.6277041435241699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 188 / 499\n",
            "LR: 8.870988271696924e-05\n",
            "Train loss: 0.4339979290962219\n",
            "\n",
            "Time (s): 0.6280651092529297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 189 / 499\n",
            "LR: 8.870970400457708e-05\n",
            "Train loss: 1.1015913486480713\n",
            "\n",
            "Time (s): 0.629443883895874\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 190 / 499\n",
            "LR: 8.8709525293265e-05\n",
            "Train loss: 0.7603497505187988\n",
            "\n",
            "Time (s): 0.6292529106140137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 191 / 499\n",
            "LR: 8.870934658303299e-05\n",
            "Train loss: 0.4461275339126587\n",
            "\n",
            "Time (s): 0.6239404678344727\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 192 / 499\n",
            "LR: 8.870916787388104e-05\n",
            "Train loss: 0.277976393699646\n",
            "\n",
            "Time (s): 0.6290512084960938\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 193 / 499\n",
            "LR: 8.870898916580912e-05\n",
            "Train loss: 0.9517822265625\n",
            "\n",
            "Time (s): 0.6290433406829834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 194 / 499\n",
            "LR: 8.870881045881725e-05\n",
            "Train loss: 1.172550916671753\n",
            "\n",
            "Time (s): 0.6294796466827393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 195 / 499\n",
            "LR: 8.870863175290542e-05\n",
            "Train loss: 1.0099561214447021\n",
            "\n",
            "Time (s): 0.6289272308349609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 196 / 499\n",
            "LR: 8.87084530480736e-05\n",
            "Train loss: 1.0595349073410034\n",
            "\n",
            "Time (s): 0.6240437030792236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 197 / 499\n",
            "LR: 8.87082743443218e-05\n",
            "Train loss: 1.0058979988098145\n",
            "\n",
            "Time (s): 0.628974437713623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 198 / 499\n",
            "LR: 8.870809564164997e-05\n",
            "Train loss: 0.27188077569007874\n",
            "\n",
            "Time (s): 0.6283285617828369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 199 / 499\n",
            "LR: 8.870791694005813e-05\n",
            "Train loss: 1.2787392139434814\n",
            "\n",
            "Time (s): 0.6282625198364258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 200 / 499\n",
            "LR: 8.870773823954629e-05\n",
            "Train loss: 1.1128270626068115\n",
            "\n",
            "Time (s): 0.6291351318359375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 201 / 499\n",
            "LR: 8.870755954011439e-05\n",
            "Train loss: 0.8987480401992798\n",
            "\n",
            "Time (s): 0.6237547397613525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 202 / 499\n",
            "LR: 8.870738084176244e-05\n",
            "Train loss: 1.4087125062942505\n",
            "\n",
            "Time (s): 0.6237144470214844\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 203 / 499\n",
            "LR: 8.870720214449043e-05\n",
            "Train loss: 0.9024020433425903\n",
            "\n",
            "Time (s): 0.6284394264221191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 204 / 499\n",
            "LR: 8.870702344829836e-05\n",
            "Train loss: 0.4835170805454254\n",
            "\n",
            "Time (s): 0.626556396484375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 205 / 499\n",
            "LR: 8.87068447531862e-05\n",
            "Train loss: 0.7748643159866333\n",
            "\n",
            "Time (s): 0.6275708675384521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 206 / 499\n",
            "LR: 8.870666605915396e-05\n",
            "Train loss: 0.8523992896080017\n",
            "\n",
            "Time (s): 0.6239550113677979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 207 / 499\n",
            "LR: 8.87064873662016e-05\n",
            "Train loss: 0.9285823106765747\n",
            "\n",
            "Time (s): 0.6282975673675537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 208 / 499\n",
            "LR: 8.870630867432914e-05\n",
            "Train loss: 0.6957404613494873\n",
            "\n",
            "Time (s): 0.6255457401275635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 209 / 499\n",
            "LR: 8.870612998353655e-05\n",
            "Train loss: 0.4802805781364441\n",
            "\n",
            "Time (s): 0.6231129169464111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 210 / 499\n",
            "LR: 8.870595129382384e-05\n",
            "Train loss: 1.2643307447433472\n",
            "\n",
            "Time (s): 0.6234114170074463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 211 / 499\n",
            "LR: 8.870577260519095e-05\n",
            "Train loss: 0.3748492896556854\n",
            "\n",
            "Time (s): 0.6232361793518066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 212 / 499\n",
            "LR: 8.870559391763793e-05\n",
            "Train loss: 1.3441709280014038\n",
            "\n",
            "Time (s): 0.6284935474395752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 213 / 499\n",
            "LR: 8.870541523116473e-05\n",
            "Train loss: 1.0229885578155518\n",
            "\n",
            "Time (s): 0.6281802654266357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 214 / 499\n",
            "LR: 8.870523654577136e-05\n",
            "Train loss: 1.211087942123413\n",
            "\n",
            "Time (s): 0.6260919570922852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 215 / 499\n",
            "LR: 8.87050578614578e-05\n",
            "Train loss: 0.9550603628158569\n",
            "\n",
            "Time (s): 0.6279158592224121\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 216 / 499\n",
            "LR: 8.870487917822403e-05\n",
            "Train loss: 1.3069535493850708\n",
            "\n",
            "Time (s): 0.6269497871398926\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 217 / 499\n",
            "LR: 8.870470049607007e-05\n",
            "Train loss: 0.8086395263671875\n",
            "\n",
            "Time (s): 0.6232256889343262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 218 / 499\n",
            "LR: 8.870452181499586e-05\n",
            "Train loss: 0.9227147698402405\n",
            "\n",
            "Time (s): 0.6290922164916992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 219 / 499\n",
            "LR: 8.870434313500143e-05\n",
            "Train loss: 0.44050127267837524\n",
            "\n",
            "Time (s): 0.6254732608795166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 220 / 499\n",
            "LR: 8.870416445608677e-05\n",
            "Train loss: 0.9184243679046631\n",
            "\n",
            "Time (s): 0.6277205944061279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 221 / 499\n",
            "LR: 8.870398577825184e-05\n",
            "Train loss: 0.8699619770050049\n",
            "\n",
            "Time (s): 0.6251645088195801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 222 / 499\n",
            "LR: 8.870380710149663e-05\n",
            "Train loss: 0.3623948395252228\n",
            "\n",
            "Time (s): 0.624065637588501\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 223 / 499\n",
            "LR: 8.870362842582115e-05\n",
            "Train loss: 0.9668735265731812\n",
            "\n",
            "Time (s): 0.628293514251709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 224 / 499\n",
            "LR: 8.87034497512254e-05\n",
            "Train loss: 1.1177988052368164\n",
            "\n",
            "Time (s): 0.6276340484619141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 225 / 499\n",
            "LR: 8.870327107770936e-05\n",
            "Train loss: 0.8349813222885132\n",
            "\n",
            "Time (s): 0.6234252452850342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 226 / 499\n",
            "LR: 8.870309240527298e-05\n",
            "Train loss: 0.5348302721977234\n",
            "\n",
            "Time (s): 0.623572587966919\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 227 / 499\n",
            "LR: 8.87029137339163e-05\n",
            "Train loss: 0.8073713779449463\n",
            "\n",
            "Time (s): 0.6233303546905518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 228 / 499\n",
            "LR: 8.870273506363928e-05\n",
            "Train loss: 1.4388302564620972\n",
            "\n",
            "Time (s): 0.6233043670654297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 229 / 499\n",
            "LR: 8.870255639444192e-05\n",
            "Train loss: 0.5990326404571533\n",
            "\n",
            "Time (s): 0.6285815238952637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 230 / 499\n",
            "LR: 8.87023777263242e-05\n",
            "Train loss: 0.661467969417572\n",
            "\n",
            "Time (s): 0.632591724395752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 231 / 499\n",
            "LR: 8.870219905928612e-05\n",
            "Train loss: 0.6140459775924683\n",
            "\n",
            "Time (s): 0.6305980682373047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 232 / 499\n",
            "LR: 8.870202039332767e-05\n",
            "Train loss: 1.1763843297958374\n",
            "\n",
            "Time (s): 0.6283998489379883\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 233 / 499\n",
            "LR: 8.870184172844884e-05\n",
            "Train loss: 0.6022809147834778\n",
            "\n",
            "Time (s): 0.6293880939483643\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 234 / 499\n",
            "LR: 8.87016630646496e-05\n",
            "Train loss: 0.8161866068840027\n",
            "\n",
            "Time (s): 0.630256175994873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 235 / 499\n",
            "LR: 8.870148440192995e-05\n",
            "Train loss: 0.5605659484863281\n",
            "\n",
            "Time (s): 0.6286578178405762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 236 / 499\n",
            "LR: 8.87013057402899e-05\n",
            "Train loss: 1.1583706140518188\n",
            "\n",
            "Time (s): 0.6270172595977783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 237 / 499\n",
            "LR: 8.870112707972942e-05\n",
            "Train loss: 0.5375086069107056\n",
            "\n",
            "Time (s): 0.6299970149993896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 238 / 499\n",
            "LR: 8.870094842024849e-05\n",
            "Train loss: 1.0957422256469727\n",
            "\n",
            "Time (s): 0.6282544136047363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 239 / 499\n",
            "LR: 8.87007697618471e-05\n",
            "Train loss: 0.5481809973716736\n",
            "\n",
            "Time (s): 0.6287298202514648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 240 / 499\n",
            "LR: 8.870059110452527e-05\n",
            "Train loss: 0.5730953812599182\n",
            "\n",
            "Time (s): 0.6287906169891357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 241 / 499\n",
            "LR: 8.870041244828297e-05\n",
            "Train loss: 0.8472551107406616\n",
            "\n",
            "Time (s): 0.6258759498596191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 242 / 499\n",
            "LR: 8.870023379312016e-05\n",
            "Train loss: 1.2305183410644531\n",
            "\n",
            "Time (s): 0.6275970935821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 243 / 499\n",
            "LR: 8.870005513903688e-05\n",
            "Train loss: 0.8184821009635925\n",
            "\n",
            "Time (s): 0.6263926029205322\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 244 / 499\n",
            "LR: 8.869987648603308e-05\n",
            "Train loss: 0.4555724859237671\n",
            "\n",
            "Time (s): 0.6284878253936768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 245 / 499\n",
            "LR: 8.869969783410878e-05\n",
            "Train loss: 0.7633309960365295\n",
            "\n",
            "Time (s): 0.6289129257202148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 246 / 499\n",
            "LR: 8.869951918326394e-05\n",
            "Train loss: 0.9456619024276733\n",
            "\n",
            "Time (s): 0.628807783126831\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 247 / 499\n",
            "LR: 8.869934053349856e-05\n",
            "Train loss: 0.5226932764053345\n",
            "\n",
            "Time (s): 0.6308856010437012\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 248 / 499\n",
            "LR: 8.869916188481263e-05\n",
            "Train loss: 0.9572926163673401\n",
            "\n",
            "Time (s): 0.6290643215179443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 249 / 499\n",
            "LR: 8.869898323720617e-05\n",
            "Train loss: 1.0319386720657349\n",
            "\n",
            "Time (s): 0.6240205764770508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 250 / 499\n",
            "LR: 8.869880459067911e-05\n",
            "Train loss: 0.30236339569091797\n",
            "\n",
            "Time (s): 0.6284286975860596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 251 / 499\n",
            "LR: 8.869862594523148e-05\n",
            "Train loss: 0.9242584705352783\n",
            "\n",
            "Time (s): 0.6293330192565918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 252 / 499\n",
            "LR: 8.869844730086324e-05\n",
            "Train loss: 1.073630928993225\n",
            "\n",
            "Time (s): 0.6287872791290283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 253 / 499\n",
            "LR: 8.869826865757441e-05\n",
            "Train loss: 0.3880530297756195\n",
            "\n",
            "Time (s): 0.6297130584716797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 254 / 499\n",
            "LR: 8.869809001536498e-05\n",
            "Train loss: 0.45272764563560486\n",
            "\n",
            "Time (s): 0.6246328353881836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 255 / 499\n",
            "LR: 8.86979113742349e-05\n",
            "Train loss: 1.00895357131958\n",
            "\n",
            "Time (s): 0.6285126209259033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 256 / 499\n",
            "LR: 8.869773273418422e-05\n",
            "Train loss: 0.67799973487854\n",
            "\n",
            "Time (s): 0.6288158893585205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 257 / 499\n",
            "LR: 8.869755409521285e-05\n",
            "Train loss: 0.393633633852005\n",
            "\n",
            "Time (s): 0.629169225692749\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 258 / 499\n",
            "LR: 8.869737545732085e-05\n",
            "Train loss: 0.45416873693466187\n",
            "\n",
            "Time (s): 0.6296417713165283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 259 / 499\n",
            "LR: 8.86971968205082e-05\n",
            "Train loss: 0.9299338459968567\n",
            "\n",
            "Time (s): 0.6278831958770752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 260 / 499\n",
            "LR: 8.869701818477483e-05\n",
            "Train loss: 1.1046123504638672\n",
            "\n",
            "Time (s): 0.628516435623169\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 261 / 499\n",
            "LR: 8.86968395501208e-05\n",
            "Train loss: 0.910206139087677\n",
            "\n",
            "Time (s): 0.6286444664001465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 262 / 499\n",
            "LR: 8.869666091654605e-05\n",
            "Train loss: 1.0816187858581543\n",
            "\n",
            "Time (s): 0.6241376399993896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 263 / 499\n",
            "LR: 8.869648228405059e-05\n",
            "Train loss: 0.7134916186332703\n",
            "\n",
            "Time (s): 0.629425048828125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 264 / 499\n",
            "LR: 8.869630365263441e-05\n",
            "Train loss: 0.88444983959198\n",
            "\n",
            "Time (s): 0.6289997100830078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 265 / 499\n",
            "LR: 8.86961250222975e-05\n",
            "Train loss: 0.31613242626190186\n",
            "\n",
            "Time (s): 0.6286261081695557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 266 / 499\n",
            "LR: 8.869594639303985e-05\n",
            "Train loss: 1.2213802337646484\n",
            "\n",
            "Time (s): 0.6297292709350586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 267 / 499\n",
            "LR: 8.869576776486144e-05\n",
            "Train loss: 0.6506804823875427\n",
            "\n",
            "Time (s): 0.6315274238586426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 268 / 499\n",
            "LR: 8.869558913776226e-05\n",
            "Train loss: 0.513725221157074\n",
            "\n",
            "Time (s): 0.6303112506866455\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 269 / 499\n",
            "LR: 8.869541051174232e-05\n",
            "Train loss: 0.5039741396903992\n",
            "\n",
            "Time (s): 0.6298103332519531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 270 / 499\n",
            "LR: 8.86952318868016e-05\n",
            "Train loss: 0.649624228477478\n",
            "\n",
            "Time (s): 0.628284215927124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 271 / 499\n",
            "LR: 8.869505326294004e-05\n",
            "Train loss: 1.0011521577835083\n",
            "\n",
            "Time (s): 0.6296579837799072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 272 / 499\n",
            "LR: 8.869487464015769e-05\n",
            "Train loss: 1.0157825946807861\n",
            "\n",
            "Time (s): 0.6287016868591309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 273 / 499\n",
            "LR: 8.869469601845453e-05\n",
            "Train loss: 0.5134969353675842\n",
            "\n",
            "Time (s): 0.6280002593994141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 274 / 499\n",
            "LR: 8.869451739783053e-05\n",
            "Train loss: 0.9148963093757629\n",
            "\n",
            "Time (s): 0.6281924247741699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 275 / 499\n",
            "LR: 8.869433877828569e-05\n",
            "Train loss: 0.6322193145751953\n",
            "\n",
            "Time (s): 0.6288225650787354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 276 / 499\n",
            "LR: 8.869416015981999e-05\n",
            "Train loss: 0.8782188296318054\n",
            "\n",
            "Time (s): 0.6280956268310547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 277 / 499\n",
            "LR: 8.869398154243343e-05\n",
            "Train loss: 1.1429963111877441\n",
            "\n",
            "Time (s): 0.6280484199523926\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 278 / 499\n",
            "LR: 8.869380292612602e-05\n",
            "Train loss: 1.2404676675796509\n",
            "\n",
            "Time (s): 0.6293027400970459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 279 / 499\n",
            "LR: 8.86936243108977e-05\n",
            "Train loss: 1.1747714281082153\n",
            "\n",
            "Time (s): 0.6278879642486572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 280 / 499\n",
            "LR: 8.869344569674847e-05\n",
            "Train loss: 1.1549320220947266\n",
            "\n",
            "Time (s): 0.6292037963867188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 281 / 499\n",
            "LR: 8.869326708367835e-05\n",
            "Train loss: 0.6636738181114197\n",
            "\n",
            "Time (s): 0.6286220550537109\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 282 / 499\n",
            "LR: 8.869308847168733e-05\n",
            "Train loss: 1.1642545461654663\n",
            "\n",
            "Time (s): 0.6291790008544922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 283 / 499\n",
            "LR: 8.869290986077534e-05\n",
            "Train loss: 1.0726715326309204\n",
            "\n",
            "Time (s): 0.6287086009979248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 284 / 499\n",
            "LR: 8.869273125094245e-05\n",
            "Train loss: 0.9626601338386536\n",
            "\n",
            "Time (s): 0.6288609504699707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 285 / 499\n",
            "LR: 8.869255264218859e-05\n",
            "Train loss: 0.8175444006919861\n",
            "\n",
            "Time (s): 0.6283535957336426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 286 / 499\n",
            "LR: 8.869237403451377e-05\n",
            "Train loss: 0.9211862683296204\n",
            "\n",
            "Time (s): 0.6288633346557617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 287 / 499\n",
            "LR: 8.869219542791797e-05\n",
            "Train loss: 0.9447146654129028\n",
            "\n",
            "Time (s): 0.6282086372375488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 288 / 499\n",
            "LR: 8.869201682240122e-05\n",
            "Train loss: 0.5487629175186157\n",
            "\n",
            "Time (s): 0.6299784183502197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 289 / 499\n",
            "LR: 8.869183821796343e-05\n",
            "Train loss: 1.103742241859436\n",
            "\n",
            "Time (s): 0.6292111873626709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 290 / 499\n",
            "LR: 8.869165961460466e-05\n",
            "Train loss: 1.2530474662780762\n",
            "\n",
            "Time (s): 0.6298959255218506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 291 / 499\n",
            "LR: 8.869148101232487e-05\n",
            "Train loss: 1.5488768815994263\n",
            "\n",
            "Time (s): 0.6297833919525146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 292 / 499\n",
            "LR: 8.869130241112406e-05\n",
            "Train loss: 0.7053766846656799\n",
            "\n",
            "Time (s): 0.6293067932128906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 293 / 499\n",
            "LR: 8.869112381100222e-05\n",
            "Train loss: 0.7292669415473938\n",
            "\n",
            "Time (s): 0.6286649703979492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 294 / 499\n",
            "LR: 8.86909452119593e-05\n",
            "Train loss: 0.1687183380126953\n",
            "\n",
            "Time (s): 0.6290633678436279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 295 / 499\n",
            "LR: 8.869076661399535e-05\n",
            "Train loss: 0.8923149108886719\n",
            "\n",
            "Time (s): 0.6256861686706543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 296 / 499\n",
            "LR: 8.869058801711032e-05\n",
            "Train loss: 1.4313336610794067\n",
            "\n",
            "Time (s): 0.629155158996582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 297 / 499\n",
            "LR: 8.86904094213042e-05\n",
            "Train loss: 0.39244893193244934\n",
            "\n",
            "Time (s): 0.6289498805999756\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 298 / 499\n",
            "LR: 8.8690230826577e-05\n",
            "Train loss: 0.55922532081604\n",
            "\n",
            "Time (s): 0.6244804859161377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 299 / 499\n",
            "LR: 8.86900522329287e-05\n",
            "Train loss: 0.7714234590530396\n",
            "\n",
            "Time (s): 0.624272346496582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 300 / 499\n",
            "LR: 8.868987364035928e-05\n",
            "Train loss: 0.43345439434051514\n",
            "\n",
            "Time (s): 0.6292145252227783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 301 / 499\n",
            "LR: 8.868969504886874e-05\n",
            "Train loss: 0.9343053102493286\n",
            "\n",
            "Time (s): 0.629502534866333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 302 / 499\n",
            "LR: 8.868951645845705e-05\n",
            "Train loss: 0.6341592073440552\n",
            "\n",
            "Time (s): 0.6241550445556641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 303 / 499\n",
            "LR: 8.868933786912423e-05\n",
            "Train loss: 1.2938146591186523\n",
            "\n",
            "Time (s): 0.6286706924438477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 304 / 499\n",
            "LR: 8.868915928087025e-05\n",
            "Train loss: 0.9803181290626526\n",
            "\n",
            "Time (s): 0.6283276081085205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 305 / 499\n",
            "LR: 8.868898069369508e-05\n",
            "Train loss: 0.6324566602706909\n",
            "\n",
            "Time (s): 0.6298110485076904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 306 / 499\n",
            "LR: 8.868880210759874e-05\n",
            "Train loss: 0.7728412747383118\n",
            "\n",
            "Time (s): 0.6287462711334229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 307 / 499\n",
            "LR: 8.868862352258124e-05\n",
            "Train loss: 1.0241698026657104\n",
            "\n",
            "Time (s): 0.6289846897125244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 308 / 499\n",
            "LR: 8.86884449386425e-05\n",
            "Train loss: 1.1776784658432007\n",
            "\n",
            "Time (s): 0.6293752193450928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 309 / 499\n",
            "LR: 8.868826635578259e-05\n",
            "Train loss: 0.9576911330223083\n",
            "\n",
            "Time (s): 0.6258718967437744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 310 / 499\n",
            "LR: 8.868808777400145e-05\n",
            "Train loss: 0.9490318298339844\n",
            "\n",
            "Time (s): 0.6277656555175781\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 311 / 499\n",
            "LR: 8.868790919329906e-05\n",
            "Train loss: 1.1183216571807861\n",
            "\n",
            "Time (s): 0.6286685466766357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 312 / 499\n",
            "LR: 8.868773061367542e-05\n",
            "Train loss: 0.9212659001350403\n",
            "\n",
            "Time (s): 0.6282603740692139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 313 / 499\n",
            "LR: 8.868755203513054e-05\n",
            "Train loss: 0.954439103603363\n",
            "\n",
            "Time (s): 0.6291749477386475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 314 / 499\n",
            "LR: 8.868737345766438e-05\n",
            "Train loss: 0.5642940402030945\n",
            "\n",
            "Time (s): 0.6293280124664307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 315 / 499\n",
            "LR: 8.868719488127695e-05\n",
            "Train loss: 0.8879294991493225\n",
            "\n",
            "Time (s): 0.6242635250091553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 316 / 499\n",
            "LR: 8.868701630596825e-05\n",
            "Train loss: 0.638380229473114\n",
            "\n",
            "Time (s): 0.6245300769805908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 317 / 499\n",
            "LR: 8.868683773173824e-05\n",
            "Train loss: 1.064746379852295\n",
            "\n",
            "Time (s): 0.629284143447876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 318 / 499\n",
            "LR: 8.868665915858692e-05\n",
            "Train loss: 1.151241421699524\n",
            "\n",
            "Time (s): 0.6240580081939697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 319 / 499\n",
            "LR: 8.868648058651428e-05\n",
            "Train loss: 0.7119084596633911\n",
            "\n",
            "Time (s): 0.6245584487915039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 320 / 499\n",
            "LR: 8.868630201552031e-05\n",
            "Train loss: 0.5894094705581665\n",
            "\n",
            "Time (s): 0.6284546852111816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 321 / 499\n",
            "LR: 8.868612344560499e-05\n",
            "Train loss: 0.8173037767410278\n",
            "\n",
            "Time (s): 0.6286897659301758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 322 / 499\n",
            "LR: 8.868594487676832e-05\n",
            "Train loss: 1.1591418981552124\n",
            "\n",
            "Time (s): 0.6266822814941406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 323 / 499\n",
            "LR: 8.868576630901029e-05\n",
            "Train loss: 1.4119131565093994\n",
            "\n",
            "Time (s): 0.6243550777435303\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 324 / 499\n",
            "LR: 8.868558774233089e-05\n",
            "Train loss: 0.8302188515663147\n",
            "\n",
            "Time (s): 0.6232962608337402\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 325 / 499\n",
            "LR: 8.86854091767301e-05\n",
            "Train loss: 0.20695555210113525\n",
            "\n",
            "Time (s): 0.627434253692627\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 326 / 499\n",
            "LR: 8.868523061220791e-05\n",
            "Train loss: 0.41146034002304077\n",
            "\n",
            "Time (s): 0.627652645111084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 327 / 499\n",
            "LR: 8.868505204876433e-05\n",
            "Train loss: 0.8068457841873169\n",
            "\n",
            "Time (s): 0.6242313385009766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 328 / 499\n",
            "LR: 8.868487348639932e-05\n",
            "Train loss: 0.6695501804351807\n",
            "\n",
            "Time (s): 0.6235976219177246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 329 / 499\n",
            "LR: 8.868469492511288e-05\n",
            "Train loss: 0.506670355796814\n",
            "\n",
            "Time (s): 0.6289427280426025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 330 / 499\n",
            "LR: 8.8684516364905e-05\n",
            "Train loss: 0.5746544599533081\n",
            "\n",
            "Time (s): 0.6240088939666748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 331 / 499\n",
            "LR: 8.868433780577567e-05\n",
            "Train loss: 0.8435404300689697\n",
            "\n",
            "Time (s): 0.6274764537811279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 332 / 499\n",
            "LR: 8.868415924772488e-05\n",
            "Train loss: 0.909148633480072\n",
            "\n",
            "Time (s): 0.629042387008667\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 333 / 499\n",
            "LR: 8.868398069075262e-05\n",
            "Train loss: 0.6317198872566223\n",
            "\n",
            "Time (s): 0.6280763149261475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 334 / 499\n",
            "LR: 8.868380213485889e-05\n",
            "Train loss: 0.9169613122940063\n",
            "\n",
            "Time (s): 0.6233565807342529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 335 / 499\n",
            "LR: 8.868362358004366e-05\n",
            "Train loss: 0.8785213232040405\n",
            "\n",
            "Time (s): 0.6236402988433838\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 336 / 499\n",
            "LR: 8.868344502630691e-05\n",
            "Train loss: 0.26432541012763977\n",
            "\n",
            "Time (s): 0.629507303237915\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 337 / 499\n",
            "LR: 8.868326647364865e-05\n",
            "Train loss: 1.2366511821746826\n",
            "\n",
            "Time (s): 0.6291821002960205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 338 / 499\n",
            "LR: 8.868308792206885e-05\n",
            "Train loss: 0.8730849027633667\n",
            "\n",
            "Time (s): 0.6262874603271484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 339 / 499\n",
            "LR: 8.868290937156755e-05\n",
            "Train loss: 0.8336221575737\n",
            "\n",
            "Time (s): 0.627800464630127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 340 / 499\n",
            "LR: 8.868273082214468e-05\n",
            "Train loss: 1.430416226387024\n",
            "\n",
            "Time (s): 0.6275012493133545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 341 / 499\n",
            "LR: 8.868255227380026e-05\n",
            "Train loss: 0.40341445803642273\n",
            "\n",
            "Time (s): 0.623659610748291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 342 / 499\n",
            "LR: 8.868237372653426e-05\n",
            "Train loss: 0.7572979927062988\n",
            "\n",
            "Time (s): 0.6238241195678711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 343 / 499\n",
            "LR: 8.86821951803467e-05\n",
            "Train loss: 0.7164190411567688\n",
            "\n",
            "Time (s): 0.6235613822937012\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 344 / 499\n",
            "LR: 8.868201663523751e-05\n",
            "Train loss: 0.8074905276298523\n",
            "\n",
            "Time (s): 0.6238760948181152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 345 / 499\n",
            "LR: 8.868183809120673e-05\n",
            "Train loss: 0.645176887512207\n",
            "\n",
            "Time (s): 0.628298282623291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 346 / 499\n",
            "LR: 8.868165954825436e-05\n",
            "Train loss: 0.584960401058197\n",
            "\n",
            "Time (s): 0.6261911392211914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 347 / 499\n",
            "LR: 8.868148100638036e-05\n",
            "Train loss: 0.5181918740272522\n",
            "\n",
            "Time (s): 0.6275546550750732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 348 / 499\n",
            "LR: 8.868130246558471e-05\n",
            "Train loss: 0.6316018104553223\n",
            "\n",
            "Time (s): 0.6301734447479248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 349 / 499\n",
            "LR: 8.868112392586741e-05\n",
            "Train loss: 0.5912395715713501\n",
            "\n",
            "Time (s): 0.6237587928771973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 350 / 499\n",
            "LR: 8.868094538722849e-05\n",
            "Train loss: 1.0632553100585938\n",
            "\n",
            "Time (s): 0.6236827373504639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 351 / 499\n",
            "LR: 8.868076684966788e-05\n",
            "Train loss: 0.5115663409233093\n",
            "\n",
            "Time (s): 0.6284422874450684\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 352 / 499\n",
            "LR: 8.868058831318559e-05\n",
            "Train loss: 0.7514742612838745\n",
            "\n",
            "Time (s): 0.6269698143005371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 353 / 499\n",
            "LR: 8.86804097777816e-05\n",
            "Train loss: 0.885342538356781\n",
            "\n",
            "Time (s): 0.628504753112793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 354 / 499\n",
            "LR: 8.868023124345594e-05\n",
            "Train loss: 0.48421189188957214\n",
            "\n",
            "Time (s): 0.6249268054962158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 355 / 499\n",
            "LR: 8.868005271020854e-05\n",
            "Train loss: 0.5279653072357178\n",
            "\n",
            "Time (s): 0.6237258911132812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 356 / 499\n",
            "LR: 8.867987417803941e-05\n",
            "Train loss: 0.8764129877090454\n",
            "\n",
            "Time (s): 0.6237306594848633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 357 / 499\n",
            "LR: 8.867969564694857e-05\n",
            "Train loss: 1.0066336393356323\n",
            "\n",
            "Time (s): 0.6284778118133545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 358 / 499\n",
            "LR: 8.8679517116936e-05\n",
            "Train loss: 0.6845274567604065\n",
            "\n",
            "Time (s): 0.6284632682800293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 359 / 499\n",
            "LR: 8.867933858800165e-05\n",
            "Train loss: 1.827014684677124\n",
            "\n",
            "Time (s): 0.6304054260253906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 360 / 499\n",
            "LR: 8.867916006014554e-05\n",
            "Train loss: 0.9854180812835693\n",
            "\n",
            "Time (s): 0.6298723220825195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 361 / 499\n",
            "LR: 8.867898153336768e-05\n",
            "Train loss: 1.2114906311035156\n",
            "\n",
            "Time (s): 0.6288571357727051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 362 / 499\n",
            "LR: 8.867880300766799e-05\n",
            "Train loss: 0.9970645308494568\n",
            "\n",
            "Time (s): 0.6293134689331055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 363 / 499\n",
            "LR: 8.867862448304653e-05\n",
            "Train loss: 1.0603947639465332\n",
            "\n",
            "Time (s): 0.6302952766418457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 364 / 499\n",
            "LR: 8.867844595950326e-05\n",
            "Train loss: 0.39962977170944214\n",
            "\n",
            "Time (s): 0.6297991275787354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 365 / 499\n",
            "LR: 8.867826743703818e-05\n",
            "Train loss: 0.8768316507339478\n",
            "\n",
            "Time (s): 0.6285479068756104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 366 / 499\n",
            "LR: 8.867808891565124e-05\n",
            "Train loss: 0.8717889785766602\n",
            "\n",
            "Time (s): 0.6293103694915771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 367 / 499\n",
            "LR: 8.867791039534248e-05\n",
            "Train loss: 1.1735634803771973\n",
            "\n",
            "Time (s): 0.6283481121063232\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 368 / 499\n",
            "LR: 8.867773187611186e-05\n",
            "Train loss: 1.0728996992111206\n",
            "\n",
            "Time (s): 0.6286933422088623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 369 / 499\n",
            "LR: 8.867755335795938e-05\n",
            "Train loss: 0.8976238965988159\n",
            "\n",
            "Time (s): 0.6290245056152344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 370 / 499\n",
            "LR: 8.867737484088502e-05\n",
            "Train loss: 1.1120152473449707\n",
            "\n",
            "Time (s): 0.6297934055328369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 371 / 499\n",
            "LR: 8.867719632488879e-05\n",
            "Train loss: 0.8228797316551208\n",
            "\n",
            "Time (s): 0.6286532878875732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 372 / 499\n",
            "LR: 8.867701780997067e-05\n",
            "Train loss: 0.78559809923172\n",
            "\n",
            "Time (s): 0.6289520263671875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 373 / 499\n",
            "LR: 8.867683929613062e-05\n",
            "Train loss: 0.7547368407249451\n",
            "\n",
            "Time (s): 0.6282444000244141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 374 / 499\n",
            "LR: 8.867666078336866e-05\n",
            "Train loss: 0.747551679611206\n",
            "\n",
            "Time (s): 0.6281528472900391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 375 / 499\n",
            "LR: 8.867648227168478e-05\n",
            "Train loss: 0.667549729347229\n",
            "\n",
            "Time (s): 0.6289286613464355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 376 / 499\n",
            "LR: 8.867630376107896e-05\n",
            "Train loss: 0.8021535277366638\n",
            "\n",
            "Time (s): 0.6290469169616699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 377 / 499\n",
            "LR: 8.867612525155117e-05\n",
            "Train loss: 1.6434446573257446\n",
            "\n",
            "Time (s): 0.6293625831604004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 378 / 499\n",
            "LR: 8.867594674310145e-05\n",
            "Train loss: 0.7688430547714233\n",
            "\n",
            "Time (s): 0.6292459964752197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 379 / 499\n",
            "LR: 8.867576823572974e-05\n",
            "Train loss: 0.7090329527854919\n",
            "\n",
            "Time (s): 0.6295120716094971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 380 / 499\n",
            "LR: 8.867558972943606e-05\n",
            "Train loss: 0.597927451133728\n",
            "\n",
            "Time (s): 0.6298325061798096\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 381 / 499\n",
            "LR: 8.867541122422038e-05\n",
            "Train loss: 0.8303223252296448\n",
            "\n",
            "Time (s): 0.629237174987793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 382 / 499\n",
            "LR: 8.86752327200827e-05\n",
            "Train loss: 1.0897005796432495\n",
            "\n",
            "Time (s): 0.6294553279876709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 383 / 499\n",
            "LR: 8.867505421702302e-05\n",
            "Train loss: 0.3292349874973297\n",
            "\n",
            "Time (s): 0.6296694278717041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 384 / 499\n",
            "LR: 8.867487571504129e-05\n",
            "Train loss: 0.5365621447563171\n",
            "\n",
            "Time (s): 0.6296253204345703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 385 / 499\n",
            "LR: 8.867469721413752e-05\n",
            "Train loss: 1.160974383354187\n",
            "\n",
            "Time (s): 0.6298015117645264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 386 / 499\n",
            "LR: 8.867451871431172e-05\n",
            "Train loss: 1.0837783813476562\n",
            "\n",
            "Time (s): 0.6284327507019043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 387 / 499\n",
            "LR: 8.867434021556385e-05\n",
            "Train loss: 0.8728430271148682\n",
            "\n",
            "Time (s): 0.6297211647033691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 388 / 499\n",
            "LR: 8.867416171789392e-05\n",
            "Train loss: 0.5145290493965149\n",
            "\n",
            "Time (s): 0.6321454048156738\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 389 / 499\n",
            "LR: 8.867398322130191e-05\n",
            "Train loss: 0.3134579658508301\n",
            "\n",
            "Time (s): 0.6295325756072998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 390 / 499\n",
            "LR: 8.867380472578782e-05\n",
            "Train loss: 0.5837514400482178\n",
            "\n",
            "Time (s): 0.6287198066711426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 391 / 499\n",
            "LR: 8.86736262313516e-05\n",
            "Train loss: 0.9731404781341553\n",
            "\n",
            "Time (s): 0.6292963027954102\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 392 / 499\n",
            "LR: 8.867344773799328e-05\n",
            "Train loss: 1.18459153175354\n",
            "\n",
            "Time (s): 0.6285824775695801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 393 / 499\n",
            "LR: 8.867326924571284e-05\n",
            "Train loss: 0.7230982780456543\n",
            "\n",
            "Time (s): 0.6294751167297363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 394 / 499\n",
            "LR: 8.867309075451028e-05\n",
            "Train loss: 1.1637269258499146\n",
            "\n",
            "Time (s): 0.6322472095489502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 395 / 499\n",
            "LR: 8.867291226438555e-05\n",
            "Train loss: 0.9082576036453247\n",
            "\n",
            "Time (s): 0.6287491321563721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 396 / 499\n",
            "LR: 8.867273377533868e-05\n",
            "Train loss: 1.1368696689605713\n",
            "\n",
            "Time (s): 0.6290285587310791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 397 / 499\n",
            "LR: 8.867255528736963e-05\n",
            "Train loss: 0.3655749559402466\n",
            "\n",
            "Time (s): 0.6292438507080078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 398 / 499\n",
            "LR: 8.867237680047843e-05\n",
            "Train loss: 0.8056433200836182\n",
            "\n",
            "Time (s): 0.6316525936126709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 399 / 499\n",
            "LR: 8.867219831466503e-05\n",
            "Train loss: 0.7039809226989746\n",
            "\n",
            "Time (s): 0.6307010650634766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 400 / 499\n",
            "LR: 8.867201982992941e-05\n",
            "Train loss: 0.8843643069267273\n",
            "\n",
            "Time (s): 0.6293845176696777\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 401 / 499\n",
            "LR: 8.86718413462716e-05\n",
            "Train loss: 1.0913971662521362\n",
            "\n",
            "Time (s): 0.6294856071472168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 402 / 499\n",
            "LR: 8.867166286369154e-05\n",
            "Train loss: 1.0914093255996704\n",
            "\n",
            "Time (s): 0.6299293041229248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 403 / 499\n",
            "LR: 8.86714843821893e-05\n",
            "Train loss: 0.6212502121925354\n",
            "\n",
            "Time (s): 0.6282620429992676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 404 / 499\n",
            "LR: 8.867130590176478e-05\n",
            "Train loss: 0.650688111782074\n",
            "\n",
            "Time (s): 0.62847900390625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 405 / 499\n",
            "LR: 8.867112742241801e-05\n",
            "Train loss: 0.8745144605636597\n",
            "\n",
            "Time (s): 0.6281683444976807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 406 / 499\n",
            "LR: 8.867094894414898e-05\n",
            "Train loss: 0.9381176233291626\n",
            "\n",
            "Time (s): 0.6285698413848877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 407 / 499\n",
            "LR: 8.867077046695769e-05\n",
            "Train loss: 1.2412610054016113\n",
            "\n",
            "Time (s): 0.6242859363555908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 408 / 499\n",
            "LR: 8.86705919908441e-05\n",
            "Train loss: 0.7682154178619385\n",
            "\n",
            "Time (s): 0.628795862197876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 409 / 499\n",
            "LR: 8.867041351580823e-05\n",
            "Train loss: 0.6280951499938965\n",
            "\n",
            "Time (s): 0.6243371963500977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 410 / 499\n",
            "LR: 8.867023504185003e-05\n",
            "Train loss: 1.4182357788085938\n",
            "\n",
            "Time (s): 0.6287829875946045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 411 / 499\n",
            "LR: 8.867005656896951e-05\n",
            "Train loss: 0.6392039060592651\n",
            "\n",
            "Time (s): 0.6283860206604004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 412 / 499\n",
            "LR: 8.866987809716666e-05\n",
            "Train loss: 0.6831788420677185\n",
            "\n",
            "Time (s): 0.6265203952789307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 413 / 499\n",
            "LR: 8.866969962644148e-05\n",
            "Train loss: 0.7585603594779968\n",
            "\n",
            "Time (s): 0.6308200359344482\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 414 / 499\n",
            "LR: 8.866952115679395e-05\n",
            "Train loss: 1.0382834672927856\n",
            "\n",
            "Time (s): 0.6240675449371338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 415 / 499\n",
            "LR: 8.866934268822407e-05\n",
            "Train loss: 1.0297032594680786\n",
            "\n",
            "Time (s): 0.6284022331237793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 416 / 499\n",
            "LR: 8.86691642207318e-05\n",
            "Train loss: 1.100874900817871\n",
            "\n",
            "Time (s): 0.6288869380950928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 417 / 499\n",
            "LR: 8.866898575431716e-05\n",
            "Train loss: 0.9695770740509033\n",
            "\n",
            "Time (s): 0.6237363815307617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 418 / 499\n",
            "LR: 8.866880728898012e-05\n",
            "Train loss: 0.9305527806282043\n",
            "\n",
            "Time (s): 0.6277189254760742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 419 / 499\n",
            "LR: 8.866862882472067e-05\n",
            "Train loss: 0.39384016394615173\n",
            "\n",
            "Time (s): 0.6296155452728271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 420 / 499\n",
            "LR: 8.86684503615388e-05\n",
            "Train loss: 0.5204418301582336\n",
            "\n",
            "Time (s): 0.6277365684509277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 421 / 499\n",
            "LR: 8.866827189943451e-05\n",
            "Train loss: 0.5595027804374695\n",
            "\n",
            "Time (s): 0.6291975975036621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 422 / 499\n",
            "LR: 8.866809343840778e-05\n",
            "Train loss: 0.8950867056846619\n",
            "\n",
            "Time (s): 0.6247427463531494\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 423 / 499\n",
            "LR: 8.86679149784586e-05\n",
            "Train loss: 0.30718737840652466\n",
            "\n",
            "Time (s): 0.6285824775695801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 424 / 499\n",
            "LR: 8.866773651958696e-05\n",
            "Train loss: 1.3484281301498413\n",
            "\n",
            "Time (s): 0.6352460384368896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 425 / 499\n",
            "LR: 8.866755806179286e-05\n",
            "Train loss: 0.4856526851654053\n",
            "\n",
            "Time (s): 0.6240806579589844\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 426 / 499\n",
            "LR: 8.866737960507628e-05\n",
            "Train loss: 0.7097770571708679\n",
            "\n",
            "Time (s): 0.6290416717529297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 427 / 499\n",
            "LR: 8.866720114943719e-05\n",
            "Train loss: 1.1659080982208252\n",
            "\n",
            "Time (s): 0.6287319660186768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 428 / 499\n",
            "LR: 8.866702269487561e-05\n",
            "Train loss: 0.7987066507339478\n",
            "\n",
            "Time (s): 0.6276309490203857\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 429 / 499\n",
            "LR: 8.866684424139151e-05\n",
            "Train loss: 0.8402631878852844\n",
            "\n",
            "Time (s): 0.628791093826294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 430 / 499\n",
            "LR: 8.86666657889849e-05\n",
            "Train loss: 0.983716607093811\n",
            "\n",
            "Time (s): 0.625382661819458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 431 / 499\n",
            "LR: 8.866648733765574e-05\n",
            "Train loss: 0.4458093047142029\n",
            "\n",
            "Time (s): 0.6285445690155029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 432 / 499\n",
            "LR: 8.866630888740405e-05\n",
            "Train loss: 0.7153679132461548\n",
            "\n",
            "Time (s): 0.6256453990936279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 433 / 499\n",
            "LR: 8.866613043822978e-05\n",
            "Train loss: 0.39474523067474365\n",
            "\n",
            "Time (s): 0.6233668327331543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 434 / 499\n",
            "LR: 8.866595199013296e-05\n",
            "Train loss: 0.3924468457698822\n",
            "\n",
            "Time (s): 0.6280999183654785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 435 / 499\n",
            "LR: 8.866577354311353e-05\n",
            "Train loss: 1.4317617416381836\n",
            "\n",
            "Time (s): 0.6295464038848877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 436 / 499\n",
            "LR: 8.866559509717157e-05\n",
            "Train loss: 0.4784947335720062\n",
            "\n",
            "Time (s): 0.6236481666564941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 437 / 499\n",
            "LR: 8.866541665230697e-05\n",
            "Train loss: 1.089980959892273\n",
            "\n",
            "Time (s): 0.6239993572235107\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 438 / 499\n",
            "LR: 8.866523820851977e-05\n",
            "Train loss: 1.3668220043182373\n",
            "\n",
            "Time (s): 0.627737283706665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 439 / 499\n",
            "LR: 8.866505976580994e-05\n",
            "Train loss: 0.6396094560623169\n",
            "\n",
            "Time (s): 0.6286287307739258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 440 / 499\n",
            "LR: 8.866488132417746e-05\n",
            "Train loss: 0.9817631840705872\n",
            "\n",
            "Time (s): 0.6289949417114258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 441 / 499\n",
            "LR: 8.866470288362235e-05\n",
            "Train loss: 1.0844606161117554\n",
            "\n",
            "Time (s): 0.62803053855896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 442 / 499\n",
            "LR: 8.866452444414461e-05\n",
            "Train loss: 0.679122805595398\n",
            "\n",
            "Time (s): 0.6289923191070557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 443 / 499\n",
            "LR: 8.866434600574417e-05\n",
            "Train loss: 1.0518476963043213\n",
            "\n",
            "Time (s): 0.6294693946838379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 444 / 499\n",
            "LR: 8.866416756842108e-05\n",
            "Train loss: 0.4006200432777405\n",
            "\n",
            "Time (s): 0.6246600151062012\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 445 / 499\n",
            "LR: 8.86639891321753e-05\n",
            "Train loss: 1.0720734596252441\n",
            "\n",
            "Time (s): 0.6295077800750732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 446 / 499\n",
            "LR: 8.866381069700681e-05\n",
            "Train loss: 0.8928438425064087\n",
            "\n",
            "Time (s): 0.624370813369751\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 447 / 499\n",
            "LR: 8.866363226291561e-05\n",
            "Train loss: 1.207780122756958\n",
            "\n",
            "Time (s): 0.6295812129974365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 448 / 499\n",
            "LR: 8.866345382990169e-05\n",
            "Train loss: 0.5844118595123291\n",
            "\n",
            "Time (s): 0.6280217170715332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 449 / 499\n",
            "LR: 8.866327539796505e-05\n",
            "Train loss: 0.4138902425765991\n",
            "\n",
            "Time (s): 0.6285507678985596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 450 / 499\n",
            "LR: 8.866309696710567e-05\n",
            "Train loss: 0.8105980753898621\n",
            "\n",
            "Time (s): 0.6285474300384521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 451 / 499\n",
            "LR: 8.866291853732354e-05\n",
            "Train loss: 1.307436466217041\n",
            "\n",
            "Time (s): 0.6289262771606445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 452 / 499\n",
            "LR: 8.866274010861864e-05\n",
            "Train loss: 0.8269315361976624\n",
            "\n",
            "Time (s): 0.6280920505523682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 453 / 499\n",
            "LR: 8.866256168099096e-05\n",
            "Train loss: 1.269478440284729\n",
            "\n",
            "Time (s): 0.6302177906036377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 454 / 499\n",
            "LR: 8.866238325444051e-05\n",
            "Train loss: 0.7468010187149048\n",
            "\n",
            "Time (s): 0.6281335353851318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 455 / 499\n",
            "LR: 8.866220482896726e-05\n",
            "Train loss: 1.0783487558364868\n",
            "\n",
            "Time (s): 0.6289751529693604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 456 / 499\n",
            "LR: 8.86620264045712e-05\n",
            "Train loss: 1.3521384000778198\n",
            "\n",
            "Time (s): 0.6292965412139893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 457 / 499\n",
            "LR: 8.86618479812523e-05\n",
            "Train loss: 0.6372634172439575\n",
            "\n",
            "Time (s): 0.6287505626678467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 458 / 499\n",
            "LR: 8.86616695590106e-05\n",
            "Train loss: 0.44965890049934387\n",
            "\n",
            "Time (s): 0.629615068435669\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 459 / 499\n",
            "LR: 8.866149113784607e-05\n",
            "Train loss: 1.154029369354248\n",
            "\n",
            "Time (s): 0.6281650066375732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 460 / 499\n",
            "LR: 8.866131271775867e-05\n",
            "Train loss: 0.8945200443267822\n",
            "\n",
            "Time (s): 0.628422737121582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 461 / 499\n",
            "LR: 8.866113429874843e-05\n",
            "Train loss: 0.9634681344032288\n",
            "\n",
            "Time (s): 0.6285195350646973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 462 / 499\n",
            "LR: 8.866095588081529e-05\n",
            "Train loss: 1.2302806377410889\n",
            "\n",
            "Time (s): 0.6294291019439697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 463 / 499\n",
            "LR: 8.866077746395928e-05\n",
            "Train loss: 1.346958875656128\n",
            "\n",
            "Time (s): 0.628504753112793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 464 / 499\n",
            "LR: 8.86605990481804e-05\n",
            "Train loss: 0.929265022277832\n",
            "\n",
            "Time (s): 0.6289932727813721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 465 / 499\n",
            "LR: 8.866042063347856e-05\n",
            "Train loss: 0.9375753402709961\n",
            "\n",
            "Time (s): 0.6276683807373047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 466 / 499\n",
            "LR: 8.866024221985386e-05\n",
            "Train loss: 0.7021485567092896\n",
            "\n",
            "Time (s): 0.6281864643096924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 467 / 499\n",
            "LR: 8.866006380730624e-05\n",
            "Train loss: 0.5359079837799072\n",
            "\n",
            "Time (s): 0.6294386386871338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 468 / 499\n",
            "LR: 8.865988539583565e-05\n",
            "Train loss: 0.8724226355552673\n",
            "\n",
            "Time (s): 0.6296954154968262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 469 / 499\n",
            "LR: 8.86597069854421e-05\n",
            "Train loss: 0.5022302865982056\n",
            "\n",
            "Time (s): 0.6292190551757812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 470 / 499\n",
            "LR: 8.865952857612562e-05\n",
            "Train loss: 0.9978401064872742\n",
            "\n",
            "Time (s): 0.627845048904419\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 471 / 499\n",
            "LR: 8.865935016788618e-05\n",
            "Train loss: 1.2206730842590332\n",
            "\n",
            "Time (s): 0.6280977725982666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 472 / 499\n",
            "LR: 8.865917176072375e-05\n",
            "Train loss: 0.7593130469322205\n",
            "\n",
            "Time (s): 0.6290302276611328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 473 / 499\n",
            "LR: 8.865899335463831e-05\n",
            "Train loss: 0.7189943790435791\n",
            "\n",
            "Time (s): 0.6280219554901123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 474 / 499\n",
            "LR: 8.865881494962989e-05\n",
            "Train loss: 1.4327625036239624\n",
            "\n",
            "Time (s): 0.6289288997650146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 475 / 499\n",
            "LR: 8.865863654569845e-05\n",
            "Train loss: 0.9482460021972656\n",
            "\n",
            "Time (s): 0.6298198699951172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 476 / 499\n",
            "LR: 8.865845814284398e-05\n",
            "Train loss: 0.9866842031478882\n",
            "\n",
            "Time (s): 0.6291790008544922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 477 / 499\n",
            "LR: 8.86582797410665e-05\n",
            "Train loss: 0.7090967297554016\n",
            "\n",
            "Time (s): 0.629319429397583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 478 / 499\n",
            "LR: 8.865810134036595e-05\n",
            "Train loss: 0.6337783932685852\n",
            "\n",
            "Time (s): 0.6280195713043213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 479 / 499\n",
            "LR: 8.865792294074236e-05\n",
            "Train loss: 0.5094398856163025\n",
            "\n",
            "Time (s): 0.6289243698120117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 480 / 499\n",
            "LR: 8.86577445421957e-05\n",
            "Train loss: 0.6593319177627563\n",
            "\n",
            "Time (s): 0.6282086372375488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 481 / 499\n",
            "LR: 8.865756614472596e-05\n",
            "Train loss: 1.019332766532898\n",
            "\n",
            "Time (s): 0.628331184387207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 482 / 499\n",
            "LR: 8.865738774833313e-05\n",
            "Train loss: 0.5412815809249878\n",
            "\n",
            "Time (s): 0.628230094909668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 483 / 499\n",
            "LR: 8.865720935301721e-05\n",
            "Train loss: 0.7541049122810364\n",
            "\n",
            "Time (s): 0.6282494068145752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 484 / 499\n",
            "LR: 8.865703095877819e-05\n",
            "Train loss: 0.8222956657409668\n",
            "\n",
            "Time (s): 0.6324265003204346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 485 / 499\n",
            "LR: 8.865685256561602e-05\n",
            "Train loss: 1.19566011428833\n",
            "\n",
            "Time (s): 0.6313846111297607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 486 / 499\n",
            "LR: 8.865667417353074e-05\n",
            "Train loss: 1.1972414255142212\n",
            "\n",
            "Time (s): 0.6317391395568848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 487 / 499\n",
            "LR: 8.865649578252231e-05\n",
            "Train loss: 0.9379029273986816\n",
            "\n",
            "Time (s): 0.6294395923614502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 488 / 499\n",
            "LR: 8.865631739259072e-05\n",
            "Train loss: 0.812653124332428\n",
            "\n",
            "Time (s): 0.6272680759429932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 489 / 499\n",
            "LR: 8.865613900373597e-05\n",
            "Train loss: 1.0144264698028564\n",
            "\n",
            "Time (s): 0.628502607345581\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 490 / 499\n",
            "LR: 8.865596061595805e-05\n",
            "Train loss: 0.3362858295440674\n",
            "\n",
            "Time (s): 0.6236381530761719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 491 / 499\n",
            "LR: 8.865578222925695e-05\n",
            "Train loss: 0.6142602562904358\n",
            "\n",
            "Time (s): 0.6282882690429688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 492 / 499\n",
            "LR: 8.865560384363263e-05\n",
            "Train loss: 1.1422733068466187\n",
            "\n",
            "Time (s): 0.6289451122283936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 493 / 499\n",
            "LR: 8.865542545908513e-05\n",
            "Train loss: 1.1394054889678955\n",
            "\n",
            "Time (s): 0.6322934627532959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 494 / 499\n",
            "LR: 8.86552470756144e-05\n",
            "Train loss: 0.7659573554992676\n",
            "\n",
            "Time (s): 0.6301631927490234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 495 / 499\n",
            "LR: 8.865506869322045e-05\n",
            "Train loss: 0.9767875075340271\n",
            "\n",
            "Time (s): 0.6261906623840332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 496 / 499\n",
            "LR: 8.865489031190324e-05\n",
            "Train loss: 0.784947395324707\n",
            "\n",
            "Time (s): 0.62774658203125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 497 / 499\n",
            "LR: 8.86547119316628e-05\n",
            "Train loss: 1.070634126663208\n",
            "\n",
            "Time (s): 0.6311521530151367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 498 / 499\n",
            "LR: 8.86545335524991e-05\n",
            "Train loss: 1.2229129076004028\n",
            "\n",
            "Time (s): 0.6285736560821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 498  Batch 499 / 499\n",
            "LR: 8.865435517441212e-05\n",
            "Train loss: 0.10766922682523727\n",
            "\n",
            "Time (s): 0.053940534591674805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 498\n",
            "Avg train loss: 0.7027407597324892\n",
            "Avg train acc: 0.7918043031482276\n",
            "Avg eval loss: 0.9068396722569185\n",
            "Avg eval acc: 0.7551898430375492\n",
            "=========================\n",
            "\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 499\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 1 / 499\n",
            "LR: 8.865417679740184e-05\n",
            "Train loss: 0.49679580330848694\n",
            "\n",
            "Time (s): 0.6348967552185059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 2 / 499\n",
            "LR: 8.865399842146831e-05\n",
            "Train loss: 0.7032351493835449\n",
            "\n",
            "Time (s): 0.6319072246551514\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 3 / 499\n",
            "LR: 8.865382004661143e-05\n",
            "Train loss: 0.6001749038696289\n",
            "\n",
            "Time (s): 0.6393022537231445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 4 / 499\n",
            "LR: 8.865364167283126e-05\n",
            "Train loss: 0.6952637434005737\n",
            "\n",
            "Time (s): 0.6287844181060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 5 / 499\n",
            "LR: 8.865346330012776e-05\n",
            "Train loss: 0.4074620008468628\n",
            "\n",
            "Time (s): 0.63077712059021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 6 / 499\n",
            "LR: 8.865328492850093e-05\n",
            "Train loss: 0.7395089864730835\n",
            "\n",
            "Time (s): 0.6292603015899658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 7 / 499\n",
            "LR: 8.865310655795072e-05\n",
            "Train loss: 0.4282667338848114\n",
            "\n",
            "Time (s): 0.6298074722290039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 8 / 499\n",
            "LR: 8.865292818847717e-05\n",
            "Train loss: 1.0029261112213135\n",
            "\n",
            "Time (s): 0.6244938373565674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 9 / 499\n",
            "LR: 8.865274982008026e-05\n",
            "Train loss: 0.5559598207473755\n",
            "\n",
            "Time (s): 0.6300859451293945\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 10 / 499\n",
            "LR: 8.865257145275995e-05\n",
            "Train loss: 1.304314374923706\n",
            "\n",
            "Time (s): 0.6250133514404297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 11 / 499\n",
            "LR: 8.865239308651628e-05\n",
            "Train loss: 0.4215989410877228\n",
            "\n",
            "Time (s): 0.6298625469207764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 12 / 499\n",
            "LR: 8.865221472134917e-05\n",
            "Train loss: 0.9153090715408325\n",
            "\n",
            "Time (s): 0.6283667087554932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 13 / 499\n",
            "LR: 8.865203635725868e-05\n",
            "Train loss: 0.9606940746307373\n",
            "\n",
            "Time (s): 0.6285207271575928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 14 / 499\n",
            "LR: 8.865185799424475e-05\n",
            "Train loss: 1.0926811695098877\n",
            "\n",
            "Time (s): 0.6291160583496094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 15 / 499\n",
            "LR: 8.865167963230738e-05\n",
            "Train loss: 0.5298067331314087\n",
            "\n",
            "Time (s): 0.6283888816833496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 16 / 499\n",
            "LR: 8.865150127144658e-05\n",
            "Train loss: 1.113754391670227\n",
            "\n",
            "Time (s): 0.6283271312713623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 17 / 499\n",
            "LR: 8.86513229116623e-05\n",
            "Train loss: 0.8350223302841187\n",
            "\n",
            "Time (s): 0.6286282539367676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 18 / 499\n",
            "LR: 8.865114455295458e-05\n",
            "Train loss: 0.581046998500824\n",
            "\n",
            "Time (s): 0.6290373802185059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 19 / 499\n",
            "LR: 8.865096619532337e-05\n",
            "Train loss: 0.6210336685180664\n",
            "\n",
            "Time (s): 0.6314833164215088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 20 / 499\n",
            "LR: 8.865078783876867e-05\n",
            "Train loss: 0.6371652483940125\n",
            "\n",
            "Time (s): 0.6294689178466797\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 21 / 499\n",
            "LR: 8.865060948329047e-05\n",
            "Train loss: 0.668924868106842\n",
            "\n",
            "Time (s): 0.6254913806915283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 22 / 499\n",
            "LR: 8.865043112888876e-05\n",
            "Train loss: 0.9910566210746765\n",
            "\n",
            "Time (s): 0.6323575973510742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 23 / 499\n",
            "LR: 8.865025277556352e-05\n",
            "Train loss: 0.37202000617980957\n",
            "\n",
            "Time (s): 0.6293935775756836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 24 / 499\n",
            "LR: 8.865007442331476e-05\n",
            "Train loss: 0.728519856929779\n",
            "\n",
            "Time (s): 0.6292369365692139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 25 / 499\n",
            "LR: 8.864989607214246e-05\n",
            "Train loss: 0.8536667823791504\n",
            "\n",
            "Time (s): 0.6289043426513672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 26 / 499\n",
            "LR: 8.86497177220466e-05\n",
            "Train loss: 0.6712332963943481\n",
            "\n",
            "Time (s): 0.6272454261779785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 27 / 499\n",
            "LR: 8.864953937302717e-05\n",
            "Train loss: 1.0893529653549194\n",
            "\n",
            "Time (s): 0.6291911602020264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 28 / 499\n",
            "LR: 8.864936102508419e-05\n",
            "Train loss: 1.6835829019546509\n",
            "\n",
            "Time (s): 0.6254382133483887\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 29 / 499\n",
            "LR: 8.86491826782176e-05\n",
            "Train loss: 0.841073215007782\n",
            "\n",
            "Time (s): 0.6248135566711426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 30 / 499\n",
            "LR: 8.864900433242741e-05\n",
            "Train loss: 1.3226745128631592\n",
            "\n",
            "Time (s): 0.6293504238128662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 31 / 499\n",
            "LR: 8.864882598771362e-05\n",
            "Train loss: 0.7586614489555359\n",
            "\n",
            "Time (s): 0.6304323673248291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 32 / 499\n",
            "LR: 8.864864764407621e-05\n",
            "Train loss: 0.2839231789112091\n",
            "\n",
            "Time (s): 0.6276934146881104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 33 / 499\n",
            "LR: 8.864846930151518e-05\n",
            "Train loss: 1.1900825500488281\n",
            "\n",
            "Time (s): 0.6239619255065918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 34 / 499\n",
            "LR: 8.864829096003049e-05\n",
            "Train loss: 1.460541844367981\n",
            "\n",
            "Time (s): 0.6240818500518799\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 35 / 499\n",
            "LR: 8.864811261962217e-05\n",
            "Train loss: 0.4679096043109894\n",
            "\n",
            "Time (s): 0.6283729076385498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 36 / 499\n",
            "LR: 8.864793428029017e-05\n",
            "Train loss: 0.5326775908470154\n",
            "\n",
            "Time (s): 0.6242406368255615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 37 / 499\n",
            "LR: 8.86477559420345e-05\n",
            "Train loss: 0.4526669979095459\n",
            "\n",
            "Time (s): 0.629138708114624\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 38 / 499\n",
            "LR: 8.864757760485516e-05\n",
            "Train loss: 0.7937238812446594\n",
            "\n",
            "Time (s): 0.624131441116333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 39 / 499\n",
            "LR: 8.864739926875211e-05\n",
            "Train loss: 0.5873818397521973\n",
            "\n",
            "Time (s): 0.6293601989746094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 40 / 499\n",
            "LR: 8.864722093372537e-05\n",
            "Train loss: 0.6155707240104675\n",
            "\n",
            "Time (s): 0.6244895458221436\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 41 / 499\n",
            "LR: 8.864704259977491e-05\n",
            "Train loss: 0.7030277848243713\n",
            "\n",
            "Time (s): 0.628375768661499\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 42 / 499\n",
            "LR: 8.864686426690071e-05\n",
            "Train loss: 0.710106611251831\n",
            "\n",
            "Time (s): 0.6236355304718018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 43 / 499\n",
            "LR: 8.864668593510278e-05\n",
            "Train loss: 0.4062335789203644\n",
            "\n",
            "Time (s): 0.629767894744873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 44 / 499\n",
            "LR: 8.86465076043811e-05\n",
            "Train loss: 0.9417285919189453\n",
            "\n",
            "Time (s): 0.6283173561096191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 45 / 499\n",
            "LR: 8.864632927473567e-05\n",
            "Train loss: 0.7333642244338989\n",
            "\n",
            "Time (s): 0.6239807605743408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 46 / 499\n",
            "LR: 8.864615094616645e-05\n",
            "Train loss: 0.8703615069389343\n",
            "\n",
            "Time (s): 0.6283929347991943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 47 / 499\n",
            "LR: 8.864597261867347e-05\n",
            "Train loss: 1.0893874168395996\n",
            "\n",
            "Time (s): 0.6238846778869629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 48 / 499\n",
            "LR: 8.864579429225667e-05\n",
            "Train loss: 0.9973929524421692\n",
            "\n",
            "Time (s): 0.6240572929382324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 49 / 499\n",
            "LR: 8.864561596691611e-05\n",
            "Train loss: 0.4894924759864807\n",
            "\n",
            "Time (s): 0.6294717788696289\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 50 / 499\n",
            "LR: 8.864543764265171e-05\n",
            "Train loss: 0.8797686696052551\n",
            "\n",
            "Time (s): 0.624312162399292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 51 / 499\n",
            "LR: 8.864525931946347e-05\n",
            "Train loss: 0.6295084953308105\n",
            "\n",
            "Time (s): 0.6292703151702881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 52 / 499\n",
            "LR: 8.864508099735143e-05\n",
            "Train loss: 1.240652084350586\n",
            "\n",
            "Time (s): 0.625314474105835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 53 / 499\n",
            "LR: 8.86449026763155e-05\n",
            "Train loss: 0.9011485576629639\n",
            "\n",
            "Time (s): 0.6279728412628174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 54 / 499\n",
            "LR: 8.864472435635577e-05\n",
            "Train loss: 0.9975969791412354\n",
            "\n",
            "Time (s): 0.6280531883239746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 55 / 499\n",
            "LR: 8.864454603747213e-05\n",
            "Train loss: 0.8547925353050232\n",
            "\n",
            "Time (s): 0.6266508102416992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 56 / 499\n",
            "LR: 8.864436771966463e-05\n",
            "Train loss: 0.6535160541534424\n",
            "\n",
            "Time (s): 0.6287803649902344\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 57 / 499\n",
            "LR: 8.864418940293324e-05\n",
            "Train loss: 1.0444602966308594\n",
            "\n",
            "Time (s): 0.628394365310669\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 58 / 499\n",
            "LR: 8.864401108727793e-05\n",
            "Train loss: 0.8538148403167725\n",
            "\n",
            "Time (s): 0.6318354606628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 59 / 499\n",
            "LR: 8.864383277269873e-05\n",
            "Train loss: 1.0157688856124878\n",
            "\n",
            "Time (s): 0.6294717788696289\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 60 / 499\n",
            "LR: 8.86436544591956e-05\n",
            "Train loss: 0.8569476008415222\n",
            "\n",
            "Time (s): 0.6291191577911377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 61 / 499\n",
            "LR: 8.864347614676854e-05\n",
            "Train loss: 0.7173236608505249\n",
            "\n",
            "Time (s): 0.6300671100616455\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 62 / 499\n",
            "LR: 8.864329783541753e-05\n",
            "Train loss: 0.8228768110275269\n",
            "\n",
            "Time (s): 0.628173828125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 63 / 499\n",
            "LR: 8.864311952514258e-05\n",
            "Train loss: 1.1195969581604004\n",
            "\n",
            "Time (s): 0.628908634185791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 64 / 499\n",
            "LR: 8.864294121594364e-05\n",
            "Train loss: 0.6891685128211975\n",
            "\n",
            "Time (s): 0.6276583671569824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 65 / 499\n",
            "LR: 8.864276290782073e-05\n",
            "Train loss: 1.2242780923843384\n",
            "\n",
            "Time (s): 0.629831075668335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 66 / 499\n",
            "LR: 8.864258460077387e-05\n",
            "Train loss: 0.6712656021118164\n",
            "\n",
            "Time (s): 0.6286225318908691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 67 / 499\n",
            "LR: 8.864240629480297e-05\n",
            "Train loss: 0.6732478141784668\n",
            "\n",
            "Time (s): 0.6245954036712646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 68 / 499\n",
            "LR: 8.864222798990808e-05\n",
            "Train loss: 1.4450584650039673\n",
            "\n",
            "Time (s): 0.6292529106140137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 69 / 499\n",
            "LR: 8.864204968608916e-05\n",
            "Train loss: 1.4428917169570923\n",
            "\n",
            "Time (s): 0.6289713382720947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 70 / 499\n",
            "LR: 8.864187138334622e-05\n",
            "Train loss: 0.8892422318458557\n",
            "\n",
            "Time (s): 0.6316680908203125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 71 / 499\n",
            "LR: 8.864169308167923e-05\n",
            "Train loss: 0.816596508026123\n",
            "\n",
            "Time (s): 0.6285789012908936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 72 / 499\n",
            "LR: 8.86415147810882e-05\n",
            "Train loss: 0.864656388759613\n",
            "\n",
            "Time (s): 0.6301631927490234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 73 / 499\n",
            "LR: 8.864133648157311e-05\n",
            "Train loss: 0.6769483685493469\n",
            "\n",
            "Time (s): 0.6295194625854492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 74 / 499\n",
            "LR: 8.864115818313393e-05\n",
            "Train loss: 0.5642306208610535\n",
            "\n",
            "Time (s): 0.6317141056060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 75 / 499\n",
            "LR: 8.864097988577067e-05\n",
            "Train loss: 0.8356671333312988\n",
            "\n",
            "Time (s): 0.6297271251678467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 76 / 499\n",
            "LR: 8.864080158948334e-05\n",
            "Train loss: 0.7446740865707397\n",
            "\n",
            "Time (s): 0.6303243637084961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 77 / 499\n",
            "LR: 8.864062329427187e-05\n",
            "Train loss: 0.753716766834259\n",
            "\n",
            "Time (s): 0.628800630569458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 78 / 499\n",
            "LR: 8.86404450001363e-05\n",
            "Train loss: 0.9504634141921997\n",
            "\n",
            "Time (s): 0.6306910514831543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 79 / 499\n",
            "LR: 8.86402667070766e-05\n",
            "Train loss: 0.7741015553474426\n",
            "\n",
            "Time (s): 0.6284666061401367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 80 / 499\n",
            "LR: 8.864008841509277e-05\n",
            "Train loss: 1.1264874935150146\n",
            "\n",
            "Time (s): 0.6305263042449951\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 81 / 499\n",
            "LR: 8.863991012418477e-05\n",
            "Train loss: 0.5020335912704468\n",
            "\n",
            "Time (s): 0.6278481483459473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 82 / 499\n",
            "LR: 8.863973183435264e-05\n",
            "Train loss: 1.154617428779602\n",
            "\n",
            "Time (s): 0.6290781497955322\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 83 / 499\n",
            "LR: 8.86395535455963e-05\n",
            "Train loss: 0.8642482161521912\n",
            "\n",
            "Time (s): 0.6290769577026367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 84 / 499\n",
            "LR: 8.863937525791582e-05\n",
            "Train loss: 0.5160733461380005\n",
            "\n",
            "Time (s): 0.6290850639343262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 85 / 499\n",
            "LR: 8.863919697131113e-05\n",
            "Train loss: 1.2399349212646484\n",
            "\n",
            "Time (s): 0.6289267539978027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 86 / 499\n",
            "LR: 8.863901868578221e-05\n",
            "Train loss: 0.8968123197555542\n",
            "\n",
            "Time (s): 0.6287844181060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 87 / 499\n",
            "LR: 8.863884040132911e-05\n",
            "Train loss: 1.216822862625122\n",
            "\n",
            "Time (s): 0.6292915344238281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 88 / 499\n",
            "LR: 8.863866211795179e-05\n",
            "Train loss: 0.7249997854232788\n",
            "\n",
            "Time (s): 0.6291933059692383\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 89 / 499\n",
            "LR: 8.863848383565022e-05\n",
            "Train loss: 0.7412038445472717\n",
            "\n",
            "Time (s): 0.6290309429168701\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 90 / 499\n",
            "LR: 8.863830555442439e-05\n",
            "Train loss: 1.2210862636566162\n",
            "\n",
            "Time (s): 0.6295716762542725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 91 / 499\n",
            "LR: 8.863812727427432e-05\n",
            "Train loss: 0.8334859013557434\n",
            "\n",
            "Time (s): 0.6289534568786621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 92 / 499\n",
            "LR: 8.863794899519998e-05\n",
            "Train loss: 0.9561343789100647\n",
            "\n",
            "Time (s): 0.6295976638793945\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 93 / 499\n",
            "LR: 8.863777071720136e-05\n",
            "Train loss: 0.38107189536094666\n",
            "\n",
            "Time (s): 0.6298565864562988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 94 / 499\n",
            "LR: 8.863759244027843e-05\n",
            "Train loss: 0.8380776047706604\n",
            "\n",
            "Time (s): 0.6297445297241211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 95 / 499\n",
            "LR: 8.863741416443122e-05\n",
            "Train loss: 0.9064483642578125\n",
            "\n",
            "Time (s): 0.6298279762268066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 96 / 499\n",
            "LR: 8.86372358896597e-05\n",
            "Train loss: 1.3804025650024414\n",
            "\n",
            "Time (s): 0.6288852691650391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 97 / 499\n",
            "LR: 8.863705761596388e-05\n",
            "Train loss: 0.701987624168396\n",
            "\n",
            "Time (s): 0.6284945011138916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 98 / 499\n",
            "LR: 8.863687934334369e-05\n",
            "Train loss: 1.533000111579895\n",
            "\n",
            "Time (s): 0.6284425258636475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 99 / 499\n",
            "LR: 8.863670107179918e-05\n",
            "Train loss: 0.5204789042472839\n",
            "\n",
            "Time (s): 0.6302695274353027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 100 / 499\n",
            "LR: 8.863652280133029e-05\n",
            "Train loss: 1.2591322660446167\n",
            "\n",
            "Time (s): 0.6291120052337646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 101 / 499\n",
            "LR: 8.863634453193705e-05\n",
            "Train loss: 1.2069756984710693\n",
            "\n",
            "Time (s): 0.6292264461517334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 102 / 499\n",
            "LR: 8.863616626361942e-05\n",
            "Train loss: 0.5254553556442261\n",
            "\n",
            "Time (s): 0.631195068359375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 103 / 499\n",
            "LR: 8.863598799637743e-05\n",
            "Train loss: 0.6999316215515137\n",
            "\n",
            "Time (s): 0.6285297870635986\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 104 / 499\n",
            "LR: 8.863580973021102e-05\n",
            "Train loss: 0.5802318453788757\n",
            "\n",
            "Time (s): 0.6293485164642334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 105 / 499\n",
            "LR: 8.863563146512022e-05\n",
            "Train loss: 0.32579144835472107\n",
            "\n",
            "Time (s): 0.6295416355133057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 106 / 499\n",
            "LR: 8.863545320110497e-05\n",
            "Train loss: 1.2117502689361572\n",
            "\n",
            "Time (s): 0.6277031898498535\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 107 / 499\n",
            "LR: 8.863527493816533e-05\n",
            "Train loss: 0.6170908212661743\n",
            "\n",
            "Time (s): 0.6281366348266602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 108 / 499\n",
            "LR: 8.863509667630121e-05\n",
            "Train loss: 0.5547656416893005\n",
            "\n",
            "Time (s): 0.6332244873046875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 109 / 499\n",
            "LR: 8.863491841551266e-05\n",
            "Train loss: 1.0387904644012451\n",
            "\n",
            "Time (s): 0.6299333572387695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 110 / 499\n",
            "LR: 8.863474015579964e-05\n",
            "Train loss: 0.48796263337135315\n",
            "\n",
            "Time (s): 0.6289644241333008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 111 / 499\n",
            "LR: 8.863456189716216e-05\n",
            "Train loss: 0.7592144012451172\n",
            "\n",
            "Time (s): 0.624537467956543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 112 / 499\n",
            "LR: 8.863438363960018e-05\n",
            "Train loss: 0.5261509418487549\n",
            "\n",
            "Time (s): 0.6285927295684814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 113 / 499\n",
            "LR: 8.86342053831137e-05\n",
            "Train loss: 0.7105585932731628\n",
            "\n",
            "Time (s): 0.6289780139923096\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 114 / 499\n",
            "LR: 8.863402712770272e-05\n",
            "Train loss: 0.30566853284835815\n",
            "\n",
            "Time (s): 0.6247508525848389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 115 / 499\n",
            "LR: 8.863384887336723e-05\n",
            "Train loss: 0.7835732102394104\n",
            "\n",
            "Time (s): 0.628145694732666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 116 / 499\n",
            "LR: 8.86336706201072e-05\n",
            "Train loss: 0.49668851494789124\n",
            "\n",
            "Time (s): 0.629652738571167\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 117 / 499\n",
            "LR: 8.863349236792265e-05\n",
            "Train loss: 0.4680632948875427\n",
            "\n",
            "Time (s): 0.6307446956634521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 118 / 499\n",
            "LR: 8.863331411681354e-05\n",
            "Train loss: 0.7695508599281311\n",
            "\n",
            "Time (s): 0.6290228366851807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 119 / 499\n",
            "LR: 8.863313586677987e-05\n",
            "Train loss: 0.47890788316726685\n",
            "\n",
            "Time (s): 0.6287095546722412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 120 / 499\n",
            "LR: 8.863295761782164e-05\n",
            "Train loss: 0.7886158227920532\n",
            "\n",
            "Time (s): 0.6292545795440674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 121 / 499\n",
            "LR: 8.863277936993881e-05\n",
            "Train loss: 0.3995496332645416\n",
            "\n",
            "Time (s): 0.628854513168335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 122 / 499\n",
            "LR: 8.863260112313139e-05\n",
            "Train loss: 1.5023083686828613\n",
            "\n",
            "Time (s): 0.6296935081481934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 123 / 499\n",
            "LR: 8.863242287739939e-05\n",
            "Train loss: 1.051151990890503\n",
            "\n",
            "Time (s): 0.629058837890625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 124 / 499\n",
            "LR: 8.863224463274275e-05\n",
            "Train loss: 1.1613967418670654\n",
            "\n",
            "Time (s): 0.628385066986084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 125 / 499\n",
            "LR: 8.863206638916149e-05\n",
            "Train loss: 0.36376625299453735\n",
            "\n",
            "Time (s): 0.6284711360931396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 126 / 499\n",
            "LR: 8.86318881466556e-05\n",
            "Train loss: 0.5695965886116028\n",
            "\n",
            "Time (s): 0.6286635398864746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 127 / 499\n",
            "LR: 8.863170990522506e-05\n",
            "Train loss: 0.5762548446655273\n",
            "\n",
            "Time (s): 0.6291687488555908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 128 / 499\n",
            "LR: 8.863153166486986e-05\n",
            "Train loss: 1.1967853307724\n",
            "\n",
            "Time (s): 0.6290872097015381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 129 / 499\n",
            "LR: 8.863135342558998e-05\n",
            "Train loss: 0.9057070016860962\n",
            "\n",
            "Time (s): 0.6287209987640381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 130 / 499\n",
            "LR: 8.863117518738544e-05\n",
            "Train loss: 0.4159614145755768\n",
            "\n",
            "Time (s): 0.6282298564910889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 131 / 499\n",
            "LR: 8.86309969502562e-05\n",
            "Train loss: 0.7864862680435181\n",
            "\n",
            "Time (s): 0.6294405460357666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 132 / 499\n",
            "LR: 8.863081871420226e-05\n",
            "Train loss: 0.6466714143753052\n",
            "\n",
            "Time (s): 0.6290719509124756\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 133 / 499\n",
            "LR: 8.863064047922362e-05\n",
            "Train loss: 0.9305511713027954\n",
            "\n",
            "Time (s): 0.631403923034668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 134 / 499\n",
            "LR: 8.863046224532026e-05\n",
            "Train loss: 0.5106533765792847\n",
            "\n",
            "Time (s): 0.6289300918579102\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 135 / 499\n",
            "LR: 8.863028401249216e-05\n",
            "Train loss: 1.0932637453079224\n",
            "\n",
            "Time (s): 0.6283245086669922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 136 / 499\n",
            "LR: 8.863010578073931e-05\n",
            "Train loss: 0.43137863278388977\n",
            "\n",
            "Time (s): 0.6299309730529785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 137 / 499\n",
            "LR: 8.862992755006171e-05\n",
            "Train loss: 1.2526872158050537\n",
            "\n",
            "Time (s): 0.6282570362091064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 138 / 499\n",
            "LR: 8.862974932045934e-05\n",
            "Train loss: 0.9756838083267212\n",
            "\n",
            "Time (s): 0.6281917095184326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 139 / 499\n",
            "LR: 8.86295710919322e-05\n",
            "Train loss: 0.6747139692306519\n",
            "\n",
            "Time (s): 0.6285722255706787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 140 / 499\n",
            "LR: 8.862939286448027e-05\n",
            "Train loss: 0.9161204695701599\n",
            "\n",
            "Time (s): 0.6290695667266846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 141 / 499\n",
            "LR: 8.862921463810355e-05\n",
            "Train loss: 1.093921422958374\n",
            "\n",
            "Time (s): 0.6296238899230957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 142 / 499\n",
            "LR: 8.8629036412802e-05\n",
            "Train loss: 1.3664709329605103\n",
            "\n",
            "Time (s): 0.6295843124389648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 143 / 499\n",
            "LR: 8.862885818857566e-05\n",
            "Train loss: 0.7079080939292908\n",
            "\n",
            "Time (s): 0.6292200088500977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 144 / 499\n",
            "LR: 8.862867996542447e-05\n",
            "Train loss: 0.9641202688217163\n",
            "\n",
            "Time (s): 0.6276051998138428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 145 / 499\n",
            "LR: 8.862850174334844e-05\n",
            "Train loss: 0.5508951544761658\n",
            "\n",
            "Time (s): 0.6295945644378662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 146 / 499\n",
            "LR: 8.862832352234755e-05\n",
            "Train loss: 1.181416392326355\n",
            "\n",
            "Time (s): 0.6294147968292236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 147 / 499\n",
            "LR: 8.86281453024218e-05\n",
            "Train loss: 1.0825594663619995\n",
            "\n",
            "Time (s): 0.6299912929534912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 148 / 499\n",
            "LR: 8.862796708357119e-05\n",
            "Train loss: 0.5634858012199402\n",
            "\n",
            "Time (s): 0.6290130615234375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 149 / 499\n",
            "LR: 8.862778886579569e-05\n",
            "Train loss: 0.9191612005233765\n",
            "\n",
            "Time (s): 0.6278769969940186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 150 / 499\n",
            "LR: 8.862761064909529e-05\n",
            "Train loss: 1.140458583831787\n",
            "\n",
            "Time (s): 0.6275217533111572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 151 / 499\n",
            "LR: 8.862743243346999e-05\n",
            "Train loss: 1.1361212730407715\n",
            "\n",
            "Time (s): 0.6290123462677002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 152 / 499\n",
            "LR: 8.862725421891976e-05\n",
            "Train loss: 1.1246341466903687\n",
            "\n",
            "Time (s): 0.6285254955291748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 153 / 499\n",
            "LR: 8.862707600544462e-05\n",
            "Train loss: 0.8760802745819092\n",
            "\n",
            "Time (s): 0.6284725666046143\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 154 / 499\n",
            "LR: 8.862689779304454e-05\n",
            "Train loss: 0.6896505355834961\n",
            "\n",
            "Time (s): 0.6240832805633545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 155 / 499\n",
            "LR: 8.862671958171949e-05\n",
            "Train loss: 0.657948911190033\n",
            "\n",
            "Time (s): 0.6283872127532959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 156 / 499\n",
            "LR: 8.86265413714695e-05\n",
            "Train loss: 0.9162390232086182\n",
            "\n",
            "Time (s): 0.6237895488739014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 157 / 499\n",
            "LR: 8.862636316229454e-05\n",
            "Train loss: 1.1563928127288818\n",
            "\n",
            "Time (s): 0.629279375076294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 158 / 499\n",
            "LR: 8.86261849541946e-05\n",
            "Train loss: 0.6019096374511719\n",
            "\n",
            "Time (s): 0.6276323795318604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 159 / 499\n",
            "LR: 8.862600674716965e-05\n",
            "Train loss: 1.071118950843811\n",
            "\n",
            "Time (s): 0.6243619918823242\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 160 / 499\n",
            "LR: 8.862582854121971e-05\n",
            "Train loss: 0.6908490657806396\n",
            "\n",
            "Time (s): 0.6289355754852295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 161 / 499\n",
            "LR: 8.862565033634473e-05\n",
            "Train loss: 0.45439574122428894\n",
            "\n",
            "Time (s): 0.6240940093994141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 162 / 499\n",
            "LR: 8.862547213254474e-05\n",
            "Train loss: 0.9475656151771545\n",
            "\n",
            "Time (s): 0.6292016506195068\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 163 / 499\n",
            "LR: 8.862529392981973e-05\n",
            "Train loss: 0.40441420674324036\n",
            "\n",
            "Time (s): 0.6278493404388428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 164 / 499\n",
            "LR: 8.862511572816967e-05\n",
            "Train loss: 0.9137005805969238\n",
            "\n",
            "Time (s): 0.6237320899963379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 165 / 499\n",
            "LR: 8.862493752759454e-05\n",
            "Train loss: 1.3885530233383179\n",
            "\n",
            "Time (s): 0.6294827461242676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 166 / 499\n",
            "LR: 8.862475932809435e-05\n",
            "Train loss: 0.9134717583656311\n",
            "\n",
            "Time (s): 0.6280982494354248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 167 / 499\n",
            "LR: 8.862458112966908e-05\n",
            "Train loss: 1.2005010843276978\n",
            "\n",
            "Time (s): 0.629047155380249\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 168 / 499\n",
            "LR: 8.862440293231873e-05\n",
            "Train loss: 0.5195726752281189\n",
            "\n",
            "Time (s): 0.6286759376525879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 169 / 499\n",
            "LR: 8.862422473604326e-05\n",
            "Train loss: 1.5124223232269287\n",
            "\n",
            "Time (s): 0.6238267421722412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 170 / 499\n",
            "LR: 8.862404654084268e-05\n",
            "Train loss: 1.1006391048431396\n",
            "\n",
            "Time (s): 0.6285429000854492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 171 / 499\n",
            "LR: 8.8623868346717e-05\n",
            "Train loss: 0.5808149576187134\n",
            "\n",
            "Time (s): 0.6297183036804199\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 172 / 499\n",
            "LR: 8.862369015366617e-05\n",
            "Train loss: 0.3627326488494873\n",
            "\n",
            "Time (s): 0.6286602020263672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 173 / 499\n",
            "LR: 8.86235119616902e-05\n",
            "Train loss: 1.2527015209197998\n",
            "\n",
            "Time (s): 0.6294653415679932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 174 / 499\n",
            "LR: 8.862333377078906e-05\n",
            "Train loss: 0.6994991898536682\n",
            "\n",
            "Time (s): 0.6290454864501953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 175 / 499\n",
            "LR: 8.862315558096277e-05\n",
            "Train loss: 0.9978950023651123\n",
            "\n",
            "Time (s): 0.6294901371002197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 176 / 499\n",
            "LR: 8.86229773922113e-05\n",
            "Train loss: 0.6643955111503601\n",
            "\n",
            "Time (s): 0.6281805038452148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 177 / 499\n",
            "LR: 8.862279920453464e-05\n",
            "Train loss: 0.7792877554893494\n",
            "\n",
            "Time (s): 0.6258509159088135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 178 / 499\n",
            "LR: 8.862262101793279e-05\n",
            "Train loss: 0.7052320837974548\n",
            "\n",
            "Time (s): 0.6270942687988281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 179 / 499\n",
            "LR: 8.862244283240573e-05\n",
            "Train loss: 0.5863969922065735\n",
            "\n",
            "Time (s): 0.6282978057861328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 180 / 499\n",
            "LR: 8.862226464795345e-05\n",
            "Train loss: 0.7923299074172974\n",
            "\n",
            "Time (s): 0.6261281967163086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 181 / 499\n",
            "LR: 8.862208646457593e-05\n",
            "Train loss: 0.41171613335609436\n",
            "\n",
            "Time (s): 0.6284098625183105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 182 / 499\n",
            "LR: 8.862190828227318e-05\n",
            "Train loss: 0.6700151562690735\n",
            "\n",
            "Time (s): 0.625420331954956\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 183 / 499\n",
            "LR: 8.862173010104518e-05\n",
            "Train loss: 0.5218409299850464\n",
            "\n",
            "Time (s): 0.6283571720123291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 184 / 499\n",
            "LR: 8.862155192089191e-05\n",
            "Train loss: 0.8842480182647705\n",
            "\n",
            "Time (s): 0.6286814212799072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 185 / 499\n",
            "LR: 8.862137374181338e-05\n",
            "Train loss: 0.7104616165161133\n",
            "\n",
            "Time (s): 0.62406325340271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 186 / 499\n",
            "LR: 8.862119556380955e-05\n",
            "Train loss: 0.5229256749153137\n",
            "\n",
            "Time (s): 0.6238861083984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 187 / 499\n",
            "LR: 8.862101738688042e-05\n",
            "Train loss: 0.8579162359237671\n",
            "\n",
            "Time (s): 0.6288506984710693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 188 / 499\n",
            "LR: 8.8620839211026e-05\n",
            "Train loss: 0.8575109839439392\n",
            "\n",
            "Time (s): 0.6234984397888184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 189 / 499\n",
            "LR: 8.862066103624625e-05\n",
            "Train loss: 0.9722558259963989\n",
            "\n",
            "Time (s): 0.6283619403839111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 190 / 499\n",
            "LR: 8.862048286254119e-05\n",
            "Train loss: 0.5045624375343323\n",
            "\n",
            "Time (s): 0.6293120384216309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 191 / 499\n",
            "LR: 8.862030468991078e-05\n",
            "Train loss: 1.4637242555618286\n",
            "\n",
            "Time (s): 0.6245236396789551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 192 / 499\n",
            "LR: 8.862012651835503e-05\n",
            "Train loss: 0.8819077610969543\n",
            "\n",
            "Time (s): 0.628697395324707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 193 / 499\n",
            "LR: 8.861994834787389e-05\n",
            "Train loss: 0.998394787311554\n",
            "\n",
            "Time (s): 0.6286110877990723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 194 / 499\n",
            "LR: 8.86197701784674e-05\n",
            "Train loss: 0.9893066883087158\n",
            "\n",
            "Time (s): 0.6308057308197021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 195 / 499\n",
            "LR: 8.861959201013555e-05\n",
            "Train loss: 0.4253424406051636\n",
            "\n",
            "Time (s): 0.6293368339538574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 196 / 499\n",
            "LR: 8.861941384287827e-05\n",
            "Train loss: 1.0806931257247925\n",
            "\n",
            "Time (s): 0.6291272640228271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 197 / 499\n",
            "LR: 8.861923567669559e-05\n",
            "Train loss: 0.5025745034217834\n",
            "\n",
            "Time (s): 0.6291422843933105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 198 / 499\n",
            "LR: 8.861905751158753e-05\n",
            "Train loss: 0.7201561331748962\n",
            "\n",
            "Time (s): 0.630211353302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 199 / 499\n",
            "LR: 8.861887934755401e-05\n",
            "Train loss: 0.8039638996124268\n",
            "\n",
            "Time (s): 0.62998366355896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 200 / 499\n",
            "LR: 8.861870118459508e-05\n",
            "Train loss: 0.6792348623275757\n",
            "\n",
            "Time (s): 0.6299188137054443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 201 / 499\n",
            "LR: 8.861852302271068e-05\n",
            "Train loss: 0.8514420390129089\n",
            "\n",
            "Time (s): 0.6297025680541992\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 202 / 499\n",
            "LR: 8.861834486190083e-05\n",
            "Train loss: 0.3853810727596283\n",
            "\n",
            "Time (s): 0.6303937435150146\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 203 / 499\n",
            "LR: 8.861816670216554e-05\n",
            "Train loss: 1.1234562397003174\n",
            "\n",
            "Time (s): 0.6312525272369385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 204 / 499\n",
            "LR: 8.861798854350474e-05\n",
            "Train loss: 0.415193647146225\n",
            "\n",
            "Time (s): 0.6306192874908447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 205 / 499\n",
            "LR: 8.861781038591845e-05\n",
            "Train loss: 1.1218737363815308\n",
            "\n",
            "Time (s): 0.6303062438964844\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 206 / 499\n",
            "LR: 8.861763222940668e-05\n",
            "Train loss: 0.9151521325111389\n",
            "\n",
            "Time (s): 0.6302235126495361\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 207 / 499\n",
            "LR: 8.861745407396939e-05\n",
            "Train loss: 0.369965136051178\n",
            "\n",
            "Time (s): 0.6293745040893555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 208 / 499\n",
            "LR: 8.861727591960656e-05\n",
            "Train loss: 1.3906941413879395\n",
            "\n",
            "Time (s): 0.6303219795227051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 209 / 499\n",
            "LR: 8.861709776631823e-05\n",
            "Train loss: 0.8743323683738708\n",
            "\n",
            "Time (s): 0.6287953853607178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 210 / 499\n",
            "LR: 8.861691961410434e-05\n",
            "Train loss: 0.9930968880653381\n",
            "\n",
            "Time (s): 0.6296861171722412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 211 / 499\n",
            "LR: 8.86167414629649e-05\n",
            "Train loss: 0.25679877400398254\n",
            "\n",
            "Time (s): 0.6290445327758789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 212 / 499\n",
            "LR: 8.861656331289987e-05\n",
            "Train loss: 1.1031206846237183\n",
            "\n",
            "Time (s): 0.6287801265716553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 213 / 499\n",
            "LR: 8.86163851639093e-05\n",
            "Train loss: 0.9317877888679504\n",
            "\n",
            "Time (s): 0.6299338340759277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 214 / 499\n",
            "LR: 8.861620701599311e-05\n",
            "Train loss: 1.016303539276123\n",
            "\n",
            "Time (s): 0.6299290657043457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 215 / 499\n",
            "LR: 8.861602886915135e-05\n",
            "Train loss: 0.9116753935813904\n",
            "\n",
            "Time (s): 0.6300938129425049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 216 / 499\n",
            "LR: 8.861585072338397e-05\n",
            "Train loss: 1.0284035205841064\n",
            "\n",
            "Time (s): 0.6295669078826904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 217 / 499\n",
            "LR: 8.861567257869096e-05\n",
            "Train loss: 0.6257779002189636\n",
            "\n",
            "Time (s): 0.6297652721405029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 218 / 499\n",
            "LR: 8.861549443507234e-05\n",
            "Train loss: 0.7860409021377563\n",
            "\n",
            "Time (s): 0.630239725112915\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 219 / 499\n",
            "LR: 8.861531629252808e-05\n",
            "Train loss: 0.8780354261398315\n",
            "\n",
            "Time (s): 0.6303110122680664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 220 / 499\n",
            "LR: 8.861513815105816e-05\n",
            "Train loss: 0.6202175617218018\n",
            "\n",
            "Time (s): 0.62935471534729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 221 / 499\n",
            "LR: 8.861496001066257e-05\n",
            "Train loss: 1.0679782629013062\n",
            "\n",
            "Time (s): 0.6300206184387207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 222 / 499\n",
            "LR: 8.861478187134131e-05\n",
            "Train loss: 1.110520601272583\n",
            "\n",
            "Time (s): 0.6292037963867188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 223 / 499\n",
            "LR: 8.861460373309436e-05\n",
            "Train loss: 0.9151362180709839\n",
            "\n",
            "Time (s): 0.6285872459411621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 224 / 499\n",
            "LR: 8.861442559592173e-05\n",
            "Train loss: 0.29608890414237976\n",
            "\n",
            "Time (s): 0.6288635730743408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 225 / 499\n",
            "LR: 8.86142474598234e-05\n",
            "Train loss: 0.6374606490135193\n",
            "\n",
            "Time (s): 0.6295900344848633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 226 / 499\n",
            "LR: 8.861406932479933e-05\n",
            "Train loss: 0.7024965882301331\n",
            "\n",
            "Time (s): 0.6294553279876709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 227 / 499\n",
            "LR: 8.861389119084955e-05\n",
            "Train loss: 1.5438802242279053\n",
            "\n",
            "Time (s): 0.6295671463012695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 228 / 499\n",
            "LR: 8.861371305797402e-05\n",
            "Train loss: 0.7005395293235779\n",
            "\n",
            "Time (s): 0.6287219524383545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 229 / 499\n",
            "LR: 8.861353492617276e-05\n",
            "Train loss: 0.2827315330505371\n",
            "\n",
            "Time (s): 0.6290493011474609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 230 / 499\n",
            "LR: 8.861335679544573e-05\n",
            "Train loss: 0.6230131387710571\n",
            "\n",
            "Time (s): 0.630333662033081\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 231 / 499\n",
            "LR: 8.861317866579292e-05\n",
            "Train loss: 0.7455950975418091\n",
            "\n",
            "Time (s): 0.6300175189971924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 232 / 499\n",
            "LR: 8.861300053721434e-05\n",
            "Train loss: 1.0784310102462769\n",
            "\n",
            "Time (s): 0.6292071342468262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 233 / 499\n",
            "LR: 8.861282240970997e-05\n",
            "Train loss: 1.4334439039230347\n",
            "\n",
            "Time (s): 0.6296992301940918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 234 / 499\n",
            "LR: 8.861264428327979e-05\n",
            "Train loss: 1.0998858213424683\n",
            "\n",
            "Time (s): 0.6304445266723633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 235 / 499\n",
            "LR: 8.86124661579238e-05\n",
            "Train loss: 0.9576472640037537\n",
            "\n",
            "Time (s): 0.6289887428283691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 236 / 499\n",
            "LR: 8.861228803364199e-05\n",
            "Train loss: 0.7353816628456116\n",
            "\n",
            "Time (s): 0.6295754909515381\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 237 / 499\n",
            "LR: 8.861210991043434e-05\n",
            "Train loss: 0.9406459331512451\n",
            "\n",
            "Time (s): 0.6305410861968994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 238 / 499\n",
            "LR: 8.861193178830084e-05\n",
            "Train loss: 0.6895831823348999\n",
            "\n",
            "Time (s): 0.6291420459747314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 239 / 499\n",
            "LR: 8.86117536672415e-05\n",
            "Train loss: 1.069546103477478\n",
            "\n",
            "Time (s): 0.6301074028015137\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 240 / 499\n",
            "LR: 8.861157554725625e-05\n",
            "Train loss: 0.37150755524635315\n",
            "\n",
            "Time (s): 0.6296727657318115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 241 / 499\n",
            "LR: 8.861139742834517e-05\n",
            "Train loss: 1.5158333778381348\n",
            "\n",
            "Time (s): 0.6285390853881836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 242 / 499\n",
            "LR: 8.861121931050819e-05\n",
            "Train loss: 0.6720975041389465\n",
            "\n",
            "Time (s): 0.6291995048522949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 243 / 499\n",
            "LR: 8.86110411937453e-05\n",
            "Train loss: 0.9702165126800537\n",
            "\n",
            "Time (s): 0.6287093162536621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 244 / 499\n",
            "LR: 8.861086307805649e-05\n",
            "Train loss: 0.7252721190452576\n",
            "\n",
            "Time (s): 0.6299698352813721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 245 / 499\n",
            "LR: 8.861068496344178e-05\n",
            "Train loss: 0.6377731561660767\n",
            "\n",
            "Time (s): 0.6290082931518555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 246 / 499\n",
            "LR: 8.861050684990113e-05\n",
            "Train loss: 0.9179555177688599\n",
            "\n",
            "Time (s): 0.6302428245544434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 247 / 499\n",
            "LR: 8.861032873743453e-05\n",
            "Train loss: 0.8504536151885986\n",
            "\n",
            "Time (s): 0.6313028335571289\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 248 / 499\n",
            "LR: 8.861015062604197e-05\n",
            "Train loss: 1.1984421014785767\n",
            "\n",
            "Time (s): 0.6300718784332275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 249 / 499\n",
            "LR: 8.860997251572346e-05\n",
            "Train loss: 0.8850929737091064\n",
            "\n",
            "Time (s): 0.6290609836578369\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 250 / 499\n",
            "LR: 8.860979440647899e-05\n",
            "Train loss: 0.5240732431411743\n",
            "\n",
            "Time (s): 0.6297285556793213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 251 / 499\n",
            "LR: 8.860961629830851e-05\n",
            "Train loss: 0.9101424813270569\n",
            "\n",
            "Time (s): 0.6296038627624512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 252 / 499\n",
            "LR: 8.860943819121203e-05\n",
            "Train loss: 0.7011444568634033\n",
            "\n",
            "Time (s): 0.6298518180847168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 253 / 499\n",
            "LR: 8.860926008518956e-05\n",
            "Train loss: 0.6589798331260681\n",
            "\n",
            "Time (s): 0.6299452781677246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 254 / 499\n",
            "LR: 8.860908198024105e-05\n",
            "Train loss: 0.4494863748550415\n",
            "\n",
            "Time (s): 0.6289918422698975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 255 / 499\n",
            "LR: 8.860890387636652e-05\n",
            "Train loss: 0.6985979080200195\n",
            "\n",
            "Time (s): 0.6305563449859619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 256 / 499\n",
            "LR: 8.860872577356595e-05\n",
            "Train loss: 0.7181841135025024\n",
            "\n",
            "Time (s): 0.6297993659973145\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 257 / 499\n",
            "LR: 8.860854767183932e-05\n",
            "Train loss: 0.8452845811843872\n",
            "\n",
            "Time (s): 0.6286928653717041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 258 / 499\n",
            "LR: 8.860836957118666e-05\n",
            "Train loss: 0.5254149436950684\n",
            "\n",
            "Time (s): 0.6284372806549072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 259 / 499\n",
            "LR: 8.860819147160789e-05\n",
            "Train loss: 1.4123547077178955\n",
            "\n",
            "Time (s): 0.6300551891326904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 260 / 499\n",
            "LR: 8.860801337310306e-05\n",
            "Train loss: 0.6651257276535034\n",
            "\n",
            "Time (s): 0.6284515857696533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 261 / 499\n",
            "LR: 8.860783527567212e-05\n",
            "Train loss: 0.8848407864570618\n",
            "\n",
            "Time (s): 0.62900710105896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 262 / 499\n",
            "LR: 8.860765717931509e-05\n",
            "Train loss: 1.1962707042694092\n",
            "\n",
            "Time (s): 0.6298155784606934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 263 / 499\n",
            "LR: 8.860747908403193e-05\n",
            "Train loss: 1.0408271551132202\n",
            "\n",
            "Time (s): 0.6302554607391357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 264 / 499\n",
            "LR: 8.860730098982267e-05\n",
            "Train loss: 0.9695528149604797\n",
            "\n",
            "Time (s): 0.6284027099609375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 265 / 499\n",
            "LR: 8.860712289668723e-05\n",
            "Train loss: 0.7125275731086731\n",
            "\n",
            "Time (s): 0.6301696300506592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 266 / 499\n",
            "LR: 8.860694480462566e-05\n",
            "Train loss: 0.47008010745048523\n",
            "\n",
            "Time (s): 0.6282145977020264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 267 / 499\n",
            "LR: 8.860676671363796e-05\n",
            "Train loss: 0.5481066107749939\n",
            "\n",
            "Time (s): 0.6296319961547852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 268 / 499\n",
            "LR: 8.860658862372405e-05\n",
            "Train loss: 0.8726657032966614\n",
            "\n",
            "Time (s): 0.6291019916534424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 269 / 499\n",
            "LR: 8.860641053488399e-05\n",
            "Train loss: 1.1801340579986572\n",
            "\n",
            "Time (s): 0.6295504570007324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 270 / 499\n",
            "LR: 8.86062324471177e-05\n",
            "Train loss: 0.821338951587677\n",
            "\n",
            "Time (s): 0.6299238204956055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 271 / 499\n",
            "LR: 8.860605436042526e-05\n",
            "Train loss: 0.3436952829360962\n",
            "\n",
            "Time (s): 0.6296119689941406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 272 / 499\n",
            "LR: 8.860587627480656e-05\n",
            "Train loss: 0.8234502077102661\n",
            "\n",
            "Time (s): 0.6308567523956299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 273 / 499\n",
            "LR: 8.860569819026165e-05\n",
            "Train loss: 0.47114670276641846\n",
            "\n",
            "Time (s): 0.6293001174926758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 274 / 499\n",
            "LR: 8.860552010679052e-05\n",
            "Train loss: 0.43075913190841675\n",
            "\n",
            "Time (s): 0.6308126449584961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 275 / 499\n",
            "LR: 8.860534202439314e-05\n",
            "Train loss: 1.4283708333969116\n",
            "\n",
            "Time (s): 0.6294760704040527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 276 / 499\n",
            "LR: 8.86051639430695e-05\n",
            "Train loss: 0.7493393421173096\n",
            "\n",
            "Time (s): 0.6289606094360352\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 277 / 499\n",
            "LR: 8.86049858628196e-05\n",
            "Train loss: 0.6334253549575806\n",
            "\n",
            "Time (s): 0.6294617652893066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 278 / 499\n",
            "LR: 8.86048077836434e-05\n",
            "Train loss: 0.5470304489135742\n",
            "\n",
            "Time (s): 0.629885196685791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 279 / 499\n",
            "LR: 8.860462970554093e-05\n",
            "Train loss: 0.7392864227294922\n",
            "\n",
            "Time (s): 0.6290225982666016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 280 / 499\n",
            "LR: 8.860445162851216e-05\n",
            "Train loss: 0.8047807812690735\n",
            "\n",
            "Time (s): 0.6300325393676758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 281 / 499\n",
            "LR: 8.860427355255709e-05\n",
            "Train loss: 1.282731294631958\n",
            "\n",
            "Time (s): 0.6296589374542236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 282 / 499\n",
            "LR: 8.860409547767567e-05\n",
            "Train loss: 0.5002467632293701\n",
            "\n",
            "Time (s): 0.6295137405395508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 283 / 499\n",
            "LR: 8.860391740386794e-05\n",
            "Train loss: 1.0233618021011353\n",
            "\n",
            "Time (s): 0.6295387744903564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 284 / 499\n",
            "LR: 8.860373933113386e-05\n",
            "Train loss: 0.9885509014129639\n",
            "\n",
            "Time (s): 0.6296834945678711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 285 / 499\n",
            "LR: 8.860356125947343e-05\n",
            "Train loss: 1.1257576942443848\n",
            "\n",
            "Time (s): 0.6280081272125244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 286 / 499\n",
            "LR: 8.860338318888663e-05\n",
            "Train loss: 0.4444330930709839\n",
            "\n",
            "Time (s): 0.628795862197876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 287 / 499\n",
            "LR: 8.860320511937346e-05\n",
            "Train loss: 0.358137845993042\n",
            "\n",
            "Time (s): 0.6298031806945801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 288 / 499\n",
            "LR: 8.860302705093393e-05\n",
            "Train loss: 0.8998990058898926\n",
            "\n",
            "Time (s): 0.6291835308074951\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 289 / 499\n",
            "LR: 8.860284898356797e-05\n",
            "Train loss: 0.8594893217086792\n",
            "\n",
            "Time (s): 0.629612922668457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 290 / 499\n",
            "LR: 8.86026709172756e-05\n",
            "Train loss: 0.9329222440719604\n",
            "\n",
            "Time (s): 0.6297109127044678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 291 / 499\n",
            "LR: 8.860249285205683e-05\n",
            "Train loss: 0.4475555121898651\n",
            "\n",
            "Time (s): 0.6298584938049316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 292 / 499\n",
            "LR: 8.860231478791163e-05\n",
            "Train loss: 0.9991275668144226\n",
            "\n",
            "Time (s): 0.6305027008056641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 293 / 499\n",
            "LR: 8.860213672483999e-05\n",
            "Train loss: 0.691074550151825\n",
            "\n",
            "Time (s): 0.6297485828399658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 294 / 499\n",
            "LR: 8.860195866284189e-05\n",
            "Train loss: 0.785578191280365\n",
            "\n",
            "Time (s): 0.6297879219055176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 295 / 499\n",
            "LR: 8.860178060191733e-05\n",
            "Train loss: 1.2674602270126343\n",
            "\n",
            "Time (s): 0.6290898323059082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 296 / 499\n",
            "LR: 8.86016025420663e-05\n",
            "Train loss: 0.8096632361412048\n",
            "\n",
            "Time (s): 0.6299552917480469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 297 / 499\n",
            "LR: 8.86014244832888e-05\n",
            "Train loss: 0.6409607529640198\n",
            "\n",
            "Time (s): 0.6299302577972412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 298 / 499\n",
            "LR: 8.86012464255848e-05\n",
            "Train loss: 0.9631151556968689\n",
            "\n",
            "Time (s): 0.6295332908630371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 299 / 499\n",
            "LR: 8.860106836895428e-05\n",
            "Train loss: 0.8604310750961304\n",
            "\n",
            "Time (s): 0.6295468807220459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 300 / 499\n",
            "LR: 8.860089031339725e-05\n",
            "Train loss: 1.1279882192611694\n",
            "\n",
            "Time (s): 0.629535436630249\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 301 / 499\n",
            "LR: 8.860071225891371e-05\n",
            "Train loss: 0.7445622086524963\n",
            "\n",
            "Time (s): 0.6298832893371582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 302 / 499\n",
            "LR: 8.860053420550363e-05\n",
            "Train loss: 0.764168918132782\n",
            "\n",
            "Time (s): 0.6296508312225342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 303 / 499\n",
            "LR: 8.860035615316699e-05\n",
            "Train loss: 0.9149881601333618\n",
            "\n",
            "Time (s): 0.6296300888061523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 304 / 499\n",
            "LR: 8.860017810190382e-05\n",
            "Train loss: 1.0456151962280273\n",
            "\n",
            "Time (s): 0.6288719177246094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 305 / 499\n",
            "LR: 8.860000005171403e-05\n",
            "Train loss: 1.1467267274856567\n",
            "\n",
            "Time (s): 0.6294565200805664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 306 / 499\n",
            "LR: 8.859982200259769e-05\n",
            "Train loss: 0.8100513815879822\n",
            "\n",
            "Time (s): 0.6297087669372559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 307 / 499\n",
            "LR: 8.859964395455477e-05\n",
            "Train loss: 0.7123578190803528\n",
            "\n",
            "Time (s): 0.6307668685913086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 308 / 499\n",
            "LR: 8.859946590758523e-05\n",
            "Train loss: 0.7371523976325989\n",
            "\n",
            "Time (s): 0.6295952796936035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 309 / 499\n",
            "LR: 8.85992878616891e-05\n",
            "Train loss: 1.3726385831832886\n",
            "\n",
            "Time (s): 0.6295223236083984\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 310 / 499\n",
            "LR: 8.859910981686632e-05\n",
            "Train loss: 0.9344584345817566\n",
            "\n",
            "Time (s): 0.6301965713500977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 311 / 499\n",
            "LR: 8.859893177311694e-05\n",
            "Train loss: 0.5077134966850281\n",
            "\n",
            "Time (s): 0.629241943359375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 312 / 499\n",
            "LR: 8.859875373044089e-05\n",
            "Train loss: 0.6454805135726929\n",
            "\n",
            "Time (s): 0.630079984664917\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 313 / 499\n",
            "LR: 8.85985756888382e-05\n",
            "Train loss: 1.0319868326187134\n",
            "\n",
            "Time (s): 0.6293129920959473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 314 / 499\n",
            "LR: 8.859839764830882e-05\n",
            "Train loss: 0.44659537076950073\n",
            "\n",
            "Time (s): 0.6296603679656982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 315 / 499\n",
            "LR: 8.859821960885279e-05\n",
            "Train loss: 0.5083786249160767\n",
            "\n",
            "Time (s): 0.6289756298065186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 316 / 499\n",
            "LR: 8.859804157047006e-05\n",
            "Train loss: 0.7496485114097595\n",
            "\n",
            "Time (s): 0.6300950050354004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 317 / 499\n",
            "LR: 8.85978635331606e-05\n",
            "Train loss: 1.0672264099121094\n",
            "\n",
            "Time (s): 0.6293997764587402\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 318 / 499\n",
            "LR: 8.859768549692449e-05\n",
            "Train loss: 1.076846957206726\n",
            "\n",
            "Time (s): 0.628485918045044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 319 / 499\n",
            "LR: 8.859750746176162e-05\n",
            "Train loss: 0.9422503709793091\n",
            "\n",
            "Time (s): 0.629016637802124\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 320 / 499\n",
            "LR: 8.859732942767204e-05\n",
            "Train loss: 1.384590983390808\n",
            "\n",
            "Time (s): 0.6297502517700195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 321 / 499\n",
            "LR: 8.85971513946557e-05\n",
            "Train loss: 0.8783431053161621\n",
            "\n",
            "Time (s): 0.6294901371002197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 322 / 499\n",
            "LR: 8.859697336271263e-05\n",
            "Train loss: 1.1473444700241089\n",
            "\n",
            "Time (s): 0.6297285556793213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 323 / 499\n",
            "LR: 8.859679533184279e-05\n",
            "Train loss: 0.8127713203430176\n",
            "\n",
            "Time (s): 0.6286051273345947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 324 / 499\n",
            "LR: 8.859661730204615e-05\n",
            "Train loss: 1.0743584632873535\n",
            "\n",
            "Time (s): 0.6284346580505371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 325 / 499\n",
            "LR: 8.859643927332277e-05\n",
            "Train loss: 0.987615168094635\n",
            "\n",
            "Time (s): 0.6289196014404297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 326 / 499\n",
            "LR: 8.859626124567256e-05\n",
            "Train loss: 0.6354147791862488\n",
            "\n",
            "Time (s): 0.6302304267883301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 327 / 499\n",
            "LR: 8.859608321909556e-05\n",
            "Train loss: 0.42534369230270386\n",
            "\n",
            "Time (s): 0.6292328834533691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 328 / 499\n",
            "LR: 8.859590519359174e-05\n",
            "Train loss: 0.6125816106796265\n",
            "\n",
            "Time (s): 0.6298372745513916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 329 / 499\n",
            "LR: 8.85957271691611e-05\n",
            "Train loss: 1.1631320714950562\n",
            "\n",
            "Time (s): 0.6289126873016357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 330 / 499\n",
            "LR: 8.859554914580359e-05\n",
            "Train loss: 0.8976253867149353\n",
            "\n",
            "Time (s): 0.6295778751373291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 331 / 499\n",
            "LR: 8.859537112351925e-05\n",
            "Train loss: 0.7849467396736145\n",
            "\n",
            "Time (s): 0.6299080848693848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 332 / 499\n",
            "LR: 8.859519310230807e-05\n",
            "Train loss: 1.093618631362915\n",
            "\n",
            "Time (s): 0.6298117637634277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 333 / 499\n",
            "LR: 8.859501508217e-05\n",
            "Train loss: 0.4983596205711365\n",
            "\n",
            "Time (s): 0.6291651725769043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 334 / 499\n",
            "LR: 8.859483706310505e-05\n",
            "Train loss: 0.8434908986091614\n",
            "\n",
            "Time (s): 0.6265881061553955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 335 / 499\n",
            "LR: 8.859465904511319e-05\n",
            "Train loss: 0.4498918354511261\n",
            "\n",
            "Time (s): 0.6246950626373291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 336 / 499\n",
            "LR: 8.859448102819446e-05\n",
            "Train loss: 0.6336595416069031\n",
            "\n",
            "Time (s): 0.6298642158508301\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 337 / 499\n",
            "LR: 8.859430301234879e-05\n",
            "Train loss: 0.7940523028373718\n",
            "\n",
            "Time (s): 0.6247766017913818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 338 / 499\n",
            "LR: 8.85941249975762e-05\n",
            "Train loss: 0.7750994563102722\n",
            "\n",
            "Time (s): 0.6247336864471436\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 339 / 499\n",
            "LR: 8.85939469838767e-05\n",
            "Train loss: 0.33713406324386597\n",
            "\n",
            "Time (s): 0.6296343803405762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 340 / 499\n",
            "LR: 8.859376897125024e-05\n",
            "Train loss: 1.5529727935791016\n",
            "\n",
            "Time (s): 0.6286730766296387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 341 / 499\n",
            "LR: 8.85935909596968e-05\n",
            "Train loss: 1.4683345556259155\n",
            "\n",
            "Time (s): 0.6298110485076904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 342 / 499\n",
            "LR: 8.85934129492164e-05\n",
            "Train loss: 0.3526732921600342\n",
            "\n",
            "Time (s): 0.6242034435272217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 343 / 499\n",
            "LR: 8.859323493980906e-05\n",
            "Train loss: 0.512697160243988\n",
            "\n",
            "Time (s): 0.6245098114013672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 344 / 499\n",
            "LR: 8.859305693147468e-05\n",
            "Train loss: 0.8577514290809631\n",
            "\n",
            "Time (s): 0.6297862529754639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 345 / 499\n",
            "LR: 8.859287892421333e-05\n",
            "Train loss: 0.695125162601471\n",
            "\n",
            "Time (s): 0.6290295124053955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 346 / 499\n",
            "LR: 8.859270091802496e-05\n",
            "Train loss: 1.013189435005188\n",
            "\n",
            "Time (s): 0.6261475086212158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 347 / 499\n",
            "LR: 8.859252291290956e-05\n",
            "Train loss: 0.32121822237968445\n",
            "\n",
            "Time (s): 0.6286368370056152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 348 / 499\n",
            "LR: 8.859234490886714e-05\n",
            "Train loss: 0.5924291610717773\n",
            "\n",
            "Time (s): 0.626415491104126\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 349 / 499\n",
            "LR: 8.859216690589767e-05\n",
            "Train loss: 0.973626971244812\n",
            "\n",
            "Time (s): 0.6286852359771729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 350 / 499\n",
            "LR: 8.859198890400115e-05\n",
            "Train loss: 0.6640244722366333\n",
            "\n",
            "Time (s): 0.6289527416229248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 351 / 499\n",
            "LR: 8.859181090317755e-05\n",
            "Train loss: 0.6974226236343384\n",
            "\n",
            "Time (s): 0.6251544952392578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 352 / 499\n",
            "LR: 8.859163290342688e-05\n",
            "Train loss: 0.5987474918365479\n",
            "\n",
            "Time (s): 0.6303160190582275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 353 / 499\n",
            "LR: 8.859145490474914e-05\n",
            "Train loss: 0.9811863899230957\n",
            "\n",
            "Time (s): 0.6245126724243164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 354 / 499\n",
            "LR: 8.859127690714429e-05\n",
            "Train loss: 0.9155967235565186\n",
            "\n",
            "Time (s): 0.6286704540252686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 355 / 499\n",
            "LR: 8.859109891061235e-05\n",
            "Train loss: 1.6532691717147827\n",
            "\n",
            "Time (s): 0.6301956176757812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 356 / 499\n",
            "LR: 8.859092091515326e-05\n",
            "Train loss: 0.7437238693237305\n",
            "\n",
            "Time (s): 0.6247098445892334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 357 / 499\n",
            "LR: 8.859074292076706e-05\n",
            "Train loss: 1.126297116279602\n",
            "\n",
            "Time (s): 0.6249837875366211\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 358 / 499\n",
            "LR: 8.859056492745371e-05\n",
            "Train loss: 0.8500298261642456\n",
            "\n",
            "Time (s): 0.6282107830047607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 359 / 499\n",
            "LR: 8.859038693521322e-05\n",
            "Train loss: 0.503433108329773\n",
            "\n",
            "Time (s): 0.6267621517181396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 360 / 499\n",
            "LR: 8.859020894404555e-05\n",
            "Train loss: 0.6412660479545593\n",
            "\n",
            "Time (s): 0.6287200450897217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 361 / 499\n",
            "LR: 8.859003095395074e-05\n",
            "Train loss: 0.5722116827964783\n",
            "\n",
            "Time (s): 0.6320674419403076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 362 / 499\n",
            "LR: 8.858985296492871e-05\n",
            "Train loss: 0.6985092163085938\n",
            "\n",
            "Time (s): 0.6239004135131836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 363 / 499\n",
            "LR: 8.858967497697952e-05\n",
            "Train loss: 0.49579739570617676\n",
            "\n",
            "Time (s): 0.6283175945281982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 364 / 499\n",
            "LR: 8.85894969901031e-05\n",
            "Train loss: 0.2672112286090851\n",
            "\n",
            "Time (s): 0.6291251182556152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 365 / 499\n",
            "LR: 8.858931900429947e-05\n",
            "Train loss: 0.5420661568641663\n",
            "\n",
            "Time (s): 0.629784345626831\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 366 / 499\n",
            "LR: 8.858914101956861e-05\n",
            "Train loss: 0.4447330832481384\n",
            "\n",
            "Time (s): 0.6293320655822754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 367 / 499\n",
            "LR: 8.858896303591052e-05\n",
            "Train loss: 1.223970890045166\n",
            "\n",
            "Time (s): 0.6291778087615967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 368 / 499\n",
            "LR: 8.858878505332519e-05\n",
            "Train loss: 1.4046871662139893\n",
            "\n",
            "Time (s): 0.6300208568572998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 369 / 499\n",
            "LR: 8.858860707181259e-05\n",
            "Train loss: 1.0248299837112427\n",
            "\n",
            "Time (s): 0.6302602291107178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 370 / 499\n",
            "LR: 8.858842909137272e-05\n",
            "Train loss: 0.960242748260498\n",
            "\n",
            "Time (s): 0.6266152858734131\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 371 / 499\n",
            "LR: 8.858825111200556e-05\n",
            "Train loss: 0.7390588521957397\n",
            "\n",
            "Time (s): 0.6286485195159912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 372 / 499\n",
            "LR: 8.858807313371114e-05\n",
            "Train loss: 0.5842159986495972\n",
            "\n",
            "Time (s): 0.626110315322876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 373 / 499\n",
            "LR: 8.858789515648939e-05\n",
            "Train loss: 1.0992815494537354\n",
            "\n",
            "Time (s): 0.6294465065002441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 374 / 499\n",
            "LR: 8.858771718034034e-05\n",
            "Train loss: 1.3780746459960938\n",
            "\n",
            "Time (s): 0.6284306049346924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 375 / 499\n",
            "LR: 8.858753920526396e-05\n",
            "Train loss: 0.6265183687210083\n",
            "\n",
            "Time (s): 0.6305136680603027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 376 / 499\n",
            "LR: 8.858736123126023e-05\n",
            "Train loss: 1.1125190258026123\n",
            "\n",
            "Time (s): 0.6290037631988525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 377 / 499\n",
            "LR: 8.858718325832919e-05\n",
            "Train loss: 1.0934209823608398\n",
            "\n",
            "Time (s): 0.629673957824707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 378 / 499\n",
            "LR: 8.858700528647075e-05\n",
            "Train loss: 1.0615037679672241\n",
            "\n",
            "Time (s): 0.624974250793457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 379 / 499\n",
            "LR: 8.858682731568499e-05\n",
            "Train loss: 0.5425692200660706\n",
            "\n",
            "Time (s): 0.6297986507415771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 380 / 499\n",
            "LR: 8.858664934597182e-05\n",
            "Train loss: 0.883827805519104\n",
            "\n",
            "Time (s): 0.6292014122009277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 381 / 499\n",
            "LR: 8.858647137733129e-05\n",
            "Train loss: 0.8763963580131531\n",
            "\n",
            "Time (s): 0.6283323764801025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 382 / 499\n",
            "LR: 8.858629340976333e-05\n",
            "Train loss: 0.6157764792442322\n",
            "\n",
            "Time (s): 0.6282904148101807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 383 / 499\n",
            "LR: 8.858611544326796e-05\n",
            "Train loss: 0.6690329313278198\n",
            "\n",
            "Time (s): 0.6244206428527832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 384 / 499\n",
            "LR: 8.858593747784521e-05\n",
            "Train loss: 0.8443227410316467\n",
            "\n",
            "Time (s): 0.6239690780639648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 385 / 499\n",
            "LR: 8.8585759513495e-05\n",
            "Train loss: 1.3409274816513062\n",
            "\n",
            "Time (s): 0.6291143894195557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 386 / 499\n",
            "LR: 8.858558155021734e-05\n",
            "Train loss: 1.3279081583023071\n",
            "\n",
            "Time (s): 0.6245906352996826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 387 / 499\n",
            "LR: 8.858540358801223e-05\n",
            "Train loss: 0.7749541997909546\n",
            "\n",
            "Time (s): 0.6244385242462158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 388 / 499\n",
            "LR: 8.858522562687967e-05\n",
            "Train loss: 1.7432998418807983\n",
            "\n",
            "Time (s): 0.6287908554077148\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 389 / 499\n",
            "LR: 8.858504766681964e-05\n",
            "Train loss: 0.7081544995307922\n",
            "\n",
            "Time (s): 0.6287403106689453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 390 / 499\n",
            "LR: 8.858486970783211e-05\n",
            "Train loss: 0.36474981904029846\n",
            "\n",
            "Time (s): 0.6238551139831543\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 391 / 499\n",
            "LR: 8.858469174991709e-05\n",
            "Train loss: 0.3871364891529083\n",
            "\n",
            "Time (s): 0.6247446537017822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 392 / 499\n",
            "LR: 8.858451379307456e-05\n",
            "Train loss: 1.3945481777191162\n",
            "\n",
            "Time (s): 0.6288909912109375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 393 / 499\n",
            "LR: 8.858433583730453e-05\n",
            "Train loss: 1.2767738103866577\n",
            "\n",
            "Time (s): 0.6294894218444824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 394 / 499\n",
            "LR: 8.858415788260694e-05\n",
            "Train loss: 0.7852842807769775\n",
            "\n",
            "Time (s): 0.6248009204864502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 395 / 499\n",
            "LR: 8.858397992898183e-05\n",
            "Train loss: 0.7938312292098999\n",
            "\n",
            "Time (s): 0.6267943382263184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 396 / 499\n",
            "LR: 8.858380197642917e-05\n",
            "Train loss: 1.1387206315994263\n",
            "\n",
            "Time (s): 0.629021167755127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 397 / 499\n",
            "LR: 8.858362402494894e-05\n",
            "Train loss: 0.45397114753723145\n",
            "\n",
            "Time (s): 0.6242485046386719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 398 / 499\n",
            "LR: 8.858344607454116e-05\n",
            "Train loss: 0.40490153431892395\n",
            "\n",
            "Time (s): 0.6288537979125977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 399 / 499\n",
            "LR: 8.858326812520578e-05\n",
            "Train loss: 0.9343283176422119\n",
            "\n",
            "Time (s): 0.6263771057128906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 400 / 499\n",
            "LR: 8.858309017694279e-05\n",
            "Train loss: 0.5242840647697449\n",
            "\n",
            "Time (s): 0.6290500164031982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 401 / 499\n",
            "LR: 8.858291222975223e-05\n",
            "Train loss: 1.0055464506149292\n",
            "\n",
            "Time (s): 0.6292071342468262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 402 / 499\n",
            "LR: 8.858273428363403e-05\n",
            "Train loss: 1.0279576778411865\n",
            "\n",
            "Time (s): 0.6244251728057861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 403 / 499\n",
            "LR: 8.858255633858823e-05\n",
            "Train loss: 0.5080121159553528\n",
            "\n",
            "Time (s): 0.6242468357086182\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 404 / 499\n",
            "LR: 8.858237839461478e-05\n",
            "Train loss: 0.40948617458343506\n",
            "\n",
            "Time (s): 0.6288728713989258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 405 / 499\n",
            "LR: 8.858220045171369e-05\n",
            "Train loss: 1.4520294666290283\n",
            "\n",
            "Time (s): 0.6244592666625977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 406 / 499\n",
            "LR: 8.858202250988493e-05\n",
            "Train loss: 0.4274628162384033\n",
            "\n",
            "Time (s): 0.6243014335632324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 407 / 499\n",
            "LR: 8.858184456912851e-05\n",
            "Train loss: 0.46465280652046204\n",
            "\n",
            "Time (s): 0.6244146823883057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 408 / 499\n",
            "LR: 8.858166662944439e-05\n",
            "Train loss: 0.476235955953598\n",
            "\n",
            "Time (s): 0.6277515888214111\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 409 / 499\n",
            "LR: 8.85814886908326e-05\n",
            "Train loss: 0.7345787882804871\n",
            "\n",
            "Time (s): 0.6278207302093506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 410 / 499\n",
            "LR: 8.858131075329313e-05\n",
            "Train loss: 0.7215782999992371\n",
            "\n",
            "Time (s): 0.6291046142578125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 411 / 499\n",
            "LR: 8.858113281682592e-05\n",
            "Train loss: 0.676686704158783\n",
            "\n",
            "Time (s): 0.6293675899505615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 412 / 499\n",
            "LR: 8.8580954881431e-05\n",
            "Train loss: 0.7075002193450928\n",
            "\n",
            "Time (s): 0.6306095123291016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 413 / 499\n",
            "LR: 8.858077694710833e-05\n",
            "Train loss: 0.790758490562439\n",
            "\n",
            "Time (s): 0.6257100105285645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 414 / 499\n",
            "LR: 8.858059901385793e-05\n",
            "Train loss: 1.3571107387542725\n",
            "\n",
            "Time (s): 0.6277861595153809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 415 / 499\n",
            "LR: 8.858042108167977e-05\n",
            "Train loss: 0.8763117790222168\n",
            "\n",
            "Time (s): 0.6297240257263184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 416 / 499\n",
            "LR: 8.858024315057386e-05\n",
            "Train loss: 0.4644390046596527\n",
            "\n",
            "Time (s): 0.6269984245300293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 417 / 499\n",
            "LR: 8.858006522054016e-05\n",
            "Train loss: 1.1223433017730713\n",
            "\n",
            "Time (s): 0.6293103694915771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 418 / 499\n",
            "LR: 8.857988729157866e-05\n",
            "Train loss: 1.6199666261672974\n",
            "\n",
            "Time (s): 0.6308534145355225\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 419 / 499\n",
            "LR: 8.857970936368939e-05\n",
            "Train loss: 0.5915116667747498\n",
            "\n",
            "Time (s): 0.6311233043670654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 420 / 499\n",
            "LR: 8.857953143687231e-05\n",
            "Train loss: 1.1331675052642822\n",
            "\n",
            "Time (s): 0.6245489120483398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 421 / 499\n",
            "LR: 8.857935351112739e-05\n",
            "Train loss: 0.34959056973457336\n",
            "\n",
            "Time (s): 0.6285622119903564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 422 / 499\n",
            "LR: 8.857917558645466e-05\n",
            "Train loss: 0.5216978788375854\n",
            "\n",
            "Time (s): 0.6248321533203125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 423 / 499\n",
            "LR: 8.857899766285408e-05\n",
            "Train loss: 0.2716003954410553\n",
            "\n",
            "Time (s): 0.6300387382507324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 424 / 499\n",
            "LR: 8.857881974032565e-05\n",
            "Train loss: 0.6794493198394775\n",
            "\n",
            "Time (s): 0.6292424201965332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 425 / 499\n",
            "LR: 8.857864181886935e-05\n",
            "Train loss: 1.0045777559280396\n",
            "\n",
            "Time (s): 0.6262309551239014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 426 / 499\n",
            "LR: 8.857846389848521e-05\n",
            "Train loss: 0.4315779209136963\n",
            "\n",
            "Time (s): 0.6293766498565674\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 427 / 499\n",
            "LR: 8.857828597917314e-05\n",
            "Train loss: 0.6601338386535645\n",
            "\n",
            "Time (s): 0.6241223812103271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 428 / 499\n",
            "LR: 8.85781080609332e-05\n",
            "Train loss: 0.9775061011314392\n",
            "\n",
            "Time (s): 0.6284723281860352\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 429 / 499\n",
            "LR: 8.857793014376534e-05\n",
            "Train loss: 1.5330137014389038\n",
            "\n",
            "Time (s): 0.6286084651947021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 430 / 499\n",
            "LR: 8.857775222766959e-05\n",
            "Train loss: 0.3701206147670746\n",
            "\n",
            "Time (s): 0.6288192272186279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 431 / 499\n",
            "LR: 8.857757431264589e-05\n",
            "Train loss: 0.8230670690536499\n",
            "\n",
            "Time (s): 0.628547191619873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 432 / 499\n",
            "LR: 8.857739639869427e-05\n",
            "Train loss: 1.3282444477081299\n",
            "\n",
            "Time (s): 0.6294372081756592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 433 / 499\n",
            "LR: 8.857721848581469e-05\n",
            "Train loss: 0.7042443752288818\n",
            "\n",
            "Time (s): 0.6289694309234619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 434 / 499\n",
            "LR: 8.857704057400716e-05\n",
            "Train loss: 0.9735280275344849\n",
            "\n",
            "Time (s): 0.6297740936279297\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 435 / 499\n",
            "LR: 8.857686266327164e-05\n",
            "Train loss: 1.1426615715026855\n",
            "\n",
            "Time (s): 0.6288321018218994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 436 / 499\n",
            "LR: 8.857668475360816e-05\n",
            "Train loss: 1.2294394969940186\n",
            "\n",
            "Time (s): 0.6296937465667725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 437 / 499\n",
            "LR: 8.857650684501667e-05\n",
            "Train loss: 0.9966352581977844\n",
            "\n",
            "Time (s): 0.6290302276611328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 438 / 499\n",
            "LR: 8.85763289374972e-05\n",
            "Train loss: 0.26461219787597656\n",
            "\n",
            "Time (s): 0.6264183521270752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 439 / 499\n",
            "LR: 8.857615103104971e-05\n",
            "Train loss: 0.9186714291572571\n",
            "\n",
            "Time (s): 0.62807297706604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 440 / 499\n",
            "LR: 8.857597312567418e-05\n",
            "Train loss: 0.9428112506866455\n",
            "\n",
            "Time (s): 0.6283917427062988\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 441 / 499\n",
            "LR: 8.857579522137064e-05\n",
            "Train loss: 1.149454116821289\n",
            "\n",
            "Time (s): 0.6293306350708008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 442 / 499\n",
            "LR: 8.857561731813904e-05\n",
            "Train loss: 0.8959827423095703\n",
            "\n",
            "Time (s): 0.6292715072631836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 443 / 499\n",
            "LR: 8.857543941597939e-05\n",
            "Train loss: 1.6354970932006836\n",
            "\n",
            "Time (s): 0.6247360706329346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 444 / 499\n",
            "LR: 8.857526151489168e-05\n",
            "Train loss: 1.439283847808838\n",
            "\n",
            "Time (s): 0.6283824443817139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 445 / 499\n",
            "LR: 8.857508361487589e-05\n",
            "Train loss: 0.747531533241272\n",
            "\n",
            "Time (s): 0.6260366439819336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 446 / 499\n",
            "LR: 8.857490571593198e-05\n",
            "Train loss: 0.9368652105331421\n",
            "\n",
            "Time (s): 0.6301660537719727\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 447 / 499\n",
            "LR: 8.857472781806001e-05\n",
            "Train loss: 0.8610947132110596\n",
            "\n",
            "Time (s): 0.6288573741912842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 448 / 499\n",
            "LR: 8.85745499212599e-05\n",
            "Train loss: 0.6031973958015442\n",
            "\n",
            "Time (s): 0.6267659664154053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 449 / 499\n",
            "LR: 8.85743720255317e-05\n",
            "Train loss: 1.1003806591033936\n",
            "\n",
            "Time (s): 0.6309781074523926\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 450 / 499\n",
            "LR: 8.857419413087537e-05\n",
            "Train loss: 0.29249775409698486\n",
            "\n",
            "Time (s): 0.6249713897705078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 451 / 499\n",
            "LR: 8.857401623729087e-05\n",
            "Train loss: 1.4969927072525024\n",
            "\n",
            "Time (s): 0.6300327777862549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 452 / 499\n",
            "LR: 8.857383834477822e-05\n",
            "Train loss: 1.0890823602676392\n",
            "\n",
            "Time (s): 0.6302521228790283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 453 / 499\n",
            "LR: 8.857366045333741e-05\n",
            "Train loss: 0.9628466367721558\n",
            "\n",
            "Time (s): 0.6252105236053467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 454 / 499\n",
            "LR: 8.857348256296845e-05\n",
            "Train loss: 0.8505988717079163\n",
            "\n",
            "Time (s): 0.6295680999755859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 455 / 499\n",
            "LR: 8.857330467367128e-05\n",
            "Train loss: 0.65390545129776\n",
            "\n",
            "Time (s): 0.6299009323120117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 456 / 499\n",
            "LR: 8.85731267854459e-05\n",
            "Train loss: 0.9067158102989197\n",
            "\n",
            "Time (s): 0.6250278949737549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 457 / 499\n",
            "LR: 8.857294889829236e-05\n",
            "Train loss: 0.8632931113243103\n",
            "\n",
            "Time (s): 0.6301054954528809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 458 / 499\n",
            "LR: 8.857277101221057e-05\n",
            "Train loss: 0.5496442914009094\n",
            "\n",
            "Time (s): 0.6301195621490479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 459 / 499\n",
            "LR: 8.857259312720057e-05\n",
            "Train loss: 1.2543822526931763\n",
            "\n",
            "Time (s): 0.6282596588134766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 460 / 499\n",
            "LR: 8.85724152432623e-05\n",
            "Train loss: 0.4942476749420166\n",
            "\n",
            "Time (s): 0.6289668083190918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 461 / 499\n",
            "LR: 8.857223736039582e-05\n",
            "Train loss: 0.8538478016853333\n",
            "\n",
            "Time (s): 0.6283228397369385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 462 / 499\n",
            "LR: 8.857205947860106e-05\n",
            "Train loss: 0.62429279088974\n",
            "\n",
            "Time (s): 0.6285586357116699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 463 / 499\n",
            "LR: 8.857188159787802e-05\n",
            "Train loss: 1.1472035646438599\n",
            "\n",
            "Time (s): 0.6244993209838867\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 464 / 499\n",
            "LR: 8.85717037182267e-05\n",
            "Train loss: 0.7656938433647156\n",
            "\n",
            "Time (s): 0.6288535594940186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 465 / 499\n",
            "LR: 8.85715258396471e-05\n",
            "Train loss: 0.49138179421424866\n",
            "\n",
            "Time (s): 0.6303493976593018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 466 / 499\n",
            "LR: 8.85713479621392e-05\n",
            "Train loss: 1.1223748922348022\n",
            "\n",
            "Time (s): 0.6295590400695801\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 467 / 499\n",
            "LR: 8.857117008570297e-05\n",
            "Train loss: 1.6162620782852173\n",
            "\n",
            "Time (s): 0.6294593811035156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 468 / 499\n",
            "LR: 8.857099221033843e-05\n",
            "Train loss: 1.6197694540023804\n",
            "\n",
            "Time (s): 0.6284749507904053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 469 / 499\n",
            "LR: 8.857081433604554e-05\n",
            "Train loss: 0.7020398378372192\n",
            "\n",
            "Time (s): 0.6310219764709473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 470 / 499\n",
            "LR: 8.857063646282428e-05\n",
            "Train loss: 0.5169553756713867\n",
            "\n",
            "Time (s): 0.627565860748291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 471 / 499\n",
            "LR: 8.857045859067471e-05\n",
            "Train loss: 0.804715633392334\n",
            "\n",
            "Time (s): 0.6274497509002686\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 472 / 499\n",
            "LR: 8.857028071959677e-05\n",
            "Train loss: 0.6813819408416748\n",
            "\n",
            "Time (s): 0.6238656044006348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 473 / 499\n",
            "LR: 8.857010284959042e-05\n",
            "Train loss: 0.7085950374603271\n",
            "\n",
            "Time (s): 0.6240918636322021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 474 / 499\n",
            "LR: 8.856992498065571e-05\n",
            "Train loss: 0.610643208026886\n",
            "\n",
            "Time (s): 0.6295514106750488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 475 / 499\n",
            "LR: 8.856974711279258e-05\n",
            "Train loss: 1.1675721406936646\n",
            "\n",
            "Time (s): 0.6280930042266846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 476 / 499\n",
            "LR: 8.856956924600104e-05\n",
            "Train loss: 0.8326621055603027\n",
            "\n",
            "Time (s): 0.6286473274230957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 477 / 499\n",
            "LR: 8.856939138028107e-05\n",
            "Train loss: 1.1764698028564453\n",
            "\n",
            "Time (s): 0.6286935806274414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 478 / 499\n",
            "LR: 8.856921351563269e-05\n",
            "Train loss: 0.6581810116767883\n",
            "\n",
            "Time (s): 0.6268720626831055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 479 / 499\n",
            "LR: 8.856903565205586e-05\n",
            "Train loss: 1.041604995727539\n",
            "\n",
            "Time (s): 0.628715991973877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 480 / 499\n",
            "LR: 8.856885778955057e-05\n",
            "Train loss: 1.1167503595352173\n",
            "\n",
            "Time (s): 0.6302101612091064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 481 / 499\n",
            "LR: 8.856867992811682e-05\n",
            "Train loss: 1.2325607538223267\n",
            "\n",
            "Time (s): 0.6292030811309814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 482 / 499\n",
            "LR: 8.856850206775458e-05\n",
            "Train loss: 0.9421679973602295\n",
            "\n",
            "Time (s): 0.6280875205993652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 483 / 499\n",
            "LR: 8.856832420846388e-05\n",
            "Train loss: 0.6369479298591614\n",
            "\n",
            "Time (s): 0.6291208267211914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 484 / 499\n",
            "LR: 8.856814635024466e-05\n",
            "Train loss: 0.7909075617790222\n",
            "\n",
            "Time (s): 0.6289660930633545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 485 / 499\n",
            "LR: 8.856796849309693e-05\n",
            "Train loss: 1.6863807439804077\n",
            "\n",
            "Time (s): 0.6299493312835693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 486 / 499\n",
            "LR: 8.856779063702069e-05\n",
            "Train loss: 0.6328362822532654\n",
            "\n",
            "Time (s): 0.629188060760498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 487 / 499\n",
            "LR: 8.856761278201592e-05\n",
            "Train loss: 0.7155104875564575\n",
            "\n",
            "Time (s): 0.6298596858978271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 488 / 499\n",
            "LR: 8.856743492808262e-05\n",
            "Train loss: 0.9016251564025879\n",
            "\n",
            "Time (s): 0.6296710968017578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 489 / 499\n",
            "LR: 8.856725707522076e-05\n",
            "Train loss: 0.5599750876426697\n",
            "\n",
            "Time (s): 0.6294164657592773\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 490 / 499\n",
            "LR: 8.856707922343034e-05\n",
            "Train loss: 1.1531829833984375\n",
            "\n",
            "Time (s): 0.6285355091094971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 491 / 499\n",
            "LR: 8.856690137271134e-05\n",
            "Train loss: 0.44324755668640137\n",
            "\n",
            "Time (s): 0.6295747756958008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 492 / 499\n",
            "LR: 8.856672352306377e-05\n",
            "Train loss: 1.1172276735305786\n",
            "\n",
            "Time (s): 0.6287257671356201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 493 / 499\n",
            "LR: 8.85665456744876e-05\n",
            "Train loss: 0.8275309801101685\n",
            "\n",
            "Time (s): 0.6281747817993164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 494 / 499\n",
            "LR: 8.856636782698283e-05\n",
            "Train loss: 0.8599080443382263\n",
            "\n",
            "Time (s): 0.6246798038482666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 495 / 499\n",
            "LR: 8.856618998054943e-05\n",
            "Train loss: 0.8808024525642395\n",
            "\n",
            "Time (s): 0.6250500679016113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 496 / 499\n",
            "LR: 8.85660121351874e-05\n",
            "Train loss: 1.1688810586929321\n",
            "\n",
            "Time (s): 0.6253962516784668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 497 / 499\n",
            "LR: 8.856583429089675e-05\n",
            "Train loss: 0.8806888461112976\n",
            "\n",
            "Time (s): 0.6290926933288574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 498 / 499\n",
            "LR: 8.856565644767746e-05\n",
            "Train loss: 0.7193950414657593\n",
            "\n",
            "Time (s): 0.6279001235961914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 499  Batch 499 / 499\n",
            "LR: 8.856547860552948e-05\n",
            "Train loss: 0.05305774137377739\n",
            "\n",
            "Time (s): 0.0509037971496582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 499\n",
            "Avg train loss: 0.7048744467312922\n",
            "Avg train acc: 0.7910994042853315\n",
            "Avg eval loss: 0.9022350784610299\n",
            "Avg eval acc: 0.7546687617021448\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 500\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 1 / 499\n",
            "LR: 8.856530076445287e-05\n",
            "Train loss: 1.4401588439941406\n",
            "\n",
            "Time (s): 0.6366071701049805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 2 / 499\n",
            "LR: 8.856512292444755e-05\n",
            "Train loss: 0.9324135780334473\n",
            "\n",
            "Time (s): 0.6355078220367432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 3 / 499\n",
            "LR: 8.856494508551355e-05\n",
            "Train loss: 1.549122929573059\n",
            "\n",
            "Time (s): 0.627798318862915\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 4 / 499\n",
            "LR: 8.856476724765086e-05\n",
            "Train loss: 0.6364469528198242\n",
            "\n",
            "Time (s): 0.6290323734283447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 5 / 499\n",
            "LR: 8.856458941085942e-05\n",
            "Train loss: 0.697354257106781\n",
            "\n",
            "Time (s): 0.6321492195129395\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 6 / 499\n",
            "LR: 8.856441157513929e-05\n",
            "Train loss: 1.1358329057693481\n",
            "\n",
            "Time (s): 0.6281354427337646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 7 / 499\n",
            "LR: 8.856423374049041e-05\n",
            "Train loss: 0.5898021459579468\n",
            "\n",
            "Time (s): 0.6248106956481934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 8 / 499\n",
            "LR: 8.856405590691281e-05\n",
            "Train loss: 1.0533480644226074\n",
            "\n",
            "Time (s): 0.6317572593688965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 9 / 499\n",
            "LR: 8.856387807440644e-05\n",
            "Train loss: 0.9341162443161011\n",
            "\n",
            "Time (s): 0.6250238418579102\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 10 / 499\n",
            "LR: 8.856370024297129e-05\n",
            "Train loss: 0.85650634765625\n",
            "\n",
            "Time (s): 0.6356432437896729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 11 / 499\n",
            "LR: 8.856352241260737e-05\n",
            "Train loss: 0.622488796710968\n",
            "\n",
            "Time (s): 0.6317427158355713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 12 / 499\n",
            "LR: 8.85633445833147e-05\n",
            "Train loss: 1.10853910446167\n",
            "\n",
            "Time (s): 0.6290898323059082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 13 / 499\n",
            "LR: 8.856316675509319e-05\n",
            "Train loss: 1.0001202821731567\n",
            "\n",
            "Time (s): 0.6308345794677734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 14 / 499\n",
            "LR: 8.856298892794288e-05\n",
            "Train loss: 0.8785741329193115\n",
            "\n",
            "Time (s): 0.6298072338104248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 15 / 499\n",
            "LR: 8.856281110186374e-05\n",
            "Train loss: 1.1379225254058838\n",
            "\n",
            "Time (s): 0.6324748992919922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 16 / 499\n",
            "LR: 8.856263327685578e-05\n",
            "Train loss: 0.30458447337150574\n",
            "\n",
            "Time (s): 0.630059003829956\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 17 / 499\n",
            "LR: 8.856245545291899e-05\n",
            "Train loss: 0.29729145765304565\n",
            "\n",
            "Time (s): 0.630030632019043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 18 / 499\n",
            "LR: 8.856227763005333e-05\n",
            "Train loss: 0.4512331783771515\n",
            "\n",
            "Time (s): 0.6287503242492676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 19 / 499\n",
            "LR: 8.856209980825881e-05\n",
            "Train loss: 0.7908873558044434\n",
            "\n",
            "Time (s): 0.6309206485748291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 20 / 499\n",
            "LR: 8.856192198753541e-05\n",
            "Train loss: 0.2528327405452728\n",
            "\n",
            "Time (s): 0.6294102668762207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 21 / 499\n",
            "LR: 8.856174416788314e-05\n",
            "Train loss: 0.7094199657440186\n",
            "\n",
            "Time (s): 0.6337730884552002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 22 / 499\n",
            "LR: 8.856156634930196e-05\n",
            "Train loss: 1.0089625120162964\n",
            "\n",
            "Time (s): 0.6275837421417236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 23 / 499\n",
            "LR: 8.85613885317919e-05\n",
            "Train loss: 0.5630109310150146\n",
            "\n",
            "Time (s): 0.6281492710113525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 24 / 499\n",
            "LR: 8.856121071535292e-05\n",
            "Train loss: 0.9459154009819031\n",
            "\n",
            "Time (s): 0.6287963390350342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 25 / 499\n",
            "LR: 8.856103289998499e-05\n",
            "Train loss: 0.8324682712554932\n",
            "\n",
            "Time (s): 0.6283407211303711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 26 / 499\n",
            "LR: 8.856085508568812e-05\n",
            "Train loss: 1.0744997262954712\n",
            "\n",
            "Time (s): 0.6293339729309082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 27 / 499\n",
            "LR: 8.856067727246232e-05\n",
            "Train loss: 0.7831705808639526\n",
            "\n",
            "Time (s): 0.6294643878936768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 28 / 499\n",
            "LR: 8.856049946030755e-05\n",
            "Train loss: 1.205858826637268\n",
            "\n",
            "Time (s): 0.6292722225189209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 29 / 499\n",
            "LR: 8.856032164922382e-05\n",
            "Train loss: 0.9283849596977234\n",
            "\n",
            "Time (s): 0.6286647319793701\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 30 / 499\n",
            "LR: 8.85601438392111e-05\n",
            "Train loss: 0.9708834290504456\n",
            "\n",
            "Time (s): 0.6305320262908936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 31 / 499\n",
            "LR: 8.855996603026937e-05\n",
            "Train loss: 0.7532712817192078\n",
            "\n",
            "Time (s): 0.6333932876586914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 32 / 499\n",
            "LR: 8.855978822239869e-05\n",
            "Train loss: 1.330253005027771\n",
            "\n",
            "Time (s): 0.629509687423706\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 33 / 499\n",
            "LR: 8.855961041559896e-05\n",
            "Train loss: 1.140880823135376\n",
            "\n",
            "Time (s): 0.6319670677185059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 34 / 499\n",
            "LR: 8.85594326098702e-05\n",
            "Train loss: 0.989359974861145\n",
            "\n",
            "Time (s): 0.6350700855255127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 35 / 499\n",
            "LR: 8.85592548052124e-05\n",
            "Train loss: 1.0720733404159546\n",
            "\n",
            "Time (s): 0.6314489841461182\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 36 / 499\n",
            "LR: 8.855907700162558e-05\n",
            "Train loss: 1.2181310653686523\n",
            "\n",
            "Time (s): 0.6301970481872559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 37 / 499\n",
            "LR: 8.85588991991097e-05\n",
            "Train loss: 0.5953055620193481\n",
            "\n",
            "Time (s): 0.6318464279174805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 38 / 499\n",
            "LR: 8.855872139766475e-05\n",
            "Train loss: 0.8089132905006409\n",
            "\n",
            "Time (s): 0.6316606998443604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 39 / 499\n",
            "LR: 8.85585435972907e-05\n",
            "Train loss: 0.7280881404876709\n",
            "\n",
            "Time (s): 0.6287055015563965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 40 / 499\n",
            "LR: 8.855836579798758e-05\n",
            "Train loss: 0.5971818566322327\n",
            "\n",
            "Time (s): 0.6328485012054443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 41 / 499\n",
            "LR: 8.855818799975537e-05\n",
            "Train loss: 0.4371051490306854\n",
            "\n",
            "Time (s): 0.6286046504974365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 42 / 499\n",
            "LR: 8.855801020259403e-05\n",
            "Train loss: 0.6804569959640503\n",
            "\n",
            "Time (s): 0.6313064098358154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 43 / 499\n",
            "LR: 8.855783240650359e-05\n",
            "Train loss: 1.320881962776184\n",
            "\n",
            "Time (s): 0.6302354335784912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 44 / 499\n",
            "LR: 8.8557654611484e-05\n",
            "Train loss: 0.4560600221157074\n",
            "\n",
            "Time (s): 0.6322295665740967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 45 / 499\n",
            "LR: 8.855747681753527e-05\n",
            "Train loss: 0.965920627117157\n",
            "\n",
            "Time (s): 0.6312332153320312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 46 / 499\n",
            "LR: 8.85572990246574e-05\n",
            "Train loss: 1.0867077112197876\n",
            "\n",
            "Time (s): 0.6305692195892334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 47 / 499\n",
            "LR: 8.855712123285038e-05\n",
            "Train loss: 0.5839413404464722\n",
            "\n",
            "Time (s): 0.6279604434967041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 48 / 499\n",
            "LR: 8.855694344211414e-05\n",
            "Train loss: 0.8389407992362976\n",
            "\n",
            "Time (s): 0.6293299198150635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 49 / 499\n",
            "LR: 8.855676565244873e-05\n",
            "Train loss: 0.8355104923248291\n",
            "\n",
            "Time (s): 0.6289160251617432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 50 / 499\n",
            "LR: 8.855658786385414e-05\n",
            "Train loss: 0.5797423124313354\n",
            "\n",
            "Time (s): 0.6338589191436768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 51 / 499\n",
            "LR: 8.855641007633033e-05\n",
            "Train loss: 0.9603816270828247\n",
            "\n",
            "Time (s): 0.6296632289886475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 52 / 499\n",
            "LR: 8.855623228987731e-05\n",
            "Train loss: 0.4974384605884552\n",
            "\n",
            "Time (s): 0.6309735774993896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 53 / 499\n",
            "LR: 8.855605450449507e-05\n",
            "Train loss: 0.482211172580719\n",
            "\n",
            "Time (s): 0.628889799118042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 54 / 499\n",
            "LR: 8.855587672018357e-05\n",
            "Train loss: 0.3349423408508301\n",
            "\n",
            "Time (s): 0.6309926509857178\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 55 / 499\n",
            "LR: 8.855569893694282e-05\n",
            "Train loss: 0.9900205135345459\n",
            "\n",
            "Time (s): 0.6332414150238037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 56 / 499\n",
            "LR: 8.855552115477283e-05\n",
            "Train loss: 1.3247419595718384\n",
            "\n",
            "Time (s): 0.6299581527709961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 57 / 499\n",
            "LR: 8.855534337367355e-05\n",
            "Train loss: 0.8811770677566528\n",
            "\n",
            "Time (s): 0.6291155815124512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 58 / 499\n",
            "LR: 8.855516559364499e-05\n",
            "Train loss: 1.0053508281707764\n",
            "\n",
            "Time (s): 0.6281418800354004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 59 / 499\n",
            "LR: 8.855498781468715e-05\n",
            "Train loss: 0.5994903445243835\n",
            "\n",
            "Time (s): 0.6243143081665039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 60 / 499\n",
            "LR: 8.85548100368e-05\n",
            "Train loss: 0.5135583877563477\n",
            "\n",
            "Time (s): 0.6304407119750977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 61 / 499\n",
            "LR: 8.855463225998354e-05\n",
            "Train loss: 0.5220919251441956\n",
            "\n",
            "Time (s): 0.6329476833343506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 62 / 499\n",
            "LR: 8.855445448423775e-05\n",
            "Train loss: 1.0514636039733887\n",
            "\n",
            "Time (s): 0.632204532623291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 63 / 499\n",
            "LR: 8.85542767095626e-05\n",
            "Train loss: 0.9493502378463745\n",
            "\n",
            "Time (s): 0.6283648014068604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 64 / 499\n",
            "LR: 8.855409893595815e-05\n",
            "Train loss: 0.76517254114151\n",
            "\n",
            "Time (s): 0.6246352195739746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 65 / 499\n",
            "LR: 8.855392116342431e-05\n",
            "Train loss: 1.0136523246765137\n",
            "\n",
            "Time (s): 0.6295123100280762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 66 / 499\n",
            "LR: 8.855374339196111e-05\n",
            "Train loss: 0.39488330483436584\n",
            "\n",
            "Time (s): 0.6274847984313965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 67 / 499\n",
            "LR: 8.855356562156853e-05\n",
            "Train loss: 0.637721061706543\n",
            "\n",
            "Time (s): 0.629227876663208\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 68 / 499\n",
            "LR: 8.855338785224657e-05\n",
            "Train loss: 0.38311073184013367\n",
            "\n",
            "Time (s): 0.6324751377105713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 69 / 499\n",
            "LR: 8.85532100839952e-05\n",
            "Train loss: 1.3902119398117065\n",
            "\n",
            "Time (s): 0.6289687156677246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 70 / 499\n",
            "LR: 8.855303231681442e-05\n",
            "Train loss: 0.5910047888755798\n",
            "\n",
            "Time (s): 0.6293492317199707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 71 / 499\n",
            "LR: 8.855285455070422e-05\n",
            "Train loss: 0.5549666285514832\n",
            "\n",
            "Time (s): 0.6323091983795166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 72 / 499\n",
            "LR: 8.855267678566458e-05\n",
            "Train loss: 1.0252668857574463\n",
            "\n",
            "Time (s): 0.628523588180542\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 73 / 499\n",
            "LR: 8.855249902169551e-05\n",
            "Train loss: 0.8506270051002502\n",
            "\n",
            "Time (s): 0.6329841613769531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 74 / 499\n",
            "LR: 8.855232125879698e-05\n",
            "Train loss: 0.5573279857635498\n",
            "\n",
            "Time (s): 0.6297256946563721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 75 / 499\n",
            "LR: 8.855214349696898e-05\n",
            "Train loss: 0.39530012011528015\n",
            "\n",
            "Time (s): 0.6331760883331299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 76 / 499\n",
            "LR: 8.85519657362115e-05\n",
            "Train loss: 0.7240365147590637\n",
            "\n",
            "Time (s): 0.6324799060821533\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 77 / 499\n",
            "LR: 8.855178797652455e-05\n",
            "Train loss: 1.390347957611084\n",
            "\n",
            "Time (s): 0.6308803558349609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 78 / 499\n",
            "LR: 8.855161021790809e-05\n",
            "Train loss: 0.411651074886322\n",
            "\n",
            "Time (s): 0.6290035247802734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 79 / 499\n",
            "LR: 8.855143246036212e-05\n",
            "Train loss: 0.9374309182167053\n",
            "\n",
            "Time (s): 0.6304049491882324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 80 / 499\n",
            "LR: 8.855125470388666e-05\n",
            "Train loss: 0.8783169388771057\n",
            "\n",
            "Time (s): 0.6339859962463379\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 81 / 499\n",
            "LR: 8.855107694848164e-05\n",
            "Train loss: 1.3816004991531372\n",
            "\n",
            "Time (s): 0.6317012310028076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 82 / 499\n",
            "LR: 8.855089919414709e-05\n",
            "Train loss: 0.8715423345565796\n",
            "\n",
            "Time (s): 0.6318929195404053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 83 / 499\n",
            "LR: 8.8550721440883e-05\n",
            "Train loss: 0.8148719668388367\n",
            "\n",
            "Time (s): 0.6301648616790771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 84 / 499\n",
            "LR: 8.855054368868932e-05\n",
            "Train loss: 0.5563324689865112\n",
            "\n",
            "Time (s): 0.6311068534851074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 85 / 499\n",
            "LR: 8.85503659375661e-05\n",
            "Train loss: 0.4060302674770355\n",
            "\n",
            "Time (s): 0.6336050033569336\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 86 / 499\n",
            "LR: 8.855018818751326e-05\n",
            "Train loss: 0.9677912592887878\n",
            "\n",
            "Time (s): 0.6314647197723389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 87 / 499\n",
            "LR: 8.855001043853087e-05\n",
            "Train loss: 0.9645174145698547\n",
            "\n",
            "Time (s): 0.6297264099121094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 88 / 499\n",
            "LR: 8.854983269061885e-05\n",
            "Train loss: 0.5294283032417297\n",
            "\n",
            "Time (s): 0.6337189674377441\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 89 / 499\n",
            "LR: 8.854965494377721e-05\n",
            "Train loss: 1.4021095037460327\n",
            "\n",
            "Time (s): 0.6302409172058105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 90 / 499\n",
            "LR: 8.854947719800596e-05\n",
            "Train loss: 1.1535837650299072\n",
            "\n",
            "Time (s): 0.6267497539520264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 91 / 499\n",
            "LR: 8.854929945330506e-05\n",
            "Train loss: 0.7497318387031555\n",
            "\n",
            "Time (s): 0.6338527202606201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 92 / 499\n",
            "LR: 8.85491217096745e-05\n",
            "Train loss: 0.8451699614524841\n",
            "\n",
            "Time (s): 0.6313903331756592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 93 / 499\n",
            "LR: 8.854894396711431e-05\n",
            "Train loss: 1.0246785879135132\n",
            "\n",
            "Time (s): 0.6323709487915039\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 94 / 499\n",
            "LR: 8.854876622562445e-05\n",
            "Train loss: 1.3881033658981323\n",
            "\n",
            "Time (s): 0.6343438625335693\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 95 / 499\n",
            "LR: 8.854858848520491e-05\n",
            "Train loss: 0.24755749106407166\n",
            "\n",
            "Time (s): 0.6336467266082764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 96 / 499\n",
            "LR: 8.854841074585566e-05\n",
            "Train loss: 0.32723814249038696\n",
            "\n",
            "Time (s): 0.6309168338775635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 97 / 499\n",
            "LR: 8.854823300757673e-05\n",
            "Train loss: 0.5117074847221375\n",
            "\n",
            "Time (s): 0.6316678524017334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 98 / 499\n",
            "LR: 8.854805527036807e-05\n",
            "Train loss: 0.57133549451828\n",
            "\n",
            "Time (s): 0.6287825107574463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 99 / 499\n",
            "LR: 8.854787753422971e-05\n",
            "Train loss: 0.4901560842990875\n",
            "\n",
            "Time (s): 0.6341953277587891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 100 / 499\n",
            "LR: 8.854769979916159e-05\n",
            "Train loss: 0.810948371887207\n",
            "\n",
            "Time (s): 0.6326127052307129\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 101 / 499\n",
            "LR: 8.854752206516374e-05\n",
            "Train loss: 0.8096792101860046\n",
            "\n",
            "Time (s): 0.6288001537322998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 102 / 499\n",
            "LR: 8.854734433223611e-05\n",
            "Train loss: 1.6021413803100586\n",
            "\n",
            "Time (s): 0.6366753578186035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 103 / 499\n",
            "LR: 8.854716660037875e-05\n",
            "Train loss: 0.7097281813621521\n",
            "\n",
            "Time (s): 0.6298058032989502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 104 / 499\n",
            "LR: 8.85469888695916e-05\n",
            "Train loss: 1.0879603624343872\n",
            "\n",
            "Time (s): 0.6333308219909668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 105 / 499\n",
            "LR: 8.854681113987466e-05\n",
            "Train loss: 0.8170969486236572\n",
            "\n",
            "Time (s): 0.6290297508239746\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 106 / 499\n",
            "LR: 8.854663341122793e-05\n",
            "Train loss: 0.4687029719352722\n",
            "\n",
            "Time (s): 0.6298503875732422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 107 / 499\n",
            "LR: 8.854645568365138e-05\n",
            "Train loss: 1.0122846364974976\n",
            "\n",
            "Time (s): 0.6238350868225098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 108 / 499\n",
            "LR: 8.854627795714501e-05\n",
            "Train loss: 0.9162189364433289\n",
            "\n",
            "Time (s): 0.6288774013519287\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 109 / 499\n",
            "LR: 8.854610023170884e-05\n",
            "Train loss: 1.1723206043243408\n",
            "\n",
            "Time (s): 0.6261045932769775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 110 / 499\n",
            "LR: 8.85459225073428e-05\n",
            "Train loss: 0.8990753889083862\n",
            "\n",
            "Time (s): 0.6274449825286865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 111 / 499\n",
            "LR: 8.854574478404692e-05\n",
            "Train loss: 0.4633837342262268\n",
            "\n",
            "Time (s): 0.6317031383514404\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 112 / 499\n",
            "LR: 8.854556706182116e-05\n",
            "Train loss: 1.2023979425430298\n",
            "\n",
            "Time (s): 0.6310129165649414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 113 / 499\n",
            "LR: 8.854538934066556e-05\n",
            "Train loss: 0.8339350819587708\n",
            "\n",
            "Time (s): 0.6245450973510742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 114 / 499\n",
            "LR: 8.854521162058004e-05\n",
            "Train loss: 0.3618752658367157\n",
            "\n",
            "Time (s): 0.6303629875183105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 115 / 499\n",
            "LR: 8.854503390156465e-05\n",
            "Train loss: 0.5966386795043945\n",
            "\n",
            "Time (s): 0.6293699741363525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 116 / 499\n",
            "LR: 8.854485618361935e-05\n",
            "Train loss: 0.6126745343208313\n",
            "\n",
            "Time (s): 0.6275894641876221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 117 / 499\n",
            "LR: 8.854467846674411e-05\n",
            "Train loss: 0.8075068593025208\n",
            "\n",
            "Time (s): 0.6284949779510498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 118 / 499\n",
            "LR: 8.854450075093896e-05\n",
            "Train loss: 0.7535250186920166\n",
            "\n",
            "Time (s): 0.6311399936676025\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 119 / 499\n",
            "LR: 8.854432303620389e-05\n",
            "Train loss: 0.9934636354446411\n",
            "\n",
            "Time (s): 0.6298508644104004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 120 / 499\n",
            "LR: 8.854414532253886e-05\n",
            "Train loss: 0.8649674654006958\n",
            "\n",
            "Time (s): 0.6259045600891113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 121 / 499\n",
            "LR: 8.854396760994388e-05\n",
            "Train loss: 0.8117255568504333\n",
            "\n",
            "Time (s): 0.6287024021148682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 122 / 499\n",
            "LR: 8.85437898984189e-05\n",
            "Train loss: 0.9982599020004272\n",
            "\n",
            "Time (s): 0.6344070434570312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 123 / 499\n",
            "LR: 8.854361218796397e-05\n",
            "Train loss: 0.3807806074619293\n",
            "\n",
            "Time (s): 0.6332757472991943\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 124 / 499\n",
            "LR: 8.854343447857903e-05\n",
            "Train loss: 0.8107625842094421\n",
            "\n",
            "Time (s): 0.6303849220275879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 125 / 499\n",
            "LR: 8.85432567702641e-05\n",
            "Train loss: 0.6131609082221985\n",
            "\n",
            "Time (s): 0.6294753551483154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 126 / 499\n",
            "LR: 8.854307906301913e-05\n",
            "Train loss: 0.6412423253059387\n",
            "\n",
            "Time (s): 0.6274306774139404\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 127 / 499\n",
            "LR: 8.854290135684419e-05\n",
            "Train loss: 1.2455213069915771\n",
            "\n",
            "Time (s): 0.6353683471679688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 128 / 499\n",
            "LR: 8.854272365173917e-05\n",
            "Train loss: 0.9196181297302246\n",
            "\n",
            "Time (s): 0.627901554107666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 129 / 499\n",
            "LR: 8.854254594770413e-05\n",
            "Train loss: 0.7007043361663818\n",
            "\n",
            "Time (s): 0.6315937042236328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 130 / 499\n",
            "LR: 8.854236824473902e-05\n",
            "Train loss: 0.48379644751548767\n",
            "\n",
            "Time (s): 0.623950719833374\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 131 / 499\n",
            "LR: 8.854219054284384e-05\n",
            "Train loss: 0.6547374129295349\n",
            "\n",
            "Time (s): 0.6323328018188477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 132 / 499\n",
            "LR: 8.854201284201858e-05\n",
            "Train loss: 0.6822503805160522\n",
            "\n",
            "Time (s): 0.6307590007781982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 133 / 499\n",
            "LR: 8.854183514226327e-05\n",
            "Train loss: 0.9169020056724548\n",
            "\n",
            "Time (s): 0.6278359889984131\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 134 / 499\n",
            "LR: 8.854165744357781e-05\n",
            "Train loss: 0.7292634844779968\n",
            "\n",
            "Time (s): 0.628490686416626\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 135 / 499\n",
            "LR: 8.854147974596227e-05\n",
            "Train loss: 0.307621031999588\n",
            "\n",
            "Time (s): 0.6314990520477295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 136 / 499\n",
            "LR: 8.854130204941661e-05\n",
            "Train loss: 0.9768164753913879\n",
            "\n",
            "Time (s): 0.6317238807678223\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 137 / 499\n",
            "LR: 8.85411243539408e-05\n",
            "Train loss: 0.6327235698699951\n",
            "\n",
            "Time (s): 0.6281707286834717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 138 / 499\n",
            "LR: 8.854094665953488e-05\n",
            "Train loss: 0.37387824058532715\n",
            "\n",
            "Time (s): 0.6341922283172607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 139 / 499\n",
            "LR: 8.854076896619878e-05\n",
            "Train loss: 1.1116174459457397\n",
            "\n",
            "Time (s): 0.6343014240264893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 140 / 499\n",
            "LR: 8.854059127393254e-05\n",
            "Train loss: 0.9552842974662781\n",
            "\n",
            "Time (s): 0.6314284801483154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 141 / 499\n",
            "LR: 8.854041358273612e-05\n",
            "Train loss: 1.5863314867019653\n",
            "\n",
            "Time (s): 0.6323518753051758\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 142 / 499\n",
            "LR: 8.854023589260951e-05\n",
            "Train loss: 0.8219747543334961\n",
            "\n",
            "Time (s): 0.6315176486968994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 143 / 499\n",
            "LR: 8.85400582035527e-05\n",
            "Train loss: 0.6977530717849731\n",
            "\n",
            "Time (s): 0.6342909336090088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 144 / 499\n",
            "LR: 8.853988051556569e-05\n",
            "Train loss: 0.6950452327728271\n",
            "\n",
            "Time (s): 0.6276304721832275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 145 / 499\n",
            "LR: 8.853970282864846e-05\n",
            "Train loss: 1.3895893096923828\n",
            "\n",
            "Time (s): 0.6301794052124023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 146 / 499\n",
            "LR: 8.853952514280102e-05\n",
            "Train loss: 0.5426854491233826\n",
            "\n",
            "Time (s): 0.6291718482971191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 147 / 499\n",
            "LR: 8.85393474580233e-05\n",
            "Train loss: 0.9285265803337097\n",
            "\n",
            "Time (s): 0.6262531280517578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 148 / 499\n",
            "LR: 8.853916977431537e-05\n",
            "Train loss: 0.3300473093986511\n",
            "\n",
            "Time (s): 0.6239447593688965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 149 / 499\n",
            "LR: 8.853899209167717e-05\n",
            "Train loss: 1.0704236030578613\n",
            "\n",
            "Time (s): 0.6284267902374268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 150 / 499\n",
            "LR: 8.85388144101087e-05\n",
            "Train loss: 1.0317285060882568\n",
            "\n",
            "Time (s): 0.6284868717193604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 151 / 499\n",
            "LR: 8.853863672960995e-05\n",
            "Train loss: 0.7307289838790894\n",
            "\n",
            "Time (s): 0.6283609867095947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 152 / 499\n",
            "LR: 8.85384590501809e-05\n",
            "Train loss: 1.0858182907104492\n",
            "\n",
            "Time (s): 0.6255342960357666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 153 / 499\n",
            "LR: 8.853828137182155e-05\n",
            "Train loss: 0.6902603507041931\n",
            "\n",
            "Time (s): 0.6306383609771729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 154 / 499\n",
            "LR: 8.85381036945319e-05\n",
            "Train loss: 1.1354939937591553\n",
            "\n",
            "Time (s): 0.6266214847564697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 155 / 499\n",
            "LR: 8.85379260183119e-05\n",
            "Train loss: 0.6700952053070068\n",
            "\n",
            "Time (s): 0.6236696243286133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 156 / 499\n",
            "LR: 8.853774834316159e-05\n",
            "Train loss: 1.325827717781067\n",
            "\n",
            "Time (s): 0.6291854381561279\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 157 / 499\n",
            "LR: 8.853757066908093e-05\n",
            "Train loss: 0.5718138217926025\n",
            "\n",
            "Time (s): 0.6320362091064453\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 158 / 499\n",
            "LR: 8.853739299606991e-05\n",
            "Train loss: 0.47808602452278137\n",
            "\n",
            "Time (s): 0.628976583480835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 159 / 499\n",
            "LR: 8.853721532412852e-05\n",
            "Train loss: 0.5158692002296448\n",
            "\n",
            "Time (s): 0.6310782432556152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 160 / 499\n",
            "LR: 8.853703765325676e-05\n",
            "Train loss: 0.4097294211387634\n",
            "\n",
            "Time (s): 0.6281619071960449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 161 / 499\n",
            "LR: 8.85368599834546e-05\n",
            "Train loss: 0.9792106747627258\n",
            "\n",
            "Time (s): 0.6286187171936035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 162 / 499\n",
            "LR: 8.853668231472205e-05\n",
            "Train loss: 0.8602386713027954\n",
            "\n",
            "Time (s): 0.6321568489074707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 163 / 499\n",
            "LR: 8.853650464705909e-05\n",
            "Train loss: 0.3657650053501129\n",
            "\n",
            "Time (s): 0.6285347938537598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 164 / 499\n",
            "LR: 8.853632698046571e-05\n",
            "Train loss: 0.9228090047836304\n",
            "\n",
            "Time (s): 0.6287696361541748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 165 / 499\n",
            "LR: 8.85361493149419e-05\n",
            "Train loss: 0.7106293439865112\n",
            "\n",
            "Time (s): 0.633009672164917\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 166 / 499\n",
            "LR: 8.853597165048763e-05\n",
            "Train loss: 1.0150399208068848\n",
            "\n",
            "Time (s): 0.628232479095459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 167 / 499\n",
            "LR: 8.853579398710293e-05\n",
            "Train loss: 1.1209343671798706\n",
            "\n",
            "Time (s): 0.6284286975860596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 168 / 499\n",
            "LR: 8.853561632478776e-05\n",
            "Train loss: 1.1846895217895508\n",
            "\n",
            "Time (s): 0.6295957565307617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 169 / 499\n",
            "LR: 8.85354386635421e-05\n",
            "Train loss: 0.9457793831825256\n",
            "\n",
            "Time (s): 0.6334197521209717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 170 / 499\n",
            "LR: 8.853526100336597e-05\n",
            "Train loss: 0.7818706035614014\n",
            "\n",
            "Time (s): 0.6288402080535889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 171 / 499\n",
            "LR: 8.853508334425936e-05\n",
            "Train loss: 0.7326768040657043\n",
            "\n",
            "Time (s): 0.6287670135498047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 172 / 499\n",
            "LR: 8.853490568622223e-05\n",
            "Train loss: 1.3251270055770874\n",
            "\n",
            "Time (s): 0.6279001235961914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 173 / 499\n",
            "LR: 8.853472802925457e-05\n",
            "Train loss: 0.46987414360046387\n",
            "\n",
            "Time (s): 0.6277103424072266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 174 / 499\n",
            "LR: 8.853455037335639e-05\n",
            "Train loss: 1.9046998023986816\n",
            "\n",
            "Time (s): 0.6326768398284912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 175 / 499\n",
            "LR: 8.853437271852768e-05\n",
            "Train loss: 0.7753557562828064\n",
            "\n",
            "Time (s): 0.6304206848144531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 176 / 499\n",
            "LR: 8.853419506476839e-05\n",
            "Train loss: 1.1501766443252563\n",
            "\n",
            "Time (s): 0.6358363628387451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 177 / 499\n",
            "LR: 8.853401741207858e-05\n",
            "Train loss: 0.9902616143226624\n",
            "\n",
            "Time (s): 0.6288893222808838\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 178 / 499\n",
            "LR: 8.853383976045818e-05\n",
            "Train loss: 0.4372682571411133\n",
            "\n",
            "Time (s): 0.6318156719207764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 179 / 499\n",
            "LR: 8.853366210990721e-05\n",
            "Train loss: 0.816822350025177\n",
            "\n",
            "Time (s): 0.6306281089782715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 180 / 499\n",
            "LR: 8.853348446042562e-05\n",
            "Train loss: 0.5534828901290894\n",
            "\n",
            "Time (s): 0.629812479019165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 181 / 499\n",
            "LR: 8.853330681201346e-05\n",
            "Train loss: 0.8889712691307068\n",
            "\n",
            "Time (s): 0.6287827491760254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 182 / 499\n",
            "LR: 8.853312916467067e-05\n",
            "Train loss: 0.41080039739608765\n",
            "\n",
            "Time (s): 0.6285881996154785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 183 / 499\n",
            "LR: 8.853295151839726e-05\n",
            "Train loss: 0.45881351828575134\n",
            "\n",
            "Time (s): 0.6287665367126465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 184 / 499\n",
            "LR: 8.85327738731932e-05\n",
            "Train loss: 1.3883265256881714\n",
            "\n",
            "Time (s): 0.6325857639312744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 185 / 499\n",
            "LR: 8.853259622905853e-05\n",
            "Train loss: 1.4958257675170898\n",
            "\n",
            "Time (s): 0.6312053203582764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 186 / 499\n",
            "LR: 8.853241858599316e-05\n",
            "Train loss: 0.7798113226890564\n",
            "\n",
            "Time (s): 0.6317226886749268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 187 / 499\n",
            "LR: 8.853224094399716e-05\n",
            "Train loss: 0.44673892855644226\n",
            "\n",
            "Time (s): 0.6285433769226074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 188 / 499\n",
            "LR: 8.853206330307045e-05\n",
            "Train loss: 0.4794413447380066\n",
            "\n",
            "Time (s): 0.632314920425415\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 189 / 499\n",
            "LR: 8.853188566321307e-05\n",
            "Train loss: 1.129059910774231\n",
            "\n",
            "Time (s): 0.6302292346954346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 190 / 499\n",
            "LR: 8.853170802442499e-05\n",
            "Train loss: 1.336474061012268\n",
            "\n",
            "Time (s): 0.6305489540100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 191 / 499\n",
            "LR: 8.853153038670618e-05\n",
            "Train loss: 0.4899469316005707\n",
            "\n",
            "Time (s): 0.635077714920044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 192 / 499\n",
            "LR: 8.853135275005667e-05\n",
            "Train loss: 0.7451968789100647\n",
            "\n",
            "Time (s): 0.6335697174072266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 193 / 499\n",
            "LR: 8.853117511447642e-05\n",
            "Train loss: 1.1435520648956299\n",
            "\n",
            "Time (s): 0.6348104476928711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 194 / 499\n",
            "LR: 8.853099747996544e-05\n",
            "Train loss: 0.4936686158180237\n",
            "\n",
            "Time (s): 0.6287481784820557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 195 / 499\n",
            "LR: 8.85308198465237e-05\n",
            "Train loss: 0.6587921977043152\n",
            "\n",
            "Time (s): 0.6261909008026123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 196 / 499\n",
            "LR: 8.853064221415118e-05\n",
            "Train loss: 1.0266165733337402\n",
            "\n",
            "Time (s): 0.6292400360107422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 197 / 499\n",
            "LR: 8.853046458284791e-05\n",
            "Train loss: 0.33378833532333374\n",
            "\n",
            "Time (s): 0.6303284168243408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 198 / 499\n",
            "LR: 8.853028695261385e-05\n",
            "Train loss: 0.6723542809486389\n",
            "\n",
            "Time (s): 0.6281483173370361\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 199 / 499\n",
            "LR: 8.853010932344897e-05\n",
            "Train loss: 0.72771817445755\n",
            "\n",
            "Time (s): 0.6305763721466064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 200 / 499\n",
            "LR: 8.85299316953533e-05\n",
            "Train loss: 0.9588611721992493\n",
            "\n",
            "Time (s): 0.6291940212249756\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 201 / 499\n",
            "LR: 8.852975406832683e-05\n",
            "Train loss: 0.8119068145751953\n",
            "\n",
            "Time (s): 0.6329362392425537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 202 / 499\n",
            "LR: 8.852957644236951e-05\n",
            "Train loss: 0.9873515963554382\n",
            "\n",
            "Time (s): 0.6286454200744629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 203 / 499\n",
            "LR: 8.852939881748136e-05\n",
            "Train loss: 0.5223691463470459\n",
            "\n",
            "Time (s): 0.633352518081665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 204 / 499\n",
            "LR: 8.852922119366236e-05\n",
            "Train loss: 1.460905909538269\n",
            "\n",
            "Time (s): 0.6298508644104004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 205 / 499\n",
            "LR: 8.85290435709125e-05\n",
            "Train loss: 1.5698857307434082\n",
            "\n",
            "Time (s): 0.6348674297332764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 206 / 499\n",
            "LR: 8.852886594923176e-05\n",
            "Train loss: 0.8953282237052917\n",
            "\n",
            "Time (s): 0.6316359043121338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 207 / 499\n",
            "LR: 8.852868832862014e-05\n",
            "Train loss: 0.7118620872497559\n",
            "\n",
            "Time (s): 0.6313884258270264\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 208 / 499\n",
            "LR: 8.852851070907762e-05\n",
            "Train loss: 0.3978129029273987\n",
            "\n",
            "Time (s): 0.6366977691650391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 209 / 499\n",
            "LR: 8.85283330906042e-05\n",
            "Train loss: 0.6209472417831421\n",
            "\n",
            "Time (s): 0.635016679763794\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 210 / 499\n",
            "LR: 8.85281554731999e-05\n",
            "Train loss: 1.3697152137756348\n",
            "\n",
            "Time (s): 0.6279549598693848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 211 / 499\n",
            "LR: 8.852797785686464e-05\n",
            "Train loss: 0.9426303505897522\n",
            "\n",
            "Time (s): 0.6346540451049805\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 212 / 499\n",
            "LR: 8.852780024159845e-05\n",
            "Train loss: 1.6201584339141846\n",
            "\n",
            "Time (s): 0.6346819400787354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 213 / 499\n",
            "LR: 8.852762262740133e-05\n",
            "Train loss: 0.4102383255958557\n",
            "\n",
            "Time (s): 0.6347377300262451\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 214 / 499\n",
            "LR: 8.852744501427324e-05\n",
            "Train loss: 0.9373882412910461\n",
            "\n",
            "Time (s): 0.6323413848876953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 215 / 499\n",
            "LR: 8.852726740221417e-05\n",
            "Train loss: 0.9200876355171204\n",
            "\n",
            "Time (s): 0.6287651062011719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 216 / 499\n",
            "LR: 8.852708979122414e-05\n",
            "Train loss: 0.2851206958293915\n",
            "\n",
            "Time (s): 0.6338300704956055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 217 / 499\n",
            "LR: 8.852691218130312e-05\n",
            "Train loss: 0.9530237913131714\n",
            "\n",
            "Time (s): 0.624664306640625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 218 / 499\n",
            "LR: 8.852673457245108e-05\n",
            "Train loss: 0.9154368042945862\n",
            "\n",
            "Time (s): 0.6328125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 219 / 499\n",
            "LR: 8.852655696466804e-05\n",
            "Train loss: 1.1509921550750732\n",
            "\n",
            "Time (s): 0.6305007934570312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 220 / 499\n",
            "LR: 8.852637935795397e-05\n",
            "Train loss: 0.217840775847435\n",
            "\n",
            "Time (s): 0.6318438053131104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 221 / 499\n",
            "LR: 8.85262017523089e-05\n",
            "Train loss: 1.1254191398620605\n",
            "\n",
            "Time (s): 0.6313645839691162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 222 / 499\n",
            "LR: 8.852602414773276e-05\n",
            "Train loss: 0.7672403454780579\n",
            "\n",
            "Time (s): 0.6340782642364502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 223 / 499\n",
            "LR: 8.852584654422559e-05\n",
            "Train loss: 0.7052844166755676\n",
            "\n",
            "Time (s): 0.6336534023284912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 224 / 499\n",
            "LR: 8.852566894178735e-05\n",
            "Train loss: 0.46662092208862305\n",
            "\n",
            "Time (s): 0.6320950984954834\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 225 / 499\n",
            "LR: 8.8525491340418e-05\n",
            "Train loss: 1.1508609056472778\n",
            "\n",
            "Time (s): 0.6340830326080322\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 226 / 499\n",
            "LR: 8.85253137401176e-05\n",
            "Train loss: 0.7568048238754272\n",
            "\n",
            "Time (s): 0.630887508392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 227 / 499\n",
            "LR: 8.85251361408861e-05\n",
            "Train loss: 0.9853224754333496\n",
            "\n",
            "Time (s): 0.6341953277587891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 228 / 499\n",
            "LR: 8.852495854272349e-05\n",
            "Train loss: 0.7476438283920288\n",
            "\n",
            "Time (s): 0.6321446895599365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 229 / 499\n",
            "LR: 8.852478094562975e-05\n",
            "Train loss: 0.6623649597167969\n",
            "\n",
            "Time (s): 0.6336312294006348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 230 / 499\n",
            "LR: 8.852460334960489e-05\n",
            "Train loss: 0.37868255376815796\n",
            "\n",
            "Time (s): 0.6303918361663818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 231 / 499\n",
            "LR: 8.85244257546489e-05\n",
            "Train loss: 1.365465760231018\n",
            "\n",
            "Time (s): 0.6329243183135986\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 232 / 499\n",
            "LR: 8.852424816076174e-05\n",
            "Train loss: 1.0464693307876587\n",
            "\n",
            "Time (s): 0.6332790851593018\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 233 / 499\n",
            "LR: 8.852407056794344e-05\n",
            "Train loss: 0.613987386226654\n",
            "\n",
            "Time (s): 0.6336512565612793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 234 / 499\n",
            "LR: 8.852389297619396e-05\n",
            "Train loss: 0.2856375277042389\n",
            "\n",
            "Time (s): 0.6284546852111816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 235 / 499\n",
            "LR: 8.852371538551327e-05\n",
            "Train loss: 0.7462325692176819\n",
            "\n",
            "Time (s): 0.631662130355835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 236 / 499\n",
            "LR: 8.852353779590143e-05\n",
            "Train loss: 1.370307445526123\n",
            "\n",
            "Time (s): 0.6263222694396973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 237 / 499\n",
            "LR: 8.852336020735837e-05\n",
            "Train loss: 1.0505342483520508\n",
            "\n",
            "Time (s): 0.6238932609558105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 238 / 499\n",
            "LR: 8.85231826198841e-05\n",
            "Train loss: 0.8135796785354614\n",
            "\n",
            "Time (s): 0.6296772956848145\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 239 / 499\n",
            "LR: 8.852300503347859e-05\n",
            "Train loss: 1.1427422761917114\n",
            "\n",
            "Time (s): 0.6287264823913574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 240 / 499\n",
            "LR: 8.852282744814186e-05\n",
            "Train loss: 0.9316777586936951\n",
            "\n",
            "Time (s): 0.6336357593536377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 241 / 499\n",
            "LR: 8.852264986387387e-05\n",
            "Train loss: 1.1801609992980957\n",
            "\n",
            "Time (s): 0.6269292831420898\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 242 / 499\n",
            "LR: 8.852247228067463e-05\n",
            "Train loss: 0.4904906451702118\n",
            "\n",
            "Time (s): 0.6339106559753418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 243 / 499\n",
            "LR: 8.852229469854414e-05\n",
            "Train loss: 1.2199898958206177\n",
            "\n",
            "Time (s): 0.6292240619659424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 244 / 499\n",
            "LR: 8.852211711748234e-05\n",
            "Train loss: 0.5360066294670105\n",
            "\n",
            "Time (s): 0.633720874786377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 245 / 499\n",
            "LR: 8.852193953748927e-05\n",
            "Train loss: 0.4817452132701874\n",
            "\n",
            "Time (s): 0.6311020851135254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 246 / 499\n",
            "LR: 8.852176195856492e-05\n",
            "Train loss: 1.3337912559509277\n",
            "\n",
            "Time (s): 0.6303873062133789\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 247 / 499\n",
            "LR: 8.852158438070922e-05\n",
            "Train loss: 0.9118488430976868\n",
            "\n",
            "Time (s): 0.6328914165496826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 248 / 499\n",
            "LR: 8.852140680392222e-05\n",
            "Train loss: 0.9732916355133057\n",
            "\n",
            "Time (s): 0.6261694431304932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 249 / 499\n",
            "LR: 8.852122922820387e-05\n",
            "Train loss: 0.7755449414253235\n",
            "\n",
            "Time (s): 0.6314239501953125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 250 / 499\n",
            "LR: 8.85210516535542e-05\n",
            "Train loss: 0.9443520307540894\n",
            "\n",
            "Time (s): 0.6291284561157227\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 251 / 499\n",
            "LR: 8.852087407997315e-05\n",
            "Train loss: 0.7324491739273071\n",
            "\n",
            "Time (s): 0.6318454742431641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 252 / 499\n",
            "LR: 8.852069650746076e-05\n",
            "Train loss: 0.5849035382270813\n",
            "\n",
            "Time (s): 0.629371166229248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 253 / 499\n",
            "LR: 8.852051893601699e-05\n",
            "Train loss: 0.5195577144622803\n",
            "\n",
            "Time (s): 0.6291542053222656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 254 / 499\n",
            "LR: 8.852034136564182e-05\n",
            "Train loss: 0.5581855773925781\n",
            "\n",
            "Time (s): 0.6288959980010986\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 255 / 499\n",
            "LR: 8.852016379633526e-05\n",
            "Train loss: 1.1251624822616577\n",
            "\n",
            "Time (s): 0.6321444511413574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 256 / 499\n",
            "LR: 8.85199862280973e-05\n",
            "Train loss: 0.6994933485984802\n",
            "\n",
            "Time (s): 0.630509614944458\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 257 / 499\n",
            "LR: 8.85198086609279e-05\n",
            "Train loss: 0.6664509773254395\n",
            "\n",
            "Time (s): 0.6313250064849854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 258 / 499\n",
            "LR: 8.851963109482711e-05\n",
            "Train loss: 0.8941479325294495\n",
            "\n",
            "Time (s): 0.6261565685272217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 259 / 499\n",
            "LR: 8.851945352979485e-05\n",
            "Train loss: 1.1412678956985474\n",
            "\n",
            "Time (s): 0.6247706413269043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 260 / 499\n",
            "LR: 8.851927596583116e-05\n",
            "Train loss: 0.6221024394035339\n",
            "\n",
            "Time (s): 0.6250169277191162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 261 / 499\n",
            "LR: 8.8519098402936e-05\n",
            "Train loss: 0.5542511940002441\n",
            "\n",
            "Time (s): 0.6241190433502197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 262 / 499\n",
            "LR: 8.851892084110937e-05\n",
            "Train loss: 0.35793063044548035\n",
            "\n",
            "Time (s): 0.6240267753601074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 263 / 499\n",
            "LR: 8.851874328035126e-05\n",
            "Train loss: 0.6551520824432373\n",
            "\n",
            "Time (s): 0.6318018436431885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 264 / 499\n",
            "LR: 8.851856572066164e-05\n",
            "Train loss: 0.7847477197647095\n",
            "\n",
            "Time (s): 0.6287167072296143\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 265 / 499\n",
            "LR: 8.851838816204054e-05\n",
            "Train loss: 1.1607139110565186\n",
            "\n",
            "Time (s): 0.631676197052002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 266 / 499\n",
            "LR: 8.851821060448789e-05\n",
            "Train loss: 0.6530558466911316\n",
            "\n",
            "Time (s): 0.6285960674285889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 267 / 499\n",
            "LR: 8.851803304800375e-05\n",
            "Train loss: 0.7587856650352478\n",
            "\n",
            "Time (s): 0.6249139308929443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 268 / 499\n",
            "LR: 8.851785549258806e-05\n",
            "Train loss: 0.6131029725074768\n",
            "\n",
            "Time (s): 0.6295881271362305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 269 / 499\n",
            "LR: 8.851767793824083e-05\n",
            "Train loss: 0.41569650173187256\n",
            "\n",
            "Time (s): 0.6258454322814941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 270 / 499\n",
            "LR: 8.851750038496203e-05\n",
            "Train loss: 1.234934687614441\n",
            "\n",
            "Time (s): 0.6330721378326416\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 271 / 499\n",
            "LR: 8.851732283275168e-05\n",
            "Train loss: 0.7263299226760864\n",
            "\n",
            "Time (s): 0.6274862289428711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 272 / 499\n",
            "LR: 8.851714528160973e-05\n",
            "Train loss: 0.8974738717079163\n",
            "\n",
            "Time (s): 0.6283111572265625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 273 / 499\n",
            "LR: 8.85169677315362e-05\n",
            "Train loss: 0.7262349128723145\n",
            "\n",
            "Time (s): 0.6293411254882812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 274 / 499\n",
            "LR: 8.851679018253108e-05\n",
            "Train loss: 0.6067938804626465\n",
            "\n",
            "Time (s): 0.627061128616333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 275 / 499\n",
            "LR: 8.851661263459434e-05\n",
            "Train loss: 1.0882856845855713\n",
            "\n",
            "Time (s): 0.6241331100463867\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 276 / 499\n",
            "LR: 8.851643508772598e-05\n",
            "Train loss: 0.750902533531189\n",
            "\n",
            "Time (s): 0.6295809745788574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 277 / 499\n",
            "LR: 8.8516257541926e-05\n",
            "Train loss: 0.5376654863357544\n",
            "\n",
            "Time (s): 0.6233956813812256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 278 / 499\n",
            "LR: 8.851607999719437e-05\n",
            "Train loss: 0.7132683396339417\n",
            "\n",
            "Time (s): 0.627500057220459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 279 / 499\n",
            "LR: 8.851590245353108e-05\n",
            "Train loss: 0.5825656652450562\n",
            "\n",
            "Time (s): 0.6280508041381836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 280 / 499\n",
            "LR: 8.85157249109361e-05\n",
            "Train loss: 0.7498986721038818\n",
            "\n",
            "Time (s): 0.6289327144622803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 281 / 499\n",
            "LR: 8.85155473694095e-05\n",
            "Train loss: 1.1637886762619019\n",
            "\n",
            "Time (s): 0.6273922920227051\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 282 / 499\n",
            "LR: 8.851536982895117e-05\n",
            "Train loss: 0.980412483215332\n",
            "\n",
            "Time (s): 0.6288909912109375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 283 / 499\n",
            "LR: 8.851519228956117e-05\n",
            "Train loss: 0.4590783417224884\n",
            "\n",
            "Time (s): 0.6295881271362305\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 284 / 499\n",
            "LR: 8.851501475123944e-05\n",
            "Train loss: 0.9040285348892212\n",
            "\n",
            "Time (s): 0.6306507587432861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 285 / 499\n",
            "LR: 8.8514837213986e-05\n",
            "Train loss: 0.451388955116272\n",
            "\n",
            "Time (s): 0.6322340965270996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 286 / 499\n",
            "LR: 8.851465967780086e-05\n",
            "Train loss: 0.7411310076713562\n",
            "\n",
            "Time (s): 0.6240463256835938\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 287 / 499\n",
            "LR: 8.851448214268395e-05\n",
            "Train loss: 1.2518236637115479\n",
            "\n",
            "Time (s): 0.628241777420044\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 288 / 499\n",
            "LR: 8.851430460863529e-05\n",
            "Train loss: 1.107346534729004\n",
            "\n",
            "Time (s): 0.6240255832672119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 289 / 499\n",
            "LR: 8.851412707565488e-05\n",
            "Train loss: 1.0759656429290771\n",
            "\n",
            "Time (s): 0.6331422328948975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 290 / 499\n",
            "LR: 8.851394954374269e-05\n",
            "Train loss: 0.6416458487510681\n",
            "\n",
            "Time (s): 0.6309397220611572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 291 / 499\n",
            "LR: 8.851377201289873e-05\n",
            "Train loss: 0.9560652375221252\n",
            "\n",
            "Time (s): 0.6266224384307861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 292 / 499\n",
            "LR: 8.851359448312296e-05\n",
            "Train loss: 0.6108340620994568\n",
            "\n",
            "Time (s): 0.6260159015655518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 293 / 499\n",
            "LR: 8.85134169544154e-05\n",
            "Train loss: 0.3927551507949829\n",
            "\n",
            "Time (s): 0.6308221817016602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 294 / 499\n",
            "LR: 8.851323942677601e-05\n",
            "Train loss: 0.5558207631111145\n",
            "\n",
            "Time (s): 0.6324093341827393\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 295 / 499\n",
            "LR: 8.851306190020481e-05\n",
            "Train loss: 1.012791633605957\n",
            "\n",
            "Time (s): 0.6312227249145508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 296 / 499\n",
            "LR: 8.851288437470176e-05\n",
            "Train loss: 1.039083480834961\n",
            "\n",
            "Time (s): 0.6267950534820557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 297 / 499\n",
            "LR: 8.851270685026687e-05\n",
            "Train loss: 0.8736241459846497\n",
            "\n",
            "Time (s): 0.6290698051452637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 298 / 499\n",
            "LR: 8.851252932690014e-05\n",
            "Train loss: 0.8445572853088379\n",
            "\n",
            "Time (s): 0.6244306564331055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 299 / 499\n",
            "LR: 8.851235180460153e-05\n",
            "Train loss: 1.1128549575805664\n",
            "\n",
            "Time (s): 0.6258389949798584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 300 / 499\n",
            "LR: 8.851217428337103e-05\n",
            "Train loss: 0.6152083873748779\n",
            "\n",
            "Time (s): 0.6317160129547119\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 301 / 499\n",
            "LR: 8.851199676320865e-05\n",
            "Train loss: 1.6119873523712158\n",
            "\n",
            "Time (s): 0.6296911239624023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 302 / 499\n",
            "LR: 8.851181924411437e-05\n",
            "Train loss: 1.0243744850158691\n",
            "\n",
            "Time (s): 0.6311044692993164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 303 / 499\n",
            "LR: 8.851164172608818e-05\n",
            "Train loss: 0.9899743795394897\n",
            "\n",
            "Time (s): 0.6313371658325195\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 304 / 499\n",
            "LR: 8.851146420913007e-05\n",
            "Train loss: 0.6850450038909912\n",
            "\n",
            "Time (s): 0.6287052631378174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 305 / 499\n",
            "LR: 8.851128669324004e-05\n",
            "Train loss: 0.8963041305541992\n",
            "\n",
            "Time (s): 0.6302523612976074\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 306 / 499\n",
            "LR: 8.851110917841804e-05\n",
            "Train loss: 0.6173481345176697\n",
            "\n",
            "Time (s): 0.6296184062957764\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 307 / 499\n",
            "LR: 8.85109316646641e-05\n",
            "Train loss: 1.1342003345489502\n",
            "\n",
            "Time (s): 0.6268470287322998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 308 / 499\n",
            "LR: 8.851075415197819e-05\n",
            "Train loss: 0.37468644976615906\n",
            "\n",
            "Time (s): 0.6314668655395508\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 309 / 499\n",
            "LR: 8.85105766403603e-05\n",
            "Train loss: 1.835554599761963\n",
            "\n",
            "Time (s): 0.6311776638031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 310 / 499\n",
            "LR: 8.851039912981044e-05\n",
            "Train loss: 0.46814948320388794\n",
            "\n",
            "Time (s): 0.63435959815979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 311 / 499\n",
            "LR: 8.851022162032858e-05\n",
            "Train loss: 1.0983778238296509\n",
            "\n",
            "Time (s): 0.6330745220184326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 312 / 499\n",
            "LR: 8.85100441119147e-05\n",
            "Train loss: 1.241766095161438\n",
            "\n",
            "Time (s): 0.6311137676239014\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 313 / 499\n",
            "LR: 8.850986660456882e-05\n",
            "Train loss: 1.1764240264892578\n",
            "\n",
            "Time (s): 0.6334414482116699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 314 / 499\n",
            "LR: 8.850968909829091e-05\n",
            "Train loss: 0.4831482768058777\n",
            "\n",
            "Time (s): 0.6296641826629639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 315 / 499\n",
            "LR: 8.850951159308093e-05\n",
            "Train loss: 0.9746150970458984\n",
            "\n",
            "Time (s): 0.6334419250488281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 316 / 499\n",
            "LR: 8.850933408893893e-05\n",
            "Train loss: 0.8172130584716797\n",
            "\n",
            "Time (s): 0.6292877197265625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 317 / 499\n",
            "LR: 8.850915658586487e-05\n",
            "Train loss: 0.7675962448120117\n",
            "\n",
            "Time (s): 0.6327807903289795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 318 / 499\n",
            "LR: 8.850897908385873e-05\n",
            "Train loss: 1.1727359294891357\n",
            "\n",
            "Time (s): 0.6339807510375977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 319 / 499\n",
            "LR: 8.850880158292051e-05\n",
            "Train loss: 0.5930562019348145\n",
            "\n",
            "Time (s): 0.6350052356719971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 320 / 499\n",
            "LR: 8.850862408305021e-05\n",
            "Train loss: 1.0498759746551514\n",
            "\n",
            "Time (s): 0.6293492317199707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 321 / 499\n",
            "LR: 8.850844658424779e-05\n",
            "Train loss: 0.27347931265830994\n",
            "\n",
            "Time (s): 0.6330809593200684\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 322 / 499\n",
            "LR: 8.850826908651324e-05\n",
            "Train loss: 0.9144871830940247\n",
            "\n",
            "Time (s): 0.6341040134429932\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 323 / 499\n",
            "LR: 8.850809158984659e-05\n",
            "Train loss: 0.8775680065155029\n",
            "\n",
            "Time (s): 0.6346666812896729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 324 / 499\n",
            "LR: 8.85079140942478e-05\n",
            "Train loss: 1.0406090021133423\n",
            "\n",
            "Time (s): 0.6330375671386719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 325 / 499\n",
            "LR: 8.850773659971688e-05\n",
            "Train loss: 1.3017290830612183\n",
            "\n",
            "Time (s): 0.630103349685669\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 326 / 499\n",
            "LR: 8.850755910625377e-05\n",
            "Train loss: 1.2897790670394897\n",
            "\n",
            "Time (s): 0.63262939453125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 327 / 499\n",
            "LR: 8.85073816138585e-05\n",
            "Train loss: 0.7666414380073547\n",
            "\n",
            "Time (s): 0.6340889930725098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 328 / 499\n",
            "LR: 8.850720412253108e-05\n",
            "Train loss: 0.8119208216667175\n",
            "\n",
            "Time (s): 0.6284298896789551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 329 / 499\n",
            "LR: 8.850702663227143e-05\n",
            "Train loss: 0.3287104666233063\n",
            "\n",
            "Time (s): 0.6280257701873779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 330 / 499\n",
            "LR: 8.85068491430796e-05\n",
            "Train loss: 0.8722072243690491\n",
            "\n",
            "Time (s): 0.6338510513305664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 331 / 499\n",
            "LR: 8.850667165495555e-05\n",
            "Train loss: 0.2940253019332886\n",
            "\n",
            "Time (s): 0.6287469863891602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 332 / 499\n",
            "LR: 8.850649416789929e-05\n",
            "Train loss: 0.4998231530189514\n",
            "\n",
            "Time (s): 0.6288547515869141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 333 / 499\n",
            "LR: 8.85063166819108e-05\n",
            "Train loss: 0.8554103970527649\n",
            "\n",
            "Time (s): 0.631962776184082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 334 / 499\n",
            "LR: 8.850613919699006e-05\n",
            "Train loss: 0.852950394153595\n",
            "\n",
            "Time (s): 0.6281857490539551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 335 / 499\n",
            "LR: 8.850596171313707e-05\n",
            "Train loss: 0.1639520823955536\n",
            "\n",
            "Time (s): 0.6293556690216064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 336 / 499\n",
            "LR: 8.850578423035182e-05\n",
            "Train loss: 0.701072096824646\n",
            "\n",
            "Time (s): 0.6320369243621826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 337 / 499\n",
            "LR: 8.850560674863428e-05\n",
            "Train loss: 0.7293190956115723\n",
            "\n",
            "Time (s): 0.6340029239654541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 338 / 499\n",
            "LR: 8.850542926798446e-05\n",
            "Train loss: 0.38899946212768555\n",
            "\n",
            "Time (s): 0.6288802623748779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 339 / 499\n",
            "LR: 8.850525178840235e-05\n",
            "Train loss: 1.2396385669708252\n",
            "\n",
            "Time (s): 0.6323161125183105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 340 / 499\n",
            "LR: 8.850507430988794e-05\n",
            "Train loss: 0.9435968995094299\n",
            "\n",
            "Time (s): 0.634589672088623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 341 / 499\n",
            "LR: 8.85048968324412e-05\n",
            "Train loss: 1.1259137392044067\n",
            "\n",
            "Time (s): 0.6326637268066406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 342 / 499\n",
            "LR: 8.850471935606214e-05\n",
            "Train loss: 0.905987024307251\n",
            "\n",
            "Time (s): 0.6294803619384766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 343 / 499\n",
            "LR: 8.850454188075073e-05\n",
            "Train loss: 1.8820933103561401\n",
            "\n",
            "Time (s): 0.6325771808624268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 344 / 499\n",
            "LR: 8.850436440650697e-05\n",
            "Train loss: 1.1605758666992188\n",
            "\n",
            "Time (s): 0.6281545162200928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 345 / 499\n",
            "LR: 8.850418693333085e-05\n",
            "Train loss: 1.091178297996521\n",
            "\n",
            "Time (s): 0.634514570236206\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 346 / 499\n",
            "LR: 8.850400946122238e-05\n",
            "Train loss: 0.9157451391220093\n",
            "\n",
            "Time (s): 0.6323704719543457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 347 / 499\n",
            "LR: 8.85038319901815e-05\n",
            "Train loss: 0.4749250113964081\n",
            "\n",
            "Time (s): 0.62868332862854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 348 / 499\n",
            "LR: 8.850365452020823e-05\n",
            "Train loss: 1.0863755941390991\n",
            "\n",
            "Time (s): 0.6289691925048828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 349 / 499\n",
            "LR: 8.850347705130258e-05\n",
            "Train loss: 0.5072058439254761\n",
            "\n",
            "Time (s): 0.6317794322967529\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 350 / 499\n",
            "LR: 8.85032995834645e-05\n",
            "Train loss: 1.3401172161102295\n",
            "\n",
            "Time (s): 0.6334538459777832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 351 / 499\n",
            "LR: 8.8503122116694e-05\n",
            "Train loss: 0.9065316319465637\n",
            "\n",
            "Time (s): 0.6273379325866699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 352 / 499\n",
            "LR: 8.850294465099107e-05\n",
            "Train loss: 0.5607704520225525\n",
            "\n",
            "Time (s): 0.6329290866851807\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 353 / 499\n",
            "LR: 8.850276718635568e-05\n",
            "Train loss: 0.5952639579772949\n",
            "\n",
            "Time (s): 0.6318445205688477\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 354 / 499\n",
            "LR: 8.850258972278784e-05\n",
            "Train loss: 1.3824210166931152\n",
            "\n",
            "Time (s): 0.6304032802581787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 355 / 499\n",
            "LR: 8.850241226028751e-05\n",
            "Train loss: 0.5720885396003723\n",
            "\n",
            "Time (s): 0.6289041042327881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 356 / 499\n",
            "LR: 8.850223479885473e-05\n",
            "Train loss: 0.913828432559967\n",
            "\n",
            "Time (s): 0.6295793056488037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 357 / 499\n",
            "LR: 8.850205733848945e-05\n",
            "Train loss: 0.9008027911186218\n",
            "\n",
            "Time (s): 0.6287622451782227\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 358 / 499\n",
            "LR: 8.850187987919168e-05\n",
            "Train loss: 0.763602077960968\n",
            "\n",
            "Time (s): 0.6282017230987549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 359 / 499\n",
            "LR: 8.850170242096139e-05\n",
            "Train loss: 1.01035737991333\n",
            "\n",
            "Time (s): 0.6269891262054443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 360 / 499\n",
            "LR: 8.850152496379859e-05\n",
            "Train loss: 0.6218069791793823\n",
            "\n",
            "Time (s): 0.6276440620422363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 361 / 499\n",
            "LR: 8.850134750770325e-05\n",
            "Train loss: 0.7900813221931458\n",
            "\n",
            "Time (s): 0.6290590763092041\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 362 / 499\n",
            "LR: 8.850117005267536e-05\n",
            "Train loss: 0.8695774078369141\n",
            "\n",
            "Time (s): 0.628502368927002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 363 / 499\n",
            "LR: 8.850099259871493e-05\n",
            "Train loss: 1.079561710357666\n",
            "\n",
            "Time (s): 0.6288354396820068\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 364 / 499\n",
            "LR: 8.850081514582193e-05\n",
            "Train loss: 0.9427584409713745\n",
            "\n",
            "Time (s): 0.6241869926452637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 365 / 499\n",
            "LR: 8.850063769399635e-05\n",
            "Train loss: 0.5285359621047974\n",
            "\n",
            "Time (s): 0.6283130645751953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 366 / 499\n",
            "LR: 8.85004602432382e-05\n",
            "Train loss: 1.0826847553253174\n",
            "\n",
            "Time (s): 0.6260559558868408\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 367 / 499\n",
            "LR: 8.850028279354746e-05\n",
            "Train loss: 0.6685237288475037\n",
            "\n",
            "Time (s): 0.6242749691009521\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 368 / 499\n",
            "LR: 8.850010534492409e-05\n",
            "Train loss: 1.469403624534607\n",
            "\n",
            "Time (s): 0.6289668083190918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 369 / 499\n",
            "LR: 8.849992789736811e-05\n",
            "Train loss: 0.7907391786575317\n",
            "\n",
            "Time (s): 0.6259853839874268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 370 / 499\n",
            "LR: 8.849975045087949e-05\n",
            "Train loss: 0.47154533863067627\n",
            "\n",
            "Time (s): 0.6290192604064941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 371 / 499\n",
            "LR: 8.849957300545826e-05\n",
            "Train loss: 0.7527041435241699\n",
            "\n",
            "Time (s): 0.6324312686920166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 372 / 499\n",
            "LR: 8.849939556110436e-05\n",
            "Train loss: 0.5661759376525879\n",
            "\n",
            "Time (s): 0.6291875839233398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 373 / 499\n",
            "LR: 8.849921811781781e-05\n",
            "Train loss: 0.7476807236671448\n",
            "\n",
            "Time (s): 0.6273379325866699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 374 / 499\n",
            "LR: 8.849904067559857e-05\n",
            "Train loss: 0.8177874684333801\n",
            "\n",
            "Time (s): 0.6287269592285156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 375 / 499\n",
            "LR: 8.849886323444666e-05\n",
            "Train loss: 0.7267872095108032\n",
            "\n",
            "Time (s): 0.6277422904968262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 376 / 499\n",
            "LR: 8.849868579436207e-05\n",
            "Train loss: 0.8270036578178406\n",
            "\n",
            "Time (s): 0.6266252994537354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 377 / 499\n",
            "LR: 8.849850835534478e-05\n",
            "Train loss: 0.4875052869319916\n",
            "\n",
            "Time (s): 0.6248011589050293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 378 / 499\n",
            "LR: 8.849833091739474e-05\n",
            "Train loss: 0.9403321743011475\n",
            "\n",
            "Time (s): 0.6290957927703857\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 379 / 499\n",
            "LR: 8.849815348051201e-05\n",
            "Train loss: 1.1771653890609741\n",
            "\n",
            "Time (s): 0.6293027400970459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 380 / 499\n",
            "LR: 8.849797604469653e-05\n",
            "Train loss: 0.8832780718803406\n",
            "\n",
            "Time (s): 0.6316776275634766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 381 / 499\n",
            "LR: 8.84977986099483e-05\n",
            "Train loss: 1.133808970451355\n",
            "\n",
            "Time (s): 0.6271214485168457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 382 / 499\n",
            "LR: 8.849762117626734e-05\n",
            "Train loss: 0.6930408477783203\n",
            "\n",
            "Time (s): 0.624626636505127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 383 / 499\n",
            "LR: 8.849744374365357e-05\n",
            "Train loss: 0.6895285844802856\n",
            "\n",
            "Time (s): 0.6333620548248291\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 384 / 499\n",
            "LR: 8.849726631210705e-05\n",
            "Train loss: 0.9984142780303955\n",
            "\n",
            "Time (s): 0.6285600662231445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 385 / 499\n",
            "LR: 8.849708888162776e-05\n",
            "Train loss: 1.2308293581008911\n",
            "\n",
            "Time (s): 0.6262233257293701\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 386 / 499\n",
            "LR: 8.849691145221564e-05\n",
            "Train loss: 0.5781285166740417\n",
            "\n",
            "Time (s): 0.6347827911376953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 387 / 499\n",
            "LR: 8.849673402387071e-05\n",
            "Train loss: 1.1168267726898193\n",
            "\n",
            "Time (s): 0.6293957233428955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 388 / 499\n",
            "LR: 8.849655659659298e-05\n",
            "Train loss: 0.7149641513824463\n",
            "\n",
            "Time (s): 0.6341352462768555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 389 / 499\n",
            "LR: 8.849637917038242e-05\n",
            "Train loss: 0.6834154725074768\n",
            "\n",
            "Time (s): 0.633596658706665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 390 / 499\n",
            "LR: 8.849620174523899e-05\n",
            "Train loss: 1.2640835046768188\n",
            "\n",
            "Time (s): 0.6315093040466309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 391 / 499\n",
            "LR: 8.849602432116272e-05\n",
            "Train loss: 0.5105604529380798\n",
            "\n",
            "Time (s): 0.6309118270874023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 392 / 499\n",
            "LR: 8.849584689815359e-05\n",
            "Train loss: 1.341318964958191\n",
            "\n",
            "Time (s): 0.6304173469543457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 393 / 499\n",
            "LR: 8.849566947621158e-05\n",
            "Train loss: 0.5295162796974182\n",
            "\n",
            "Time (s): 0.6324124336242676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 394 / 499\n",
            "LR: 8.84954920553367e-05\n",
            "Train loss: 0.8296442031860352\n",
            "\n",
            "Time (s): 0.6320366859436035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 395 / 499\n",
            "LR: 8.849531463552889e-05\n",
            "Train loss: 0.5618105530738831\n",
            "\n",
            "Time (s): 0.6348280906677246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 396 / 499\n",
            "LR: 8.849513721678822e-05\n",
            "Train loss: 0.8504077792167664\n",
            "\n",
            "Time (s): 0.6334075927734375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 397 / 499\n",
            "LR: 8.849495979911461e-05\n",
            "Train loss: 1.2671325206756592\n",
            "\n",
            "Time (s): 0.6285958290100098\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 398 / 499\n",
            "LR: 8.849478238250806e-05\n",
            "Train loss: 0.6316518187522888\n",
            "\n",
            "Time (s): 0.6306002140045166\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 399 / 499\n",
            "LR: 8.84946049669686e-05\n",
            "Train loss: 1.4940521717071533\n",
            "\n",
            "Time (s): 0.6288349628448486\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 400 / 499\n",
            "LR: 8.849442755249618e-05\n",
            "Train loss: 1.2019859552383423\n",
            "\n",
            "Time (s): 0.6298823356628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 401 / 499\n",
            "LR: 8.849425013909078e-05\n",
            "Train loss: 0.926816463470459\n",
            "\n",
            "Time (s): 0.6319725513458252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 402 / 499\n",
            "LR: 8.849407272675242e-05\n",
            "Train loss: 0.7912778258323669\n",
            "\n",
            "Time (s): 0.6326582431793213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 403 / 499\n",
            "LR: 8.849389531548109e-05\n",
            "Train loss: 1.1712268590927124\n",
            "\n",
            "Time (s): 0.6318318843841553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 404 / 499\n",
            "LR: 8.849371790527676e-05\n",
            "Train loss: 1.195434331893921\n",
            "\n",
            "Time (s): 0.629133939743042\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 405 / 499\n",
            "LR: 8.849354049613943e-05\n",
            "Train loss: 0.4814322590827942\n",
            "\n",
            "Time (s): 0.6321048736572266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 406 / 499\n",
            "LR: 8.849336308806909e-05\n",
            "Train loss: 0.9250426292419434\n",
            "\n",
            "Time (s): 0.6289761066436768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 407 / 499\n",
            "LR: 8.849318568106573e-05\n",
            "Train loss: 0.8076512813568115\n",
            "\n",
            "Time (s): 0.6293785572052002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 408 / 499\n",
            "LR: 8.849300827512931e-05\n",
            "Train loss: 0.9315033555030823\n",
            "\n",
            "Time (s): 0.6302626132965088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 409 / 499\n",
            "LR: 8.849283087025987e-05\n",
            "Train loss: 0.9802035093307495\n",
            "\n",
            "Time (s): 0.6282248497009277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 410 / 499\n",
            "LR: 8.849265346645737e-05\n",
            "Train loss: 0.5749980211257935\n",
            "\n",
            "Time (s): 0.6298775672912598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 411 / 499\n",
            "LR: 8.849247606372179e-05\n",
            "Train loss: 0.5753731727600098\n",
            "\n",
            "Time (s): 0.6316454410552979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 412 / 499\n",
            "LR: 8.849229866205317e-05\n",
            "Train loss: 0.8225818276405334\n",
            "\n",
            "Time (s): 0.6300382614135742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 413 / 499\n",
            "LR: 8.849212126145142e-05\n",
            "Train loss: 1.4390449523925781\n",
            "\n",
            "Time (s): 0.6240088939666748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 414 / 499\n",
            "LR: 8.849194386191658e-05\n",
            "Train loss: 1.0352022647857666\n",
            "\n",
            "Time (s): 0.6288051605224609\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 415 / 499\n",
            "LR: 8.849176646344865e-05\n",
            "Train loss: 0.30256831645965576\n",
            "\n",
            "Time (s): 0.6274433135986328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 416 / 499\n",
            "LR: 8.849158906604757e-05\n",
            "Train loss: 0.8605738878250122\n",
            "\n",
            "Time (s): 0.633350133895874\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 417 / 499\n",
            "LR: 8.849141166971339e-05\n",
            "Train loss: 0.8890697360038757\n",
            "\n",
            "Time (s): 0.6315274238586426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 418 / 499\n",
            "LR: 8.849123427444605e-05\n",
            "Train loss: 1.176088571548462\n",
            "\n",
            "Time (s): 0.6333484649658203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 419 / 499\n",
            "LR: 8.849105688024555e-05\n",
            "Train loss: 0.7495417594909668\n",
            "\n",
            "Time (s): 0.6328675746917725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 420 / 499\n",
            "LR: 8.849087948711191e-05\n",
            "Train loss: 0.7726805806159973\n",
            "\n",
            "Time (s): 0.6246066093444824\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 421 / 499\n",
            "LR: 8.849070209504507e-05\n",
            "Train loss: 0.544156551361084\n",
            "\n",
            "Time (s): 0.6245934963226318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 422 / 499\n",
            "LR: 8.849052470404508e-05\n",
            "Train loss: 0.6500340700149536\n",
            "\n",
            "Time (s): 0.6340692043304443\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 423 / 499\n",
            "LR: 8.849034731411188e-05\n",
            "Train loss: 0.5575845837593079\n",
            "\n",
            "Time (s): 0.6321022510528564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 424 / 499\n",
            "LR: 8.849016992524547e-05\n",
            "Train loss: 0.7387254238128662\n",
            "\n",
            "Time (s): 0.6280581951141357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 425 / 499\n",
            "LR: 8.848999253744584e-05\n",
            "Train loss: 1.0430166721343994\n",
            "\n",
            "Time (s): 0.6314404010772705\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 426 / 499\n",
            "LR: 8.848981515071299e-05\n",
            "Train loss: 1.041446566581726\n",
            "\n",
            "Time (s): 0.6275298595428467\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 427 / 499\n",
            "LR: 8.84896377650469e-05\n",
            "Train loss: 0.5878812074661255\n",
            "\n",
            "Time (s): 0.6343328952789307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 428 / 499\n",
            "LR: 8.848946038044754e-05\n",
            "Train loss: 0.7918992638587952\n",
            "\n",
            "Time (s): 0.6334865093231201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 429 / 499\n",
            "LR: 8.848928299691494e-05\n",
            "Train loss: 0.8192124366760254\n",
            "\n",
            "Time (s): 0.6294646263122559\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 430 / 499\n",
            "LR: 8.848910561444908e-05\n",
            "Train loss: 0.4241708517074585\n",
            "\n",
            "Time (s): 0.6278316974639893\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 431 / 499\n",
            "LR: 8.848892823304992e-05\n",
            "Train loss: 1.3981469869613647\n",
            "\n",
            "Time (s): 0.6290585994720459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 432 / 499\n",
            "LR: 8.84887508527175e-05\n",
            "Train loss: 1.0574891567230225\n",
            "\n",
            "Time (s): 0.6290886402130127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 433 / 499\n",
            "LR: 8.848857347345173e-05\n",
            "Train loss: 1.0360733270645142\n",
            "\n",
            "Time (s): 0.6267125606536865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 434 / 499\n",
            "LR: 8.84883960952527e-05\n",
            "Train loss: 0.4075573980808258\n",
            "\n",
            "Time (s): 0.6282744407653809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 435 / 499\n",
            "LR: 8.848821871812031e-05\n",
            "Train loss: 1.0441844463348389\n",
            "\n",
            "Time (s): 0.6283431053161621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 436 / 499\n",
            "LR: 8.84880413420546e-05\n",
            "Train loss: 1.029524326324463\n",
            "\n",
            "Time (s): 0.6277103424072266\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 437 / 499\n",
            "LR: 8.848786396705555e-05\n",
            "Train loss: 0.6444057822227478\n",
            "\n",
            "Time (s): 0.6249754428863525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 438 / 499\n",
            "LR: 8.848768659312313e-05\n",
            "Train loss: 0.8010090589523315\n",
            "\n",
            "Time (s): 0.6294875144958496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 439 / 499\n",
            "LR: 8.848750922025735e-05\n",
            "Train loss: 0.47618532180786133\n",
            "\n",
            "Time (s): 0.6284189224243164\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 440 / 499\n",
            "LR: 8.848733184845821e-05\n",
            "Train loss: 1.0830148458480835\n",
            "\n",
            "Time (s): 0.6245386600494385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 441 / 499\n",
            "LR: 8.848715447772565e-05\n",
            "Train loss: 0.5189254283905029\n",
            "\n",
            "Time (s): 0.6290285587310791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 442 / 499\n",
            "LR: 8.848697710805971e-05\n",
            "Train loss: 0.5860655307769775\n",
            "\n",
            "Time (s): 0.6261310577392578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 443 / 499\n",
            "LR: 8.848679973946037e-05\n",
            "Train loss: 0.3789036273956299\n",
            "\n",
            "Time (s): 0.6299822330474854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 444 / 499\n",
            "LR: 8.848662237192759e-05\n",
            "Train loss: 0.38633349537849426\n",
            "\n",
            "Time (s): 0.628420352935791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 445 / 499\n",
            "LR: 8.848644500546139e-05\n",
            "Train loss: 0.8284602165222168\n",
            "\n",
            "Time (s): 0.6242942810058594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 446 / 499\n",
            "LR: 8.848626764006176e-05\n",
            "Train loss: 0.750317394733429\n",
            "\n",
            "Time (s): 0.63106369972229\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 447 / 499\n",
            "LR: 8.848609027572866e-05\n",
            "Train loss: 0.462654709815979\n",
            "\n",
            "Time (s): 0.6296360492706299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 448 / 499\n",
            "LR: 8.84859129124621e-05\n",
            "Train loss: 1.025014042854309\n",
            "\n",
            "Time (s): 0.6234910488128662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 449 / 499\n",
            "LR: 8.848573555026207e-05\n",
            "Train loss: 0.7339401245117188\n",
            "\n",
            "Time (s): 0.6234738826751709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 450 / 499\n",
            "LR: 8.848555818912858e-05\n",
            "Train loss: 0.7336865067481995\n",
            "\n",
            "Time (s): 0.6332199573516846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 451 / 499\n",
            "LR: 8.848538082906157e-05\n",
            "Train loss: 0.8649303317070007\n",
            "\n",
            "Time (s): 0.6309893131256104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 452 / 499\n",
            "LR: 8.848520347006106e-05\n",
            "Train loss: 0.7935048937797546\n",
            "\n",
            "Time (s): 0.6279423236846924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 453 / 499\n",
            "LR: 8.848502611212705e-05\n",
            "Train loss: 1.0515000820159912\n",
            "\n",
            "Time (s): 0.6247220039367676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 454 / 499\n",
            "LR: 8.848484875525946e-05\n",
            "Train loss: 0.5563608407974243\n",
            "\n",
            "Time (s): 0.6240370273590088\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 455 / 499\n",
            "LR: 8.848467139945838e-05\n",
            "Train loss: 0.7228772640228271\n",
            "\n",
            "Time (s): 0.6279234886169434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 456 / 499\n",
            "LR: 8.848449404472374e-05\n",
            "Train loss: 0.9154542088508606\n",
            "\n",
            "Time (s): 0.6280272006988525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 457 / 499\n",
            "LR: 8.848431669105554e-05\n",
            "Train loss: 1.2079296112060547\n",
            "\n",
            "Time (s): 0.623948335647583\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 458 / 499\n",
            "LR: 8.848413933845378e-05\n",
            "Train loss: 0.46684885025024414\n",
            "\n",
            "Time (s): 0.6242103576660156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 459 / 499\n",
            "LR: 8.848396198691844e-05\n",
            "Train loss: 1.1876940727233887\n",
            "\n",
            "Time (s): 0.6239128112792969\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 460 / 499\n",
            "LR: 8.848378463644951e-05\n",
            "Train loss: 1.0445276498794556\n",
            "\n",
            "Time (s): 0.629669189453125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 461 / 499\n",
            "LR: 8.848360728704697e-05\n",
            "Train loss: 0.4749501049518585\n",
            "\n",
            "Time (s): 0.6239497661590576\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 462 / 499\n",
            "LR: 8.848342993871083e-05\n",
            "Train loss: 0.9396610856056213\n",
            "\n",
            "Time (s): 0.6243417263031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 463 / 499\n",
            "LR: 8.848325259144105e-05\n",
            "Train loss: 1.3815807104110718\n",
            "\n",
            "Time (s): 0.6236751079559326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 464 / 499\n",
            "LR: 8.848307524523765e-05\n",
            "Train loss: 1.232428789138794\n",
            "\n",
            "Time (s): 0.62380051612854\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 465 / 499\n",
            "LR: 8.848289790010061e-05\n",
            "Train loss: 0.4880942702293396\n",
            "\n",
            "Time (s): 0.6271035671234131\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 466 / 499\n",
            "LR: 8.848272055602989e-05\n",
            "Train loss: 1.1422703266143799\n",
            "\n",
            "Time (s): 0.6324374675750732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 467 / 499\n",
            "LR: 8.848254321302552e-05\n",
            "Train loss: 0.32631203532218933\n",
            "\n",
            "Time (s): 0.6328520774841309\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 468 / 499\n",
            "LR: 8.848236587108748e-05\n",
            "Train loss: 0.8425583839416504\n",
            "\n",
            "Time (s): 0.6348567008972168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 469 / 499\n",
            "LR: 8.848218853021576e-05\n",
            "Train loss: 1.4186127185821533\n",
            "\n",
            "Time (s): 0.6336240768432617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 470 / 499\n",
            "LR: 8.848201119041033e-05\n",
            "Train loss: 0.9368794560432434\n",
            "\n",
            "Time (s): 0.6322958469390869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 471 / 499\n",
            "LR: 8.848183385167118e-05\n",
            "Train loss: 0.8428559303283691\n",
            "\n",
            "Time (s): 0.6265759468078613\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 472 / 499\n",
            "LR: 8.848165651399833e-05\n",
            "Train loss: 0.3423602283000946\n",
            "\n",
            "Time (s): 0.6276931762695312\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 473 / 499\n",
            "LR: 8.848147917739174e-05\n",
            "Train loss: 0.8361472487449646\n",
            "\n",
            "Time (s): 0.6280422210693359\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 474 / 499\n",
            "LR: 8.848130184185142e-05\n",
            "Train loss: 0.5201989412307739\n",
            "\n",
            "Time (s): 0.6261255741119385\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 475 / 499\n",
            "LR: 8.848112450737734e-05\n",
            "Train loss: 0.5925413966178894\n",
            "\n",
            "Time (s): 0.6295747756958008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 476 / 499\n",
            "LR: 8.84809471739695e-05\n",
            "Train loss: 1.1525120735168457\n",
            "\n",
            "Time (s): 0.6303019523620605\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 477 / 499\n",
            "LR: 8.84807698416279e-05\n",
            "Train loss: 1.019930362701416\n",
            "\n",
            "Time (s): 0.6345493793487549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 478 / 499\n",
            "LR: 8.84805925103525e-05\n",
            "Train loss: 0.8887141346931458\n",
            "\n",
            "Time (s): 0.6281120777130127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 479 / 499\n",
            "LR: 8.848041518014331e-05\n",
            "Train loss: 0.3748105466365814\n",
            "\n",
            "Time (s): 0.6316256523132324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 480 / 499\n",
            "LR: 8.848023785100032e-05\n",
            "Train loss: 1.06062912940979\n",
            "\n",
            "Time (s): 0.6285579204559326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 481 / 499\n",
            "LR: 8.848006052292351e-05\n",
            "Train loss: 0.8813280463218689\n",
            "\n",
            "Time (s): 0.6336455345153809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 482 / 499\n",
            "LR: 8.847988319591289e-05\n",
            "Train loss: 0.43561115860939026\n",
            "\n",
            "Time (s): 0.6263902187347412\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 483 / 499\n",
            "LR: 8.847970586996842e-05\n",
            "Train loss: 1.1100064516067505\n",
            "\n",
            "Time (s): 0.6333644390106201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 484 / 499\n",
            "LR: 8.847952854509012e-05\n",
            "Train loss: 0.9664360284805298\n",
            "\n",
            "Time (s): 0.6338751316070557\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 485 / 499\n",
            "LR: 8.847935122127795e-05\n",
            "Train loss: 1.165573239326477\n",
            "\n",
            "Time (s): 0.6295650005340576\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 486 / 499\n",
            "LR: 8.847917389853189e-05\n",
            "Train loss: 0.6008745431900024\n",
            "\n",
            "Time (s): 0.6284358501434326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 487 / 499\n",
            "LR: 8.847899657685197e-05\n",
            "Train loss: 1.0173187255859375\n",
            "\n",
            "Time (s): 0.6319844722747803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 488 / 499\n",
            "LR: 8.847881925623817e-05\n",
            "Train loss: 1.2306345701217651\n",
            "\n",
            "Time (s): 0.6329331398010254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 489 / 499\n",
            "LR: 8.847864193669047e-05\n",
            "Train loss: 0.5210532546043396\n",
            "\n",
            "Time (s): 0.6306939125061035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 490 / 499\n",
            "LR: 8.847846461820884e-05\n",
            "Train loss: 0.7888966798782349\n",
            "\n",
            "Time (s): 0.6243524551391602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 491 / 499\n",
            "LR: 8.847828730079329e-05\n",
            "Train loss: 0.596229076385498\n",
            "\n",
            "Time (s): 0.6311357021331787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 492 / 499\n",
            "LR: 8.847810998444381e-05\n",
            "Train loss: 1.066644310951233\n",
            "\n",
            "Time (s): 0.6283211708068848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 493 / 499\n",
            "LR: 8.84779326691604e-05\n",
            "Train loss: 0.7954883575439453\n",
            "\n",
            "Time (s): 0.6319007873535156\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 494 / 499\n",
            "LR: 8.847775535494302e-05\n",
            "Train loss: 0.6475178599357605\n",
            "\n",
            "Time (s): 0.6288707256317139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 495 / 499\n",
            "LR: 8.847757804179169e-05\n",
            "Train loss: 0.6276286840438843\n",
            "\n",
            "Time (s): 0.6328699588775635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 496 / 499\n",
            "LR: 8.847740072970639e-05\n",
            "Train loss: 0.6966992020606995\n",
            "\n",
            "Time (s): 0.6282556056976318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 497 / 499\n",
            "LR: 8.847722341868709e-05\n",
            "Train loss: 0.7581499218940735\n",
            "\n",
            "Time (s): 0.6245989799499512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 498 / 499\n",
            "LR: 8.84770461087338e-05\n",
            "Train loss: 1.2383759021759033\n",
            "\n",
            "Time (s): 0.62890625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 500  Batch 499 / 499\n",
            "LR: 8.84768687998465e-05\n",
            "Train loss: 0.22408880293369293\n",
            "\n",
            "Time (s): 0.0534672737121582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 500\n",
            "Avg train loss: 0.7059049410726838\n",
            "Avg train acc: 0.7909068882107018\n",
            "Avg eval loss: 0.933945836389766\n",
            "Avg eval acc: 0.7485410781467662\n",
            "=========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Re-Start Training from a certain checkpoint and epoch\n",
        "batch_size = 4 #@param {type:\"slider\", min:0, max:8, step:1}\n",
        "number_of_training_epochs = 500 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "maximum_output_MIDI_sequence = 2048 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "saved_checkpoint_full_path = \"./output/weights/epoch_0493.pickle\" #@param {type:\"string\"}\n",
        "continue_epoch_number = 493 #@param {type:\"integer\"}\n",
        "\n",
        "!python3 train.py -output_dir ./output -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence -continue_weights $saved_checkpoint_full_path -continue_epoch $continue_epoch_number #-n_layers -num_heads -d_model -dim_feedforward"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k1D-o-E-TnI8"
      },
      "source": [
        "###Evaluate the resulted models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qQLOmv7wrOos"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate Best Resulting Accuracy Model (best_acc_weights.pickle)\n",
        "!python3 evaluate.py -model_weights ./output/results/best_acc_weights.pickle #--rpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c7QftGOfTyx2"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate Best Resulting Loss Model (best_loss_weights.pickle)\n",
        "!python3 evaluate.py -model_weights ./output/results/best_loss_weights.pickle #--rpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "MusrrrOxt1uy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creation of the directory ./output/results failed\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Graph the results\n",
        "import argparse\n",
        "import os\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RESULTS_FILE = \"results.csv\"\n",
        "EPOCH_IDX = 0\n",
        "LR_IDX = 1\n",
        "EVAL_LOSS_IDX = 4\n",
        "EVAL_ACC_IDX = 5\n",
        "\n",
        "SPLITTER = '?'\n",
        "\n",
        "\n",
        "def graph_results(input_dirs=\"./output/results\", output_dir=\"./output/results\", model_names=None, epoch_start=0, epoch_end=None):\n",
        "    \"\"\"\n",
        "    ----------\n",
        "    Author: Damon Gwinn\n",
        "    ----------\n",
        "    Graphs model training and evaluation data\n",
        "    ----------\n",
        "    \"\"\"\n",
        "\n",
        "    input_dirs = input_dirs.split(SPLITTER)\n",
        "\n",
        "    if(model_names is not None):\n",
        "        model_names = model_names.split(SPLITTER)\n",
        "        if(len(model_names) != len(input_dirs)):\n",
        "            print(\"Error: len(model_names) != len(input_dirs)\")\n",
        "            return\n",
        "\n",
        "    #Initialize Loss and Accuracy arrays\n",
        "    loss_arrs = []\n",
        "    accuracy_arrs = []\n",
        "    epoch_counts = []\n",
        "    lrs = []\n",
        "\n",
        "    for input_dir in input_dirs:\n",
        "        loss_arr = []\n",
        "        accuracy_arr = []\n",
        "        epoch_count = []\n",
        "        lr_arr = []\n",
        "\n",
        "        f = os.path.join(input_dir, RESULTS_FILE)\n",
        "        with open(f, \"r\") as i_stream:\n",
        "            reader = csv.reader(i_stream)\n",
        "            next(reader)\n",
        "\n",
        "            lines = [line for line in reader]\n",
        "\n",
        "        if(epoch_end is None):\n",
        "            epoch_end = math.inf\n",
        "\n",
        "        epoch_start = max(epoch_start, 0)\n",
        "        epoch_start = min(epoch_start, epoch_end)\n",
        "\n",
        "        for line in lines:\n",
        "            epoch = line[EPOCH_IDX]\n",
        "            lr = line[LR_IDX]\n",
        "            accuracy = line[EVAL_ACC_IDX]\n",
        "            loss = line[EVAL_LOSS_IDX]\n",
        "\n",
        "            if(int(epoch) >= epoch_start and int(epoch) < epoch_end):\n",
        "                accuracy_arr.append(float(accuracy))\n",
        "                loss_arr.append(float(loss))\n",
        "                epoch_count.append(int(epoch))\n",
        "                lr_arr.append(float(lr))\n",
        "\n",
        "        loss_arrs.append(loss_arr)\n",
        "        accuracy_arrs.append(accuracy_arr)\n",
        "        epoch_counts.append(epoch_count)\n",
        "        lrs.append(lr_arr)\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        try:\n",
        "            os.mkdir(output_dir)\n",
        "        except OSError:\n",
        "            print (\"Creation of the directory %s failed\" % output_dir)\n",
        "        else:\n",
        "            print (\"Successfully created the directory %s\" % output_dir)\n",
        "\n",
        "    ##### LOSS #####\n",
        "    for i in range(len(loss_arrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], loss_arrs[i], label=name)\n",
        "        plt.title(\"Loss Results\")\n",
        "        plt.ylabel('Loss (Cross Entropy)')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig1 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig1.savefig(os.path.join(output_dir, 'loss_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    ##### ACCURACY #####\n",
        "    for i in range(len(accuracy_arrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], accuracy_arrs[i], label=name)\n",
        "        plt.title(\"Accuracy Results\")\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig2 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig2.savefig(os.path.join(output_dir, 'accuracy_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    ##### LR #####\n",
        "    for i in range(len(lrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], lrs[i], label=name)\n",
        "        plt.title(\"Learn Rate Results\")\n",
        "        plt.ylabel('Learn Rate')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig2 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig2.savefig(os.path.join(output_dir, 'lr_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "graph_results(model_names='rpr')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fxHrTsFUdn-r"
      },
      "source": [
        "To have the model continue your custom MIDI enter the following into the custom_MIDI field below:\n",
        "\n",
        "-primer_file '/content/some_dir/some_seed_midi.mid'\n",
        "\n",
        "For example: -primer_file '/content/MusicTransformer-Pytorch/seed.mid'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EJXWoBMWL3ph"
      },
      "source": [
        "# Generate and Explore the output :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "czNulONr4tB6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================\n",
            "midi_root: ./dataset\n",
            "output_dir: ./output/Generated\n",
            "primer_file: None\n",
            "force_cpu: False\n",
            "\n",
            "target_seq_length: 1023\n",
            "num_prime: 65\n",
            "model_weights: ./output/results/best_acc_weights.pickle\n",
            "beam: 0\n",
            "\n",
            "rpr: False\n",
            "max_sequence: 2048\n",
            "n_layers: 6\n",
            "num_heads: 8\n",
            "d_model: 512\n",
            "\n",
            "dim_feedforward: 1024\n",
            "=========================\n",
            "\n",
            "Using primer index: 43 ( ./dataset/test/Anger/0dcaa15e668621bca5b1bf7532d45e2b.mid.pickle )\n",
            "RAND DIST\n",
            "Generating sequence of max length: 1023\n",
            "100 / 1023\n",
            "150 / 1023\n",
            "200 / 1023\n",
            "250 / 1023\n",
            "300 / 1023\n",
            "350 / 1023\n",
            "400 / 1023\n",
            "450 / 1023\n",
            "500 / 1023\n",
            "550 / 1023\n",
            "600 / 1023\n",
            "650 / 1023\n",
            "700 / 1023\n",
            "750 / 1023\n",
            "800 / 1023\n",
            "850 / 1023\n",
            "900 / 1023\n",
            "950 / 1023\n",
            "1000 / 1023\n",
            "Successfully exported the output to output folder. To primer.mid and rand.mid\n"
          ]
        }
      ],
      "source": [
        "#@title Generate, Plot, Graph, Save, Download, and Render the resulting output\n",
        "number_of_tokens_to_generate = 1023 #@param {type:\"slider\", min:1, max:2048, step:1}\n",
        "priming_sequence_length = 65 #@param {type:\"slider\", min:1, max:2048, step:8}\n",
        "maximum_possible_output_sequence = 2048 #@param {type:\"slider\", min:0, max:2048, step:8}\n",
        "select_model = \"./output/results/best_acc_weights.pickle\" #@param [\"/content/MusicTransformer-Pytorch/rpr/results/best_acc_weights.pickle\", \"/content/MusicTransformer-Pytorch/rpr/results/best_loss_weights.pickle\"]\n",
        "custom_MIDI = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import processor\n",
        "from processor import encode_midi, decode_midi\n",
        "\n",
        "!python generate.py -output_dir ./output/Generated -model_weights=$select_model -target_seq_length=$number_of_tokens_to_generate -num_prime=$priming_sequence_length -max_sequence=$maximum_possible_output_sequence #$custom_MIDI #\n",
        "\n",
        "print('Successfully exported the output to output folder. To primer.mid and rand.mid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IG48uyKGzcTI"
      },
      "outputs": [],
      "source": [
        "#@title Plot and Graph the Output :)\n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "highest_displayed_pitch = 92 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "lowest_displayed_pitch = 24 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "piano_roll_color_map = \"Blues\"\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/MusicTransformer-Pytorch/output/rand.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/MusicTransformer-Pytorch/output/rand.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, int(lowest_displayed_pitch), int(highest_displayed_pitch))\n",
        "plt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Super_Piano_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
